{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22951,"status":"ok","timestamp":1656831986402,"user":{"displayName":"eli","userId":"04468701451872085663"},"user_tz":-180},"id":"kPZMpUgzzEZf","outputId":"8567b2de-ce60-44f3-bcc0-2528e3adbee0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n","/content/drive/My Drive/finalProject\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","%cd /content/drive/My Drive/finalProject\n","!cp /content/drive/MyDrive/finalProject/cuda_IndRNN_onlyrecurrent.py /content\n","!cp /content/drive/MyDrive/finalProject/Indrnn_densenet.py /content\n","!cp /content/drive/MyDrive/finalProject/IndRNN_onlyrecurrent.py /content\n","!cp /content/drive/MyDrive/finalProject/indrnn.py /content"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cj4E3kPesRP_"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"GouN3UezTpaC"},"source":["###imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a56hLHQoTGD7"},"outputs":[],"source":["import torch \n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import os\n","import torch\n","import torchvision\n","import tarfile\n","import torch.nn as nn\n","import numpy as np\n","import torch.nn.functional as F\n","from torchvision.datasets.utils import download_url\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as tt\n","from torch.utils.data import random_split\n","from torchvision.utils import make_grid\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from indrnn import IndRNNv2\n","from indrnn import IndRNN\n","import argparse"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jsp7tvIevCfh"},"outputs":[],"source":["\n"]},{"cell_type":"markdown","metadata":{"id":"9GMslRn9Tqx7"},"source":["###graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S8lza7tSTqov"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","def plotArray(arr):\n","  x=np.arange(0, len(arr))\n","  y=arr\n","  plt.title(\"Line graph\")\n","  plt.xlabel(\"X axis\")\n","  plt.ylabel(\"Y axis\")\n","  plt.plot(x, y, color =\"red\")\n","  plt.show()\n","def into_graph(two_d_arr):\n","  for i in range(len(two_d_arr)):\n","    plotArray(two_d_arr[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"otXpbW5B_olN"},"outputs":[],"source":["def create_plot(arr,color,name):\n","  x=np.arange(0, len(arr))\n","  y=arr\n","  plt.xlabel(\"step\")\n","  plt.ylabel(\"Score\")\n","  plt.plot(x, y, color =color,label=name)\n"]},{"cell_type":"markdown","metadata":{"id":"e6Wcu_GnJ075"},"source":["###load data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":512,"status":"ok","timestamp":1656831988841,"user":{"displayName":"eli","userId":"04468701451872085663"},"user_tz":-180},"id":"0U-kqYa-Sz8O","outputId":"1660982a-fd6c-41cf-c23d-1a28af1af86d"},"outputs":[{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["#TEST\n","ARR=[\n","-2.502436639999999990e+00,-2.511298179999999824e+00,-3.065681459999999969e+00,-2.917245630000000034e+00,-3.988899949999999972e+00,-5.728759290000000171e+00,-2.254028799999999944e+00,1.604656700000000047e+00,2.323958130000000066e-01,-2.346296070000000178e+00,-4.170930389999999655e+00,-3.599788189999999943e+00,-2.490435600000000083e+00,-3.085383649999999811e+00,-3.597461459999999889e+00,-2.625307079999999793e+00,-2.490435600000000083e+00,-3.085383649999999811e+00,-3.597461459999999889e+00,-2.625307079999999793e+00,-2.620369909999999969e+00,-4.980332849999999922e+00,-4.330685139999999933e+00,-3.783844410000000158e-01,-1.437827390000000032e-02,-1.274017210000000011e+00,-2.742908240000000220e+00,-3.662452459999999910e+00,-4.223418239999999768e-01,3.938488359999999799e-01,-3.686849360000000075e+00,-3.554679629999999868e+00,-1.774540990000000040e-01,-3.979090750000000010e-01,-1.971811289999999994e+00,-7.766339780000000026e+00,-1.055473139999999965e+01,-4.742561819999999706e+00,1.666054869999999966e-01,1.352528689999999978e+00,-1.055473139999999965e+01,-4.742561819999999706e+00,1.666054869999999966e-01,1.352528689999999978e+00,6.034157869999999813e-01,-4.233051780000000264e+00,-6.381453989999999798e+00,-5.309863570000000088e+00,-5.375402929999999913e+00,-4.493191719999999556e+00,-2.222881319999999938e+00,1.790476560000000106e+00,4.184463499999999669e+00,2.447181940000000111e+00,-8.535397049999999819e-01,-2.757743839999999835e+00,4.184463499999999669e+00,2.447181940000000111e+00,-8.535397049999999819e-01,-2.757743839999999835e+00,-4.401417259999999665e+00,-5.553286080000000347e+00,-3.903214220000000179e+00,-4.461784360000000116e-01,-1.705364349999999973e+00,-6.263812070000000176e+00,-2.799226280000000067e+00,1.219393369999999921e+00,-1.503658890000000081e+00,-1.399117949999999944e+00,-1.300913100000000044e+00,-4.090200420000000392e+00,-2.201535699999999984e+00,-1.102677109999999905e+00,-2.077266929999999956e+00,-3.239169120000000124e+00,-2.943051819999999985e+00,-1.192650320000000042e+00,1.241175530000000027e+00,3.637886760000000219e+00,-2.943051819999999985e+00,-1.192650320000000042e+00,1.241175530000000027e+00,3.637886760000000219e+00,1.842717170000000015e+00,-2.943432570000000137e+00,-2.808387760000000011e+00,1.237600679999999898e+00,1.705308679999999910e+00,-1.557586789999999999e+00,-2.867187019999999809e+00,-5.885650519999999775e-01,1.388024090000000044e+00,2.291028499999999912e+00,1.090915319999999911e+00,-1.746490120000000035e+00,1.091378570000000048e+00,1.689127449999999975e+00,-1.008076150000000032e-01,-3.233659739999999783e+00,-2.663636209999999949e+00,1.255205150000000103e+00,2.537908789999999914e+00,3.277071240000000163e+00,2.084580659999999863e+00,-1.518180010000000024e+00,-2.915001629999999899e+00,-1.758942720000000071e+00,2.989107970000000059e-01,2.921048399999999767e-01,-1.904857040000000001e+00,-1.477271320000000054e+00,2.989107970000000059e-01,2.921048399999999767e-01,-1.904857040000000001e+00,-1.477271320000000054e+00,3.243947980000000175e+00,5.911662100000000031e+00,1.910424230000000057e+00,-1.482810970000000061e+00,1.414452080000000000e+00,1.924489969999999994e+00,5.999137759999999542e-01,6.939291359999999464e-01,-2.940968509999999814e+00,-5.015256400000000170e+00,-2.470204349999999938e+00,-1.806042310000000040e+00,-2.470204349999999938e+00,-1.806042310000000040e+00,-2.472802160000000082e+00,9.648932220000000504e-01,3.713505979999999873e+00,1.357609990000000044e+00,3.556272389999999839e-01,-8.151360149999999916e-01,-3.357682229999999768e-01,2.061651229999999835e+00,1.895046350000000102e+00,-5.384146570000000187e-01,2.211010219999999915e+00,3.585970399999999891e+00,-7.051920889999999664e-01,-3.223443749999999941e+00,1.895046350000000102e+00,-5.384146570000000187e-01,2.211010219999999915e+00,3.585970399999999891e+00,-7.051920889999999664e-01,-3.223443749999999941e+00,-4.742303489999999955e-01,5.821650029999999587e-01,-4.742303489999999955e-01,5.821650029999999587e-01,-1.694214579999999915e+00,-1.856038450000000006e+00,-1.713004350000000064e+00,-1.248252389999999989e+00,2.089238410000000101e+00,3.614716529999999928e+00,9.664743540000000355e-01,5.049821730000000342e-01,-5.150801539999999568e-01,-1.635985369999999994e+00,-9.431252479999999716e-01,9.727826120000000465e-01,-9.815101330000000623e-02,-2.591874359999999822e+00,-9.431252479999999716e-01,9.727826120000000465e-01,-9.815101330000000623e-02,-2.591874359999999822e+00,-1.868351819999999996e+00,-8.505130410000000252e-01,-1.641348479999999999e+00,-3.076065780000000194e-01,5.427227620000000252e-01,-4.085997100000000160e+00,-4.372072700000000367e+00,-3.185238599999999920e+00,1.366762999999999950e+00,5.238456249999999592e+00,3.186997649999999904e+00,-7.368213529999999567e-01,-1.918406370000000027e+00,-3.860415819999999942e-01,-5.074992780000000536e-01,-2.981536629999999910e+00,-1.281016829999999995e+00,4.104300979999999655e+00,4.282936099999999691e+00,1.821715530000000138e-01,-1.281016829999999995e+00,4.104300979999999655e+00,4.282936099999999691e+00,1.821715530000000138e-01,-7.634574170000000271e-01,-1.096706509999999968e+00,-2.187097549999999835e+00,-1.895823360000000068e+00,-1.466252090000000008e+00,-4.743559659999999761e-02,2.721320630000000129e+00,2.320161580000000168e+00,-1.218300460000000029e+00,-4.340232609999999935e-01,1.550392510000000001e+00,1.777257560000000014e+00,-1.588807110000000078e+00,-2.551204680000000113e+00,-8.603909020000000130e-01,4.243376850000000200e-01,-2.302788199999999952e-01,-2.382863460000000100e-01,5.699333919999999970e-02,1.464168909999999935e+00,-1.885511169999999972e-02,4.942258360000000295e+00,5.889770030000000212e+00,1.245039819999999908e+00,-1.168635259999999954e-01,1.774433259999999901e+00,3.330597159999999946e+00,3.900521519999999853e+00,3.330597159999999946e+00,3.900521519999999853e+00,7.416412349999999876e+00,1.553898809999999919e+01,1.719301989999999947e+01,1.093581490000000045e+01,1.210152820000000062e+01,2.653319739999999882e+01,1.210152820000000062e+01,2.653319739999999882e+01,5.302659609999999901e+01,6.410338590000000636e+01,3.636670680000000289e+01,-8.248625759999999474e+00,-3.479598620000000153e+01,-2.167834660000000113e+01,-3.479598620000000153e+01,-2.167834660000000113e+01,4.804339409999999866e+00,2.850508879999999934e+01,4.195890049999999860e+01,2.516349789999999942e+01,1.250543590000000016e+01,1.818568610000000163e+01,1.611979290000000020e+01,1.086126999999999931e+01,1.384578800000000065e+01,2.065957450000000151e+01,2.313875390000000110e+01,2.267828559999999882e+01,3.035391429999999957e+01,4.043827439999999740e+01,3.488999179999999711e+01,7.466949940000000119e+00,-2.755271669999999951e+00,3.541971450000000132e+00,8.290236469999999969e+00,1.473766419999999933e+01,1.289987469999999981e+01,8.834752079999999452e+00,1.289987469999999981e+01,8.834752079999999452e+00,2.137582019999999972e+01,3.440486529999999732e+01,3.560485080000000124e+01,3.170258330000000058e+01,2.645059200000000033e+01,1.431323910000000055e+01,-7.393504140000000113e+00,-2.581716539999999949e+00,1.400661090000000009e+01,1.559909820000000025e+01,3.936778780000000033e+00,-5.890536789999999634e+00,-6.541422840000000072e+00,1.055929059999999975e+00,7.533404349999999638e+00,8.570207599999999815e+00,-3.858952520000000219e-01,-1.157077980000000039e+01,-1.293956090000000003e+01,-1.317037870000000055e+01,-1.756743619999999950e+01,-1.672150800000000004e+01,-1.756743619999999950e+01,-1.672150800000000004e+01,-1.160573669999999957e+01,-1.519390489999999971e+01,-2.340827369999999874e+01,-2.000341799999999992e+01,-8.616444590000000403e+00,-8.879244800000000382e+00,-2.434844400000000064e+01,-2.083579059999999927e+01,-2.381126589999999865e+01,-2.621740529999999936e+01,-2.421389770000000041e+01,-2.647206119999999885e+01,-2.556122780000000105e+01,-2.250883479999999892e+01,-2.421389770000000041e+01,-2.647206119999999885e+01,-2.556122780000000105e+01,-2.250883479999999892e+01,-2.240124700000000146e+01,-2.432792849999999873e+01,-2.792347339999999889e+01,-3.030516240000000039e+01,-3.014786529999999942e+01,-2.566689110000000085e+01,-2.488413999999999859e+01,-2.787966349999999949e+01,-2.781265640000000161e+01,-3.043696399999999969e+01,-2.790872960000000091e+01,-1.767001150000000109e+01,-2.339777760000000129e+01,-2.681035609999999991e+01,-3.088507080000000116e+01,-2.465623280000000150e+01,-1.946288110000000060e+01,-2.451478200000000029e+01,-2.968122479999999896e+01,-2.734036250000000123e+01,-1.418306450000000041e+01,-2.111002159999999961e+01,-2.504866030000000166e+01,-2.048584560000000110e+01,-1.759983829999999827e+01,-1.459174160000000064e+01,-1.090692810000000001e+01,-1.330491450000000064e+01,-2.504866030000000166e+01,-2.048584560000000110e+01,-1.759983829999999827e+01,-1.459174160000000064e+01,-1.090692810000000001e+01,-1.330491450000000064e+01,-1.405705449999999956e+01,-8.775893209999999556e+00,-1.343720249999999972e+01,-1.556265160000000058e+01,-9.998327259999999939e+00,-7.692595479999999597e+00,-1.386213779999999929e+01,-1.674698830000000171e+01,-9.818346019999999896e+00,-3.949236149999999945e+00,-1.537861469999999953e+00,-1.609810949999999963e+00,-6.388462070000000104e+00,-8.848354340000000207e+00,-3.634320259999999969e+00,-9.283759590000000284e-01,-3.132132770000000122e+00,-5.629084589999999721e+00,-3.132132770000000122e+00,-5.629084589999999721e+00,-6.195121770000000083e+00,1.588476000000000055e-01,3.967128750000000093e+00,-1.002021430000000102e+00,-6.590910430000000098e+00,-7.312054159999999747e+00,5.326878549999999990e+00,4.918355939999999649e+00,-2.519742009999999865e+00,-5.517257690000000103e+00,8.460494880000000162e-01,4.268992420000000010e+00,2.420258759999999842e+00,1.358515499999999987e+00,1.858067039999999892e+00,2.958333249999999914e+00,3.391809229999999786e+00,2.703476910000000011e+00,9.539865260000000013e-01,2.143265720000000041e+00,5.021032810000000346e+00,1.903624179999999999e+00,5.021032810000000346e+00,1.903624179999999999e+00,-3.051850319999999783e+00,-1.849545479999999964e+00,4.691632270000000382e+00,1.065449710000000039e+01,9.940246580000000165e+00,4.451431750000000243e+00,4.804824830000000269e+00,1.113157840000000043e+01,8.758833890000000011e+00,4.149820329999999835e+00,4.081542490000000356e+00,6.083909990000000434e+00,8.532374380000000258e+00,9.193134309999999587e+00,6.477982520000000299e+00,5.954061030000000088e+00,6.661285399999999690e+00,5.769676689999999830e+00,8.847820280000000537e+00,1.080053810000000070e+01,8.045616150000000744e+00,1.013086889999999940e+01,4.071829799999999722e+00,6.400647160000000113e+00,5.898484230000000217e+00,3.546162840000000038e+00,3.404859539999999907e+00,5.914158819999999928e+00,6.770952699999999602e+00,6.297542570000000062e+00,5.352190489999999912e+00,3.880547759999999791e+00,4.687458519999999851e+00,6.791163440000000051e+00,7.504372120000000201e+00,4.036161899999999747e+00,3.154313800000000168e+00,9.421935080000000795e+00,7.504372120000000201e+00,4.036161899999999747e+00,3.154313800000000168e+00,9.421935080000000795e+00,9.792955400000000310e+00,3.927647589999999855e+00,6.656875460000000189e-02,-1.633417010000000058e+00,5.204110619999999798e+00,5.878268720000000336e+00,2.759825230000000129e+00,3.991747619999999941e+00,6.161927219999999927e+00,2.466633560000000003e+00,7.905533909999999942e-01,-1.540626589999999907e-01,8.134760859999999871e-01,6.814191339999999819e+00,9.307859419999999773e+00,3.283840420000000204e+00,-6.797972319999999735e-01,3.822227240000000137e+00,5.863330839999999711e+00,1.911120410000000103e+00,-6.797972319999999735e-01,3.822227240000000137e+00,5.863330839999999711e+00,1.911120410000000103e+00,-1.158525940000000087e+00,-2.133970500000000214e+00,-7.106238599999999961e-01,2.263732430000000129e+00,1.021668079999999978e+00,5.312391520000000478e-01,5.325136180000000330e+00,5.586879249999999963e+00,4.988650379999999829e-01,-1.833490010000000003e+00,2.029793979999999998e+00,6.834146500000000124e+00,4.536229129999999721e+00,2.826196190000000108e+00,-7.053476570000000168e-01,-1.508813259999999934e+00,-2.777996959999999849e-01,3.340744729999999940e+00,4.588912009999999597e+00,2.874394179999999910e+00,6.266440870000000274e+00,-4.892419279999999926e-01,-2.536014320000000044e+00,-1.346344709999999889e+00,1.037027120000000080e+00,6.248605730000000413e+00,5.714610580000000439e+00,-9.319067599999999452e-01,-2.536014320000000044e+00,-1.346344709999999889e+00,1.037027120000000080e+00,6.248605730000000413e+00,5.714610580000000439e+00,-9.319067599999999452e-01,-2.433256629999999809e+00,1.292545199999999950e+00,-4.807972430000000408e+00,3.456444670000000108e-02,3.950632569999999788e+00,1.471043469999999909e+00,-1.779645090000000041e+00,-3.254139180000000131e+00,-3.678401110000000251e-01,9.853631259999999781e-01,-3.787078140000000204e+00,-6.136975770000000274e+00,-4.329471110000000067e+00,2.295802350000000214e+00,4.961725709999999623e+00,1.145185349999999991e+00,3.280451890000000148e-01,1.020465729999999960e+00,-3.370638130000000121e+00,-2.657440900000000106e+00,1.572778819999999911e+00,-3.611574409999999791e+00,-8.749730109999999783e+00,-5.246212009999999815e+00,-2.217923639999999974e+00,-1.940854910000000100e+00,-2.217923639999999974e+00,-1.940854910000000100e+00,-2.476536509999999858e+00,-1.623806719999999926e+00,2.170772550000000134e+00,1.081975099999999967e+00,-3.967940089999999920e+00,-4.893425940000000196e+00,-2.947426559999999807e+00,-3.222779630000000006e-01,2.492130990000000157e+00,1.653410320000000100e+00,-4.458753169999999932e-01,-5.933530930000000536e-01,4.125905329999999815e-01,-5.190798039999999780e-01,4.125905329999999815e-01,-5.190798039999999780e-01,-2.674745319999999982e+00,-3.719275950000000108e+00,-3.923733949999999915e+00,-2.915592189999999917e+00,2.023774620000000191e+00,8.954138759999999309e+00,-6.107605930000000072e+00,1.099606630000000029e+00,2.321293349999999922e+00,-2.384291409999999889e+00,-3.246984780000000126e-01,1.381963250000000087e+00,-1.996176240000000046e+00,-4.665384290000000433e+00,-2.642195459999999940e+00,2.461968419999999824e+00,6.252477169999999695e+00,4.301626680000000036e+00,-2.374229189999999878e+00,-5.072390079999999912e+00,1.504805210000000004e+00,6.333673000000000108e+00,1.504805210000000004e+00,6.333673000000000108e+00,-4.973031580000000229e-01,-7.476308819999999855e+00,-3.210850240000000078e+00,6.070501329999999918e+00,6.700812339999999701e+00,9.408490059999999877e-01,-9.005800629999999307e-02,-1.866547940000000017e+00,-3.529655930000000108e+00,-1.306343669999999957e+00,3.537619349999999940e+00,3.491252659999999786e+00,-2.807728529999999889e+00,-4.574225430000000259e+00,-2.114333390000000090e+00,-3.766932960000000108e+00,-3.203268529999999892e+00,5.169875029999999594e-01,1.352872730000000079e+00,1.546818019999999905e+00,1.729664440000000081e+00,1.108499410000000074e+00,1.729664440000000081e+00,1.108499410000000074e+00,8.533198829999999457e-01,-1.264291880000000035e+00,-3.584090950000000220e+00,-2.905996079999999981e+00,-3.547636509999999799e+00,-5.319283959999999922e+00,7.263483410000000084e-01,6.066461559999999587e+00,1.131690410000000035e+01,3.180265900000000201e+00,-6.550213339999999995e+00,-6.081003189999999670e+00,-1.982461569999999895e+00,-9.980063439999999897e-01,7.536681889999999884e-01,-1.371365069999999964e+00,-6.933786389999999855e+00,-2.481315369999999909e+00,3.402029750000000075e+00,1.744006629999999891e+00,-1.528270009999999957e+00,-1.098298549999999985e+00,2.683839560000000013e+00,-1.646347190000000127e-01,-2.098874149999999938e-01,3.270215750000000199e+00,3.567515129999999868e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00\n","\n","\n","\n","]\n","plotArray(ARR)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kAwJPnj3JpAj"},"outputs":[],"source":["import torch\n","import numpy as np\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","def load_data(path,show_all=False):\n","  folders = os.listdir(path)\n","  my_x=[]\n","  my_y=[]\n","  for Class in folders:\n","    files=os.listdir(path+\"/\"+Class)\n","    for File in files:\n","      # print(path+\"/\"+Class+\"/\"+File, \"is class is:\"+ Class)\n","      CSVData = open(path+\"/\"+Class+\"/\"+File)\n","      Array2d_result = np.loadtxt(CSVData, delimiter=\",\")\n","      if show_all:\n","        print(\"Class:\",Class)\n","        into_graph(Array2d_result)\n","\n","      my_x.append(np.array(Array2d_result))\n","      my_y.append((float(Class)))\n","  into_graph(my_x[0])\n","  tensor_x = torch.Tensor(my_x) # transform to torch tensor\n","  tensor_y = torch.Tensor(np.array(my_y)).type(torch.LongTensor)\n","\n","\n","  return TensorDataset(tensor_x,tensor_y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"meTYyp8davGQ"},"outputs":[],"source":["\n"]},{"cell_type":"markdown","metadata":{"id":"3UY4_zhMKDld"},"source":["###arguments"]},{"cell_type":"code","execution_count":107,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":269,"status":"ok","timestamp":1656837102050,"user":{"displayName":"eli","userId":"04468701451872085663"},"user_tz":-180},"id":"ZI_nvusBJo-J","outputId":"bbccef47-33cf-4b35-d52f-b21d41fe5899"},"outputs":[{"name":"stdout","output_type":"stream","text":["['train', 'validation']\n","['1', '0']\n"]}],"source":["# Hyper-parameters\n","sequence_length =1\n","input_size =1024*2\n","\n","hidden_size = 1024*2\n","\n","\n","\n","#indrnn\n","lr=0.00002\n","time_steps=100\n","nlayer=3\n","no_cuda=False\n","batch_norm=True\n","bidirectional=True\n","log_interval=100\n","model_name=\"IndRNN\"\n","batch_size=1024\n","\n","num_layers = nlayer\n","num_classes = 2\n","num_epochs =15000\n","learning_rate =lr\n","max_lr=0.001\n","grad_clip=0.1\n","\n","\n","RECURRENT_MAX = pow(2, 1 / time_steps)\n","\n","data_dir = './all_2d_paper_p_train_test'\n","print(os.listdir(data_dir))\n","classes = os.listdir(data_dir + \"/train\")\n","print(classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aFwUX_IZa0Wb"},"outputs":[],"source":["#train_dataset = load_data(data_dir+'/train',show_all=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y1vIm2T7OVMT"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"SUfRY9_7KHo-"},"source":["###model"]},{"cell_type":"code","execution_count":102,"metadata":{"executionInfo":{"elapsed":252,"status":"ok","timestamp":1656836765448,"user":{"displayName":"eli","userId":"04468701451872085663"},"user_tz":-180},"id":"CXCDpDynOIUR"},"outputs":[],"source":["class personal_Net(nn.Module):\n","    def __init__(self, input_size, hidden_size, n_layer=2, model=IndRNN,model_is_initialize=False):\n","        super(personal_Net, self).__init__()\n","        self.conv_pre_irnn=torch.nn.Conv1d(1,4,1)\n","\n","      \n","        recurrent_inits = [lambda w: nn.init.uniform_(\n","            w, -RECURRENT_MAX, RECURRENT_MAX)]\n","        for _ in range(1, n_layer):\n","            recurrent_inits.append(lambda w: nn.init.constant_(w, 1))\n","        if model_is_initialize:\n","          self.indrnn=model\n","        else:\n","          self.indrnn = model(\n","              input_size, hidden_size,\n","              n_layer, batch_norm=batch_norm,\n","              bidirectional=bidirectional,\n","              hidden_max_abs=RECURRENT_MAX,\n","              recurrent_inits=recurrent_inits)\n","        \n","\n","        self.conv1=torch.nn.Conv2d(1,16,2)\n","        self.conv2=torch.nn.Conv2d(16,8,1)\n","        self.conv3=torch.nn.Conv2d(8,2,1)\n","        self.conv4=torch.nn.Conv2d(2,1,1)\n","        self.max=nn.MaxPool2d(3, stride=2)\n","        cnn_size= int((hidden_size/2-1))\n","        self.conv_com=torch.nn.Conv2d(1,1,6)\n","        self.fc = nn.Linear( (hidden_size*2+cnn_size)  if bidirectional else (hidden_size*2+cnn_size), num_classes)\n","        self.fc.bias.data.fill_(.1)\n","        self.fc.weight.data.normal_(0,.01)\n","\n","    def forward(self, x,x2d, hidden=None):\n","        y_1=self.conv_pre_irnn(x)\n","        y_1, _ = self.indrnn(y_1, hidden)\n","\n","        y_2=self.conv1(x2d)\n","        y_2=self.conv2(y_2)\n","        y_2=self.conv3(y_2)\n","        y_2=self.conv4(y_2)\n","        # y_2=self.max(y_2)\n","        # y_2=y_2[:,None,:,:]\n","        y_1=y_1[:,-1,:]\n","        y_2=y_2[:,-1,:]\n","        y_2=torch.squeeze(y_2)\n","\n","        y=torch.cat((y_2,y_1),1)\n","        # y = torch.cat(y_1,y_2)\n","        # y=self.conv_com(torch.tensor(y_1,y_2))\n","        return self.fc(y)\n","        # return self.lin(y[-1]).squeeze(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SE5sDGf9wQWF"},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self, input_size, hidden_size, n_layer=2, model=IndRNN,model_is_initialize=False):\n","        super(Net, self).__init__()\n","        recurrent_inits = [lambda w: nn.init.uniform_(\n","            w, -RECURRENT_MAX, RECURRENT_MAX)]\n","        for _ in range(1, n_layer):\n","            recurrent_inits.append(lambda w: nn.init.constant_(w, 1))\n","        if model_is_initialize:\n","          self.indrnn=model\n","        else:\n","          self.indrnn = model(\n","              input_size, hidden_size,\n","              n_layer, batch_norm=batch_norm,\n","              bidirectional=bidirectional,\n","              hidden_max_abs=RECURRENT_MAX,\n","              recurrent_inits=recurrent_inits)\n","        self.lin = nn.Linear(\n","            hidden_size * 2 if bidirectional else hidden_size, 1)\n","        self.fc = nn.Linear( hidden_size * 2 if bidirectional else hidden_size, num_classes)\n","        self.fc.bias.data.fill_(.1)\n","        self.fc.weight.data.normal_(0,.01)\n","    def forward(self, x, hidden=None):\n","        y, _ = self.indrnn(x, hidden)\n","        return self.fc(y[:, -1, :])\n","        # return self.lin(y[-1]).squeeze(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jgdoQjzZ-dCG"},"outputs":[],"source":["import torchvision.models as models\n","class My_nn(nn.Module):\n","  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","    super(My_nn, self).__init__()\n","    input=input_size\n","    self.conv1_bn=nn.BatchNorm1d(1)\n","\n","    self.conv1=torch.nn.Conv1d(1,4,1)\n","    self.conv2=torch.nn.Conv1d(4,16,3)\n","    self.conv3=torch.nn.Conv1d(16,64,3)\n","\n","    self.conv4=torch.nn.Conv1d(64,32,3)\n","    self.conv5=torch.nn.Conv1d(32,16,3)\n","    self.conv6=torch.nn.Conv1d(16,8,3)\n","    self.conv7=torch.nn.Conv1d(8,4,3)\n","    self.conv8=torch.nn.Conv1d(4,2,1)\n","    self.conv9=torch.nn.Conv1d(2,1,1)\n","    self.max=nn.MaxPool1d(3, stride=2)\n","    self.softmax = nn.LogSoftmax()\n","\n","    self.fc = nn.Linear(int((input-2*6)), num_classes)\n","\n","    pass\n","\n","  def forward(self, x):\n","    out=x\n","    out=self.conv1_bn(out)\n","    out=self.conv1(out)\n","    out=self.conv2(out)\n","    out=self.conv3(out)\n","\n","    out=self.conv4(out)\n","    out=self.conv5(out)\n","    out=self.conv6(out)\n","    out=self.conv7(out)\n","    out=self.conv8(out)\n","    out=self.conv9(out)\n","    # out=self.max(out)\n","\n","    out = self.fc(out[:, -1, :])\n","\n","    # out=self.softmax(out)\n","    return out\n","\n","    pass\n","       \n","class _My_nn(nn.Module):\n","  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","    super(_My_nn, self).__init__()\n","    input=input_size\n","\n","    self.conv1_bn=nn.BatchNorm1d(1)\n","    # self.conv1=torch.nn.Conv1d(1,4,5)\n","    # self.conv2=torch.nn.Conv1d(4,16,5)\n","    self.conv1=torch.nn.Conv1d(1,4,1)\n","    self.conv2=torch.nn.Conv1d(4,16,1)\n","    self.conv2_2=torch.nn.Conv1d(16,2,1)\n","    # self.conv1_1=torch.nn.Conv1d(32,1,1)\n","\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers\n","    self.max=nn.MaxPool1d(3, stride=2)\n","\n","\n","    # self.lstm = nn.LSTM(input-8, hidden_size, num_layers, batch_first=True)\n","    self.lstm = nn.LSTM(input, hidden_size, num_layers, batch_first=True)\n","\n","    self.conv2_bn=nn.BatchNorm1d(2)\n","    self.conv3=torch.nn.Conv1d(2,1,1)\n","    # self.conv4=torch.nn.Conv1d(4,2,5)\n","    # self.conv5=torch.nn.Conv1d(2,1,5)\n","    # self.max2=nn.MaxPool1d(3, stride=2)\n","    self.lstm_2 = nn.LSTM(input, hidden_size, num_layers, batch_first=True)\n","    # self.lstm_2 = nn.LSTM(int((input-13)/2), hidden_size, num_layers, batch_first=True)\n","    # self.lstm_2 = nn.LSTM(input-12, hidden_size, num_layers, batch_first=True)\n","\n","    # self.conv5=torch.nn.Conv1d(12,1,1)\n","    self.softmax = nn.Softmax(dim=1)\n","    self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    pass\n","  def forward(self, x):\n","    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n","    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","    out=x\n","\n","    # out=self.conv1_bn(out)\n","    out=self.conv1(out)\n","    out=self.conv2(out)\n","    out=self.conv2_2(out)\n","    # out=self.conv1_1(out)\n","\n","    out, _ = self.lstm(out, (h0, c0))\n","\n","    out=self.conv2_bn(out)\n","    out=self.conv3(out)\n","    # out=self.conv4(out)\n","    # out=self.conv5(out)\n","    # out=self.max2(out)\n","    out, _ = self.lstm_2(out, (h0, c0))\n","\n","    # out=self.conv5(out)\n","    # out=self.softmax(out)\n","    out = self.fc(out[:, -1, :])\n","    return out\n","    pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gA5AUWWToCu3"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PnMIWF3m6xp3"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9QVC5AEd_w-O"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dm_nFfyYVaNo"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JR7zT1i6Jo77"},"outputs":[],"source":["# Recurrent neural network (many-to-one)\n","class RNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(RNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","    \n","    def forward(self, x):\n","        # Set initial hidden and cell states \n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","        \n","        # Forward propagate LSTM\n","        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n","        \n","        # Decode the hidden state of the last time step\n","        out = self.fc(out[:, -1, :])\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"dSifuf46KYVT"},"source":["###Train"]},{"cell_type":"code","execution_count":104,"metadata":{"executionInfo":{"elapsed":241,"status":"ok","timestamp":1656836833878,"user":{"displayName":"eli","userId":"04468701451872085663"},"user_tz":-180},"id":"38baCwPqKbXF"},"outputs":[],"source":["\n","def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']\n","\n","def train(test_loader,train_loader,num_epochs,sequence_length,input_size,model,optimizer,max_lr=0.01,grad_clip=0.1,leraning_decay=False):\n","  # Train the model\n","  if leraning_decay:\n","    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=num_epochs,\n","                                                  steps_per_epoch=len(train_loader))\n","  total_step = len(train_loader)\n","  lrs = []\n","\n","  for epoch in range(num_epochs):\n","      for i, (images, labels) in enumerate(train_loader):\n","\n","\n","          images_1 = images.reshape(-1,sequence_length, input_size).to(device)\n","          # images_2=images.view(int(input_size/2),2)\n","          images_2= images.reshape(-1,int(sequence_length*2),int(input_size/2) ).to(device)\n","          images_2=images_2[:,None,:,:]\n","          labels = labels.to(device)\n","          \n","          # Forward pass\n","          outputs = model(images_1,images_2)\n","          # loss = criterion(outputs, torch.max(labels, 1)[1])\n","          # Backward and optimize\n","          # loss = F.mse_loss(outputs, labels)\n","          loss = criterion(outputs, labels)\n","\n","          loss.backward()\n","          if grad_clip:\n","                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n","          optimizer.step()\n","          optimizer.zero_grad()\n","          current_lr=get_lr(optimizer)\n","          lrs.append(current_lr)\n","          if leraning_decay:\n","            sched.step()\n","          if epoch % 100==0:\n","            testing(model,test_loader)\n","            pass\n","          if epoch % 10 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, lr: {:.6f}' \n","                    .format(epoch+1, num_epochs, i+1, total_step, loss.item(),current_lr))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"49T8Jk935hzo"},"outputs":[],"source":["def train_test_multi(test_loader,train_loader,num_epochs,sequence_length,input_size,\n","                     model_A,optimizer_A,model_name_A,\n","                     max_lr=0.01,grad_clip=0.1,\n","                     model_B=None,optimizer_B=None,model_name_B=None,\n","                     model_C=None,optimizer_C=None,model_name_C=None):\n","  # Train the model\n","  sched_A = torch.optim.lr_scheduler.OneCycleLR(optimizer_A, max_lr, epochs=num_epochs,\n","                                                steps_per_epoch=len(train_loader))\n","  if model_B!=None:\n","    sched_B = torch.optim.lr_scheduler.OneCycleLR(optimizer_B, max_lr, epochs=num_epochs,\n","                                                steps_per_epoch=len(train_loader))\n","  if model_C!=None:\n","    # sched_C = torch.optim.lr_scheduler.OneCycleLR(optimizer_C, max_lr, epochs=num_epochs,\n","    #                                             steps_per_epoch=len(train_loader))    \n","    pass\n","  total_step = len(train_loader)\n","  lrs_A = []\n","  lrs_B = []\n","  lrs_C = []\n","  score_A,score_B,score_C=[],[],[]\n","  for epoch in range(num_epochs):\n","      for i, (images, labels) in enumerate(train_loader):\n","\n","\n","          images = images.reshape(-1,sequence_length, input_size).to(device)\n","\n","\n","          labels = labels.to(device)\n","          \n","          # Forward pass\n","          outputs_A = model_A(images)\n","          if model_B!=None:\n","            outputs_B = model_B(images)\n","            pass\n","          if model_C!=None:\n","            outputs_C = model_C(images)\n","            pass\n","          # loss = criterion(outputs, torch.max(labels, 1)[1])\n","          # Backward and optimize\n","          # loss = F.mse_loss(outputs, labels)\n","\n","          loss_A = criterion(outputs_A, labels)\n","          loss_A.backward()\n","          if grad_clip:\n","                nn.utils.clip_grad_value_(model_A.parameters(), grad_clip)\n","          optimizer_A.step()\n","          optimizer_A.zero_grad()\n","          current_lr_A=get_lr(optimizer_A)\n","          lrs_A.append(current_lr_A)\n","          sched_A.step() \n","               \n","          if model_B!=None:\n","            loss_B = criterion(outputs_B, labels)\n","            loss_B.backward()\n","            if grad_clip:\n","              nn.utils.clip_grad_value_(model_B.parameters(), grad_clip)\n","            optimizer_B.step()\n","            optimizer_B.zero_grad()\n","            current_lr_B=get_lr(optimizer_B)\n","            lrs_B.append(current_lr_B)\n","            sched_B.step()   \n","\n","          if model_C!=None:\n","            loss_C = criterion(outputs_C, labels)\n","            optimizer_C.zero_grad()\n","            loss_C.backward()\n","            if grad_clip:\n","              nn.utils.clip_grad_value_(model_C.parameters(), grad_clip) \n","            optimizer_C.step()\n","            \n","            current_lr_C=get_lr(optimizer_C)\n","            lrs_C.append(current_lr_C)\n","            # sched_C.step()\n","                                              \n","          if epoch % 100==0:\n","            print(\"results on model: \",model_name_A)\n","            score_A.append(testing(model_A,test_loader))\n","            if model_B!=None:\n","              print(\"results on model: \",model_name_B)\n","              score_B.append(testing(model_B,test_loader))\n","            if model_C!=None:\n","              print(\"results on model: \",model_name_C)\n","              score_C.append(testing(model_C,test_loader))\n","\n","\n","            pass\n","          if epoch % 20 == 0:\n","            Str='Epoch [{}/{}], Step [{}/{}]'.format(epoch+1, num_epochs, i+1, total_step)\n","            Str+=  ',Loss of model '+model_name_A+': {:.4f}, lr: {:.6f}'.format(loss_A.item(),current_lr_A)\n","            if model_B!=None:\n","              Str+=',Loss of model '+model_name_B+': {:.4f}, lr: {:.6f}'.format(loss_B.item(),current_lr_B)\n","            if model_C!=None:\n","              Str+=',Loss of model '+model_name_C+': {:.4f}, lr: {:.6f}'.format(loss_C.item(),current_lr_C)\n","            print(Str)   \n","            # print ('Epoch [{}/{}], Step [{}/{}], Loss of model '+model_name_A+': {:.4f}, lr: {:.6f},Loss of model '+model_name_B+': {:.4f}, lr: {:.6f},Loss of model '+model_name_C+': {:.4f}, lr: {:.6f}' \n","            #         .format(epoch+1, num_epochs, i+1, total_step, loss_A.item(),current_lr_A)\n","  print(\"results on model: \",model_name_A)\n","  score_A.append(testing(model_A,test_loader))\n","  if model_B!=None:\n","    print(\"results on model: \",model_name_B)\n","    score_B.append(testing(model_B,test_loader))\n","  if model_C!=None:\n","    print(\"results on model: \",model_name_C)\n","    score_C.append(testing(model_C,test_loader))\n","\n","  print(\"finished\")\n","  return score_A,score_B,score_C"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eUr66It8yUB4"},"outputs":[],"source":["def get_batch():\n","    \"\"\"Generate the adding problem dataset\"\"\"\n","    # Build the first sequence\n","    add_values = torch.rand(\n","        time_steps, batch_size, requires_grad=False\n","    )\n","\n","    # Build the second sequence with one 1 in each half and 0s otherwise\n","    add_indices = torch.zeros_like(add_values)\n","    print(\"add_indices\",add_indices,add_indices.shape)\n","    half = int(time_steps / 2)\n","    for i in range(batch_size):\n","        first_half = np.random.randint(half)\n","        second_half = np.random.randint(half, time_steps)\n","        add_indices[first_half, i] = 1\n","        add_indices[second_half, i] = 1\n","        print(add_indices)\n","\n","    # Zip the values and indices in a third dimension:\n","    # inputs has the shape (time_steps, batch_size, 2)\n","    inputs = torch.stack((add_values, add_indices), dim=-1)\n","    targets = torch.mul(add_values, add_indices).sum(dim=0)\n","    return inputs, targets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wr1meMoOSqoA"},"outputs":[],"source":["\n","\n","def new_train(model,optimizer):\n","  from time import time\n","  # Train the model\n","  model.train()\n","  step = 0\n","  while True:\n","    losses = []\n","    start = time()\n","    for _ in range(log_interval):\n","      # Generate new input data\n","      data, target = get_batch()\n","\n","      if True:\n","        data, target = data.cuda(), target.cuda()\n","      model.zero_grad()\n","      out = model(data)\n","      print(\"out\",out.shape)\n","      loss = F.mse_loss(out, target)\n","      loss.backward()\n","      optimizer.step()\n","      losses.append(loss.item())\n","      step += 1\n","\n","    print(\"MSE after {} iterations: {} ({} sec.)\".format(step, np.mean(losses), time() - start))"]},{"cell_type":"markdown","metadata":{"id":"FWanALjBKZ1p"},"source":["###Test"]},{"cell_type":"code","execution_count":105,"metadata":{"executionInfo":{"elapsed":259,"status":"ok","timestamp":1656836837705,"user":{"displayName":"eli","userId":"04468701451872085663"},"user_tz":-180},"id":"D2ZWhx0pJo5v"},"outputs":[],"source":["# Test the model\n","def testing(model,test_loader):\n","  # model.eval()\n","  with torch.no_grad():\n","      correct = 0\n","      total = 0\n","      for images, labels in test_loader:\n","\n","          images_1 = images.reshape(-1,sequence_length, input_size).to(device)\n","          # images_2=images.view(int(input_size/2),2)\n","          images_2= images.reshape(-1,int(sequence_length*2),int(input_size/2) ).to(device)\n","          images_2=images_2[:,None,:,:]\n","          labels = labels.to(device)\n","          \n","          # Forward pass\n","          outputs = model(images_1,images_2)\n","          _, predicted = torch.max(outputs.data, 1)\n","\n","          total += labels.size(0)\n","\n","          correct += (predicted == labels).sum().item()\n","\n","      # print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total)) \n","      print('Test Accuracy of the model on '+str(total)+' samples is: {}%'.format(100 * correct / total)+', '+str(correct)+' was correct') \n","\n","  return 100 * correct / total"]},{"cell_type":"markdown","metadata":{"id":"89G3anWu7lDw"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"xky_rdR2LIZw"},"source":["###Main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p9nf2oO8cQ9X"},"outputs":[],"source":["def create_raw_model_IRNN(input_size, hidden_size,n_layer):\n","        recurrent_inits = [lambda w: nn.init.uniform_(\n","            w, -RECURRENT_MAX, RECURRENT_MAX)]\n","        for _ in range(1, n_layer):\n","            recurrent_inits.append(lambda w: nn.init.constant_(w, 1))\n","\n","\n","        RE= IndRNN(\n","            input_size, hidden_size,\n","            n_layer, batch_norm=batch_norm,\n","            bidirectional=bidirectional,\n","            hidden_max_abs=RECURRENT_MAX,\n","            recurrent_inits=recurrent_inits)\n","        return RE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cHapD_0TH0sm"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NW4RGmACBhi0"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"PoloH1moJo3k"},"outputs":[{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5wU9fkH8M/DwXlSjya9i1FEo3gCdkRBLAFjBU0EAuIviiVWjBENRo09GiuiYhJrCFGIRECEKImFQ0QFRU4EOaQcJ70f9/z+eGacvb29ujs7uzuf9+u1r9kpO/ud27195ttFVUFEROFVJ+gEEBFRsBgIiIhCjoGAiCjkGAiIiEKOgYCIKOQYCIiIQo6BgEJBRE4SkWVBpyNeItJPRAqDTgdlFgYCyigislJETo/erqrvq+pPgkgTUapjICBKIhGpG3QaiKIxEFAoRBepODmHG0XkMxHZIiKviUhOxP5zRORTEdksIv8TkSMrOfdAEVnmnOdJEfmPiIx29o0Qkf+KyCMiUgzgThHpJiLvikixiGwUkZdEJDcqbbeKyFIR2SQiL0SmzTnmBhHZICJrRWRkQv9YFDoMBBRmFwEYBKALgCMBjAAAETkawPMArgDQHMAzAKaJyAHRJxCRFgCmALjVOXYZgOOjDusDYAWAVgDuBiAA7gXQFsBhADoAuDPqNZcCOANANwCHAPhdxL7WAJoAaAdgFIAnRKRpzS6dyMNAQGH2mKp+r6o/AJgO4Chn+xgAz6jqR6q6X1VfBLAHQN8Y5zgLwBJVnaqqJQAeA7Au6pjvVfXPqlqiqrtUtUBVZ6vqHlUtAvAwgFOiXvO4qq520nY3gGER+/YBmKCq+1R1BoDtAFj/QbXG8koKs8gf7J2wO3QA6ARguIhcHbE/O2J/pLYAVrsrqqoxWvWsjlwRkVYAHgVwEoBGsBuyTZW8ZlXUexc7QScy7Q1jpI2oWpgjICpvNYC7VTU34lFfVV+JcexaAO3dFRGRyHVH9BC/9zjbjlDVxgB+ASsuitQh4nlHAN/X4jqIqoWBgDJRPRHJiXjUNOf7LID/E5E+YhqIyNki0ijGsW8BOEJEznXe5ypYGX5lGsGKc7aISDsAN8U45ioRaS8izQDcBuC1Gl4DUbUxEFAmmgFgV8Tjzpq8WFXzAVwO4HFYkU0BnIrkGMduBHAhgPsBFAPoASAfVqdQkd8D6AVgCyyQTI1xzMsAZsEqmb8B8IeaXANRTQgnpiFKHBGpA6AQwKWqOreW51gJYLSqvpPItBFVhDkCojiJyBkikus0L/0trLz/w4CTRVRtDARE8TsOVnyzEcDPAJyrqruCTRJR9bFoiIgo5JgjICIKubTrUNaiRQvt3Llz0MkgIkorCxcu3KiqLWPtS7tA0LlzZ+Tn5wedDCKitCIiqyrax6IhIqKQYyAgIgo5BgIiopBjICAiCjkGAiKikGMgICIKOQYCIqKQS7t+BBRyH38MLFwItGoFnHde0KkhyggMBJQ+1q0D+vTx1hctAo46quLjiahaWDRE6WOV0zHy3HNt2a9fYEkhyiQMBJQ+vnem7b39dlvu2BFcWogyiK+BQEQGicgyESkQkXEx9o8QkSIR+dR5jPYzPZTm1q+3ZevWwCWXAJ06BZseogzhWx2BiGQBeALAANjUfQtEZJqqLo069DVVHetXOiiDbN9uy0aNgAYNmCMgShA/cwS9ARSo6gpV3QvgVQBDfHw/ynTuD3/9+gwERAnkZyBoB2B1xHqhsy3a+SLymYhMEZEOsU4kImNEJF9E8ouKivxIK6WDHTuAnBwgKwto2NDWOcMeUdyCriyeDqCzqh4JYDaAF2MdpKoTVTVPVfNatow5rwKFwY4dlhMAbFlaCuzeHWyaiDKAn4FgDYDIO/z2zrYfqWqxqu5xVicBOMbH9FC6iw4E7jYiioufgWABgO4i0kVEsgEMBTAt8gARaROxOhjAlz6mh9LV6tVWBMRAQOQL3wKBqpYAGAtgJuwH/nVVXSIiE0RksHPYNSKyREQWA7gGwAi/0kNp6tJLgY4dgaFDgX/+04aWABgIiBLI1yEmVHUGgBlR28ZHPL8VwK1+poHSWEkJ8PLL9vz112155pm2ZCAgShiONUSpa+NGWz7+uLUU6toVGDDAtjVsaEu3bwER1RoDAaWuyJ7E559fdh9zBEQJE3TzUaKKzZljyzZtyu9jICBKGAYCSk07dwI33GDPYw013ayZLZcsSV6aiDIUAwGlps8/t+UNN9iQEtHc1kN33ZW8NBFlKAYCSk3ffWfLyy6LvV8EOMbpf1hampw0EWUoBgJKTYWFtmzfvuJjLr7Ylrt2+Z8eogzGQECpafNmu+vPza34GLfIaOfO5KSJKEMxEFBq2rLF5h2oU8lX1A0EbDlEFBcGAkpNW7cCjRtXfgxzBEQJwUBAqWnrVqBJk8qPYSAgSggGAkpNW7YwR0CUJAwElJqWL6+8xRDAQECUIAwElHqKioBVq4Bjj638OAYCooRgIKDUs3ChLRkIiJKCgYBSz+rVtuzWrfLjGAiIEoKBgFLPpk22dAeWqwgDAVFCMBBQ6tm0CahXL/Zgc5EYCIgSgoGAUs+mTUDTpjbERGWys73jiajWGAgo9axe7Q0zXRk3UDzyiL/pIcpwDASUehYuBHr1qt6xPXsCzZv7mx6iDMdAQKmlpMTmKu7SpXrHn3IKsH+/v2kiynAMBJRaiott2aJF9Y7PyQF27/YvPUQhwEBAqWXjRltWNxAceCADAVGcGAgotbg5gqr6ELhycqxoaN8+/9JElOEYCCi1uH0CGjas3vE5ObZkroCo1hgIKLW4geDAA6t3vHsc5y0mqjUGAkot7g96Vb2KXcwREMWNgYBSixsIapoj4LzFRLXmayAQkUEiskxECkRkXCXHnS8iKiJ5fqaH0kBNi4batLHl99/7kx6iEPAtEIhIFoAnAJwJoAeAYSLSI8ZxjQBcC+Ajv9JCaaSmRUOdOtny9NNtnmMiqjE/cwS9ARSo6gpV3QvgVQBDYhx3F4D7ALCQl4C5c23plv1XpUMH7/mkSYlPD1EI+BkI2gFYHbFe6Gz7kYj0AtBBVd+q7EQiMkZE8kUkv6ioKPEppdQxc6Yt61Tzq1m3rtf34Isv/EkTUYYLrLJYROoAeBjADVUdq6oTVTVPVfNatmzpf+Io+b76yhtNNK+GVUXNmgHDhgF/+Qvw3XeJTxtRhvMzEKwBEJFvR3tnm6sRgJ4A5onISgB9AUxjhXFITZ7sPb/kkpq/fvhw62HMXAFRjfkZCBYA6C4iXUQkG8BQANPcnaq6RVVbqGpnVe0M4EMAg1U138c0UapaE3GPcPTRNX9958625CQ1RDXmWyBQ1RIAYwHMBPAlgNdVdYmITBCRwX69L6WpxYuB006zZb9+NX9906a2ZCAgqrG6fp5cVWcAmBG1bXwFx/bzMy2UwlSB5cuBgQOBI4+s3TncQLB+feLSRRQS7FlMwSsutiEiOnas/Tnq1bOmpLNmJS5dRCHBQEDBKyy0Zbt2lR9XlZNPBti8mKjGGAgoeNu327JJk/jOw0lqiGqFgYCCt3evLbOz4zvPgQdyOGqiWmAgoOAlKhBw/mKiWmEgoOAlMkewe7e1QiKiamMgoOC58w3XqxffedyB6vbsie88RCHDQEDBS2SOAGDxEFENMRBQ8BJZRwCwwpiohhgIKHiJzhEwEBDVCAMBBS9RgcDth7BlS3znIQoZBgIKnhsI4q0szs215ebN8Z2HKGQYCCh4bquheHMEbiDgCKRENcJAQMFLVNGQOwIpcwRENcJAQMFzxxrKyorvPC1a2HLduvjOQxQyDAQUvHnzgKOO8uYsrq0GDYA2bWxuAyKqNgYCCt7mzcAhhyTmXF26AKtWJeZcRCHBQEDB27MHOOCAxJwrNxfYti0x5yIKCQYCCl4iA0HjxsDWrYk5F1FIMBBQ8BIdCNihjKhGGAgoeMwREAWKgYCCl+hAsGuX10mNiKrEQEDBKi0FSkoSFwgOOsiWnMSeqNoYCChY7iQyiQoErVvbkp3KiKqNgYCC5VcgWLMmMecjCgEGAgpWogNBjx42iun8+Yk5H1EIMBBQsBIdCBo1Ajp2BAoLE3M+ohBgIKBgJToQAED9+sDOnYk7H1GGYyCgYDEQEAXO10AgIoNEZJmIFIjIuBj7/09EPheRT0Vkvoj08DM9lIL8CgSct5io2nwLBCKSBeAJAGcC6AFgWIwf+pdV9QhVPQrA/QAe9is9lKKYIyAKnJ85gt4AClR1haruBfAqgCGRB6hq5FgADQCoj+mhVMRAQBS4uj6eux2A1RHrhQD6RB8kIlcBuB5ANoD+PqaHUpEfgeDAAxkIiGog8MpiVX1CVbsBuAXA72IdIyJjRCRfRPKLOHRAZvEjEDRo4E1/SURV8jMQrAHQIWK9vbOtIq8CODfWDlWdqKp5qprXsmXLBCaRAudHIGjVCvjhB2Dv3sSdkyiD+RkIFgDoLiJdRCQbwFAA0yIPEJHuEatnA+Bks2HjRyBo1w5QBaZNq/pYIvIvEKhqCYCxAGYC+BLA66q6REQmiMhg57CxIrJERD6F1RMM9ys9lKKeftqWiQwEhx5qyxEjLCAQUaWqDAQicqGINHKe/05EpopIr+qcXFVnqOohqtpNVe92to1X1WnO82tV9XBVPUpVT1XVJfFcDKWhtWttmcgivxNOAH77W2DHDu/8RFSh6uQIblfVbSJyIoDTATwH4Cl/k0WhUa8ecNFFQE5O4s4pAhxxhD3fvDlx5yXKUNUJBPud5dkAJqrqW7CmnkTx27DBKncTrVEjW27blvhzE2WY6gSCNSLyDICLAcwQkQOq+TqiypWW2h17s2aJP7cbCNiMlKhK1flBvwhW4XuGqm4G0AzATb6misLBnVc4kRXFLuYIiKqtwp7FItLYGQIiB8A8Z1szAHsA5CcldZTZ3Hb+2T6UNDZsaEsGAqIqVZYjeNlZLoT98C+MeDAQUPzcHEG9eok/d8uWQFYWsHhx4s9NlGEqDASqeo6z7KKqXZ2l++iavCRSxvIzR5CbC1xwATBpEnMFRFWoTj+CUVHrWSJyh39JotBwA4EfOQIAuP56YMsWr9MaEcVUncri00Rkhoi0EZGeAD4E0MjndFEYuEVDfuQIAKB3b+Css4DbbwfyWZpJVJEqA4GqXgLgRQCfA3gLwHWqeqPfCaMQ8DtHAAAvvmj9FAYMAL76yr/3IUpj1Ska6g7gWgD/ALAKwC9FpL7fCaMQ8DtHAAAtWgAvvWT9FaZP9+99iNJYdYqGpsOGmbgCwCmwEUIX+JoqCodk5AgA4MQTgebNgW++8fd9iNJUdWYo6+1OKamqCuAhEeGtFcUvGTkCV9u2wLp1/r8PURqqMhCo6lankrgHrHOZ62vfUkXhkKwcAWC9l93AQ0RlVBkInKai/WCBYAaAMwHMB/AXX1NGmS+ZOYJ69ThjGVEFqlNHcAGA0wCsU9WRAH4KoImvqaJwSGaOIDubgYCoAtUJBLtUtRRAiYg0BrABZeciJqqdZOcIWDREFFN1KovzRSQXwLOwcYa2A/jA11RROCQ7R7Bpk//vQ5SGqtOh7EpV3ayqTwMYAGC4U0REFJ9k5giys5kjoMT68kvgxhszYs6LGk0wo6orVfUzvxJDIZPMHAEriynRHnwQeOgh4Pnng05J3DjTGAUn2TkCBgJKJHf8qo8/DjYdCVBhIHAGmuucvKRQ6CS7jiC6aOjzz2100kilpf6nhdLf5s32/QEyoqNiZTmCFwDMEpHbRCQJ/6mUcXbvBqZMAVRtffZsmx/AXQ+yH8GmTcCRRwL9+9tgdN98A4jYZDYrV5Z//YwZQJ8+QEmJ/2ml1Pfhh/Y9btIEWL486NTErbKJaf4OoBeAxrCWQzeKyPXuI2kppPR1333AhRcCJ58M7NkDDBkCXH45MGaM7Q+yH4H7Y//JJ8BhhwEHH+zti5XVHzbMtn/3na/JpDSxerUte/e270Saj2xbVR3BXgA7ABwAm4Mg8kFUuU8+seX8+cDvfw/s2gW0bm25gi++CLbV0HPPld3foQMwdqw9X7Wq/Ou3brXloEH+pI/Si1ukONJpQFlQEFxaEqCyyesHAXgYwDQAvVR1Z9JSRell+3Ybyyfyzn7vXmDmTBv1s7gYuPdeoFs3Kyo6+mhreufeodetTneWOGVnW67EFX0Ht2qVFQ298kr5UUrduz8gI4oBKAG2brXvS+/etr5xY7DpiVNlOYLbAFyoquMYBKhCK1YAjRoBbdqUrWidPdt+eO+/39s2YQLQpYs9v+suu0OvV8/+ofx24IH2fvv323rkj/3ChV4aunUrHwimTLFl69ZA377+p5VS35YtQOPGwEEH2fr//hdseuJUWR3BSaq6JJmJoTR0zTW2LC4GPvrInj/2GHDOOUD79sDQoUBRkZWvX3KJVa7Vr285gp07k1M/ANh7AsAzz9iP/sqVwM9/Dtxyi+VQXNGBQNXmPgYsCLiVhBRuxcX2XW7Y0NbnzQs0OfFiPwKqve++A956C+je3dbXrLGWQhMmWOXrm2/aD3CLFsCxx3qve/ppa33z6KMWDJKhQQNbRuZQhgwB/vjHsjmSbt2smMgttpo/39vXsqUtr7jC37RSalO1VmRHHGHfnV/9KqOLhogq55az33OPLdets8BQXGyVw716xX7doYcmJ32R3BxBt262rFOnbE7AdfDBVsTlVhi/8ootFy604iwAePbZ2BXKFA7r11vzY7fhQNeutr57d7DpioOvgUBEBonIMhEpEJFxMfZfLyJLReQzEZkjIp38TA8l2Lff2rJ3b6uMXb7ccgUAMHBgxa/r0cP/tEVzcwTvvmvLH36wfgTR3EAxbZoFhKeeshxPr15Aq1bA66/bfvc6KXy+dubkcr8rbdvasrAwmPQkgG+BQESyADwBm8imB4BhIhL9C7AIQJ6qHglgCoD7Qelj/XpbtmkD9OsHzJ1ruYK6dYFmzSp+XYMGwMUX2/P7k/SRu4HA1aSCKTXcIPXKK8D779vzjh29/W5/A/fak23bNmDcOGAJq+8Cs8CZst3N8R5+uC0feCBtB6DzM0fQG0CBqq5Q1b0AXgUwJPIAVZ0b0SLpQwDtfUwPJdratfaDX6+eFfd8+61ta93ail4q066dLZM1ImhkIBg/vuLjmjWzCvCFC4Hzz7dtkyZ5+1u3tuXatYlPY3U8/7x11OvXL3n1K1TWqlV2I9Gqla0feaQVD02caN+P114LNn214GcgaAcgogE2Cp1tFRkF4N+xdojIGBHJF5H8oqKiBCaRak3VKoPd5qCdOtnd0OTJ3o9lZbp2teWOHb4lsYy+fa3e4h//sGVlzj7blsXFwLnnAp07e/vcf/6nn05c2pYuBf5SzZlf3XqZjRutUx4l3/bt1mTalZNjObSXX7bmpEOHAued5xWdpoGUqCwWkV8AyAPwQKz9qjpRVfNUNa+l23KDgrVpk90Vn3eerV94obevOoFg1CjgpptsPPdkyM62nICb3sqcfrrd1b3xhgWOSG5O5/PPrad0Ihx+ODB8eMXNUktKrHNecXHZyXU43EUwduzwmo26cnJsGJKlS+17Nn06cOaZwKxZadGiyM9AsAZlp7Rs72wrQ0ROh3VeG6yqe6L3U4pavNiWhx1myw4dgD/8wZ53qkadf06O1Q80bepP+uJRpw5w0UXWvDRWEZfbr8C93ni49RCAlf/Hcs011kJlwgQLBIcdZs0Wp05ln4YgbN9evs7JlZNjOc7nn7cGBWecYZ9Xqg+Brqq+PGDDV6wA0AVANoDFAA6POuZoAN8A6F7d8x5zzDFKKcB+glQ/+8zbVlqqOn++6qZNwaUrGd56y7v+ePXu7Z1rxYry+9eu9fYDqp07qw4apDp2rK2/+278aUi20lLV7duDTkXtnXKKPaqyfbvqQw/Z5zRtmt+pqhKAfK3gd9W3HIGqlgAYC2AmgC8BvK6qS0RkgogMdg57AEBDAH8XkU9FZJpf6aEEiqzgjewTIAKccAKQm5v8NCVTZNFXPK1E9uwBFi3yclXPPlv+mKVLy66vXGl/83vvtb/3O+94+3bsSP0cwv79wIknWmOBTZsszZddZhWwH3xg9R4PPAD8859Bp7RileUIIjVoAPz61/b/MHhwandErChCpOqDOYKAlZaq3nWX3eUMHx50aoLzq1/Z36CgoOz2khLVSy+1fY8/Xvk5/v1vO+6RR2x5+unlj3n88bI5AkD1f/+zfcccY+uzZ6s++qg9v+22xFxfopWU2PLee73reO0177sU67FvX7BpjmXvXtWWLVWHDq3+a5YtU23VSrV7d//SVQ2oJEcQ+A97TR9pEQiWLk3PLHtVNmxQHTbMvjZNmqj+8EPQKQrO22/b32H+/LLbP/yw7I+Z+wMYS9++9nfcsEH15z9XbdNGdcsW1dtvtx+N3r1Vs7JU27ZVfecd75xbttjrV62y9REjvH3169uPVSqZOlW1cWPVO++0awRU69VTbd684iAA2P9RMk2frvryy6r791d8zMKFlrbJk2t27nHj7JoDDG4MBMk0b55qgwb2p12yJOjUJNb556vWras6apTqzp1BpyZYn35qn/Hf/152+9FH2/Yrr7Tln/8c+/X79qnWqaN66622/uqrdvz115f/Qbz5Zjvm9dfL/wDl5XnH5eSUfd3ixYm95pp6+GHVm25SPeGEsul65x3Va6/11q+4wnKa7vrxx9uyX7/kpXX3bu/977674uOmTrVj8vNrdv7XXtMyubkAMBAky6RJZb/wgwcHnaLEWbnSrum004JOSWpYv778D/2OHbatdWvVwkLve7Bhg3fMvfeqHnSQ6gcf2L5nnrHtK1aU/e688IL3fPPmitMxerT3nl9/rXreed7rOnasPEfit1h3+a1a2b6XXrL1tm29u+SPPrJAt327d/y2bclJqxvYAcuJVeRPfyr/mVZHcbEF/vHj40tnHCoLBCnRjyBj3H23LTdutI5WadB+uNrmzrXlrbcGm45U0by5tSV3xy4CbIhqAHj8ca/nNAD88pe23LrV/n4bNni9ld3hKzp3Bo4/3p6fdBIwYgTw9ts2XHdFw2EAwJNPAp9+apWs3btbvwdV4OqrrZ9BrGk3k8Gd98H1t78Bp53m/Y1OO83a2T/7rDcxUe/e1p+iQQPguuts2xtvJCe9buevXr3sb1bRAHLFxbasbAiVWJo1s88nuvI/VVQUIVL1kbI5gq1b7U7ht7+19QsuUD3ssGDTlChffaU/lj9XVn4aNhdeqNqtm7d+5ZVWLLh1q6136uTdZapaGXnk3XFubtkitm3bLIexenX8aSsutrQkqkK/qMiKb6rrm2+867zuupq/35o19trLLqv5a2vDrWe5+mpbvvhi7OPGjrV6ndro21d1wIDapzFOYI4gCe6915YnnGDL3NyyvUDTmXtXNnp01WMIhUnbtjbpDmB3wE8+aWPUu8MPRN/9uTnE3/zGlmedZTOnuRo2tHmT2ydgyK1mzWxyoDlz4j9XcbHNxfDzn1fveFXLyQDAf/8LPPJIzd+zbVvg1FOTNzXo5Mm2/OMfbXnffbGP27y59p0gc3Pt9SmI/9XV4U5cXpn33rOlGwiaNs2MQKBqo102agT86U9Bpya1HHSQfTf27PF+sCJ7Vdevb5PvADal5w8/2NDF998PPPRQ7X4ga+KnP7WhkeMdz2nqVFu++abNMveXv1TcX2HnTgtk55xj624fidro3t0b8hkoX9zkB3cipaVLY1/jpk0MBGlv924bLOy224B/xxzfrryvv7Yy2hdfrPy45ctt/By3PLdlS/uBiBVEVq60H4NkjbxZGz/8YDMvuRO6XHppcuYWTidux7LCQu8ffPjwssf87Ge2/Mc/bFCyrCwrE7/+em++W7+4QemTT2p/jv37gTFjvPVXXrFrfO652MevWAF8/70979w5viFEune33MiGDcCDD9ocwZFDclRl/37rpFZSUvlxqpbTve02W7/9dltG1/GpWn2MOw9BTaVwKUG4AsGjj1pPv3vusWx5RXc1kdw7vREjgDvvtB/D558ve8yUKfZljZxwxc3eR09WkZ9vFcm33AJceWXq9gSdMgV44QX7sWrZ0qsIJ4/7eR98sFeJHt2ruksX+0FzJ7RJ5kBxPXvaMvr7Wl2q3nDbkUVYbdpYz19Vu67I7/hf/+odM3t27d7X5VaeP/64DVC4cydw8snAzTfb0OcilvMoKrKbrmgjRtg53JnEKrJ9u01C5H52bgX+ihXewILvv2/XtmaN/XbURsuWFtiqCkxBqKjyIFUfta4sXrSobEUdoPrXv1b9ushmfJGP/Hxre7xvn7dtzhzvde+9Z9tGj/a2lZaq9u9v27OybDlpUu2ux2+jRqm2aGFpDnufgYrs2mW9gavqBDVggLf/hReSm8ZOnVQHDqz56/LzrV/CiSdauqdPV/31r1Wff96aRffsaf1k3OsaP94qpt31RHU2bNEi9v9f9OPcc8u+btMma64J2NLthBfLf/5jx02caOvr1nmvrVfPOplFvtc339TuWp5+2l5fWFi718cJrCyG12zt9deBa6+155HljxVxs7nPPQfk5Vm2OCvLnufk2J0JYBWpp57qva5vX1tGzp+wZIk1N7zoIm+MmtGjgeOOS72ZjWbNAg45xO66Iu8GyZOTY3e9kcUVsZp6RtYbDB5cfr+fjj8eKCio2Ws2bQJGjrSi1Pnzbduxx1pl+MiRNtLst9/aUNyuCRO84tMXX0zcqLJuMczpp9vd+WWX2Xj/d95Z9rg33rDZ8Vxff213+VdfbcsPPqj4PebNs6U701irVt4Is/v2Wb1IpA4dUCvulJapOE9BRREiVR9xNR91O6fs32935FdeWfVrrrpKtWnTstvef7/8HcnCheVfO3Cg6rHHeutvvGHHfvyxrV93nff6efNqd01++OQTS9OQIUGnJH289JINDRGriaXbWalz5+Sn6/bb7e52z57qv8b9Xvbpo/rYY16nN9f06d731r1zBlQvv7z82EvxWrHC7shj/V1LS61ps3tHP2aMt+/NN23b3Lle+vr2tVKAK68s2wz65ptVs7PLnnvHDtU77rBextH/67W1caOXe6yUKlMAABAQSURBVAoA2LM4hpNPLvsjXRFAtV278ttXrLD23j172jFu2/FII0faa5csUb34YtWzzlIVsTbeqqqzZpX9gtWknbaf3PTMmhV0SjLHJ58k/keyOtxijTvuKL+vpMSGDRk92nolX3mlfWfr1bPvdWVjFg0erD+283/0UftfivU/kCw5Oapnn+2tn3OOpW/16rL9OdzH3LnesVdcYQPJxVJaaoG8sNDOtWhRfOk84ABvyJAkqywQ1A06RxKYE0+0ljs7dlQ8pKyb1TzggPL73CkaP/vMWgZFTl3natvWzjF+vDfT1cCBXq/En/yk7PHz5llLh/79bX3nzvIzIflNIyqvjzsuue+dyY4+Opj3vfBCawUzdao1A87J8fbl53vfy82brYGA6/LLvWLPWNwisOOPt+GVr7km8WmviYEDbZ7p0lJrAeQW+7ZubcWxs2fbNY4bZ9snT7Z5nwH7/62o97aINcN1xdvHo06dlGwgEp46gmh9+ljtfWXzvq5aZUu3k0ksIhV/idq1sx92t4/BFVeUPVf0l6p/f2DAAKuDyMqy4PLKK1VfSyK57d6vuCL5QYgSr25dG87h88/L1/WsXOk9nzLFvm/vvWfl4lX9sLtNnyMDS5BOO81a9PznP3Zz9vXXwPnn2/V37Wrf51tuARYssPqLl17ymvxu2VL5MB6JJGLBKsWENxC0aWPLyMrcaKtX2/KQQ2r3Hu4df1GRNRV9+umyd4Z16tjdyPr13ja3rb7bRG3UKPuiJsPixdbr9aij2Hksk0T2V4js0BTdlHXwYBvnqG41Cgr+8Ae7Cz/33MSkMV6XXGL/O7/4BfDYY7Yt1gRJeXnAv/5lN4F/+5ttW7/eOpElgwhzBCnF/eA3brSJwUW8HIDLHWCqZcvavcepp1priksvtWKoWBo1sn/UWbOAr76yu4Vdu4C33rK7l127vAHK/OYOifDkk6lzp0fxGzbMe75ggS2XLrX2+J062d1z//7e0BfV0a2b/d8k6066Ki1a2P/a9997nd3cgBDt+OPtf+7jj+3/belS6+uRDCwaSjFuIPjiC6/DSXQTM7dXcKzy/+oQsfLZv/2t6qntBgzwchDuj3Benv2jLlpUu/evKbfzUDzDAlDq6dHDu6l5+21buj3rH3zQfgTnzAGOOSaY9CXKbbcBd91lzxs39nrFx3LoodZBLCvLbrbczmt+Y9FQimnY0LKODz3kbRs2DNi2zVvfts0+uOrMT+qX0lIrz3SLh4qK7I5iwwa7o3OLrxJh7VoLQqlyl0eJ06yZVZy63+/vv7c6g/PPDzZdiSQC/O531q/jrbcqP3bUKO95bq71TUgGFg2lGBGv1cAhh3idwdwBtgDLETRsGOyImwcfbMvcXAsGBx1kFd1nn22TfJ90UuIGsioosNZQHFMoMzVsaIFgyRLr9NWmTWZ+1ieeaI/K/PKXNufB8OF2M5Wsv0OKBoLwNh8F7J9h8WLLOjdoYD0LR4ywMtO777Yelo0bB5vGKVNsEhQAeOIJW7rlvIDVa5xzjt0FxftlXr48eWWllHyNGlld1Kuv2npVP5aZTMT/0V9jYR1BCmrc2O6omze3IpF33rHt99xjXdanT/dGmAxKs2ZWiQx4oyOOGFG2O/1//2vN5uJVXGzd6ykz7dtno8oCVv/04IPBpieMWEeQBrp08ZrUjR1rOYJLLw02TYBVIt98sz2vW9cmzWjVyiq33QDw2mtl7zSWLrXrqUlHn61bg88BkX/cYZUPOshylW6xIyVPihYNMRBE69DBOlWtWWPrZ58dbHpcbueu4cO9duF9+9qwvJ06WR8Ft9ncsmVWzLVyJfDnP1sHmlNOsZ7KFdm/3/bXtoUUpb6sLFtOnx5sOsKMRUNp5JprrNXBlCm170yWaO546+4IhpHcES0vv9zuOA491Fs/9VSrTH7vPW/6wFjc1iTMEWSumTNtyIkjjww6JeHFoqE0c9ZZqdW0bsQIq68YMaL8vgcftM40kTMn3XorMHGi/fOPHm3bKmtq6rYzZ44gcx1+uA3Dzs6CwWHREMXl4IOtnX/XruX3ZWdbx7WCAustuXSpVXgDNnDYAw9YscDkydZSon9/Oy6S25IkVo6DiBIjRQNBuJuPZqJjjy2/LTfXxoV58017ADZI15w5lmvo29cmy6hfHzjzzOSmlyhMUrSOgIEgLHr29IYVuOkmyyX06WPrzz1nQSAvLzM7GBGlijDWEYjIIBFZJiIFIjIuxv6TReQTESkRkQv8TEvouS2NrrrKBsA74ghvX3a2zbkQPf0fESVW2IqGRCQLwBMABgAoBLBARKap6tKIw74DMALAjX6lgxwjR1rF8Q032Lo732xenvVFyMqKPQEPESVOigYCP3MEvQEUqOoKVd0L4FUAQyIPUNWVqvoZgNTLK2Wa5s1tliZ3ZjV3sL2nnrJiIQYBIv+laB2Bn4GgHYDI9oqFzrYaE5ExIpIvIvlFlU0kQ9V3/fX2hczLCzolROERxjqCRFHViaqap6p5LWs7SQwRUdBCWDS0BkCHiPX2zjYionAKYdHQAgDdRaSLiGQDGApgmo/vR0SU2sJWNKSqJQDGApgJ4EsAr6vqEhGZICKDAUBEjhWRQgAXAnhGRJb4lR4iosClaNGQrx3KVHUGgBlR28ZHPF8AKzIiIsp8KRoI0qKymIgoI4SwjoCIiCKFrY6AiIiisGiIiCjkWDRERBRyLBoiIgo5Fg0REYUcAwERUcixjoCIKORYR0BEFHIsGiIiCjkGAiKikGMdARFRyLGOgIgo5Fg0REQUciwaIiIKORYNERGFHIuGiIhCjoGAiCjkWEdARBRyrCMgIgo5Fg0REYUci4aIiEKORUNERCHHoiEiopBjICAiCjnWERARhRzrCIiIQo5FQ0REIcdAQEQUcmGsIxCRQSKyTEQKRGRcjP0HiMhrzv6PRKSzn+khIgpU2OoIRCQLwBMAzgTQA8AwEekRddgoAJtU9WAAjwC4z6/0EBEFLkWLhur6eO7eAApUdQUAiMirAIYAWBpxzBAAdzrPpwB4XERENQX/UkRE8apTB1i2DDj88Nq9fvx44OKLE5sm+BsI2gFYHbFeCKBPRceoaomIbAHQHMDGyINEZAyAMQDQsWNHv9JLROSvUaMsGNRW06aJS0sEPwNBwqjqRAATASAvL4+5BSJKT2edZY8U42dl8RoAHSLW2zvbYh4jInUBNAFQ7GOaiIgoip+BYAGA7iLSRUSyAQwFMC3qmGkAhjvPLwDwLusHiIiSy7eiIafMfyyAmQCyADyvqktEZAKAfFWdBuA5AH8VkQIAP8CCBRERJZGvdQSqOgPAjKht4yOe7wZwoZ9pICKiyrFnMRFRyDEQEBGFHAMBEVHIMRAQEYWcpFtrTREpArCqli9vgaheyxkuTNcbpmsFwnW9YbpWwL/r7aSqLWPtSLtAEA8RyVfVvKDTkSxhut4wXSsQrusN07UCwVwvi4aIiEKOgYCIKOTCFggmBp2AJAvT9YbpWoFwXW+YrhUI4HpDVUdARETlhS1HQEREURgIiIhCLjSBQEQGicgyESkQkXFBpydeItJBROaKyFIRWSIi1zrbm4nIbBFZ7iybOttFRB5zrv8zEekV7BXUnIhkicgiEfmXs95FRD5yruk1Z7hziMgBznqBs79zkOmuDRHJFZEpIvKViHwpIsdl+Gf7G+d7/IWIvCIiOZny+YrI8yKyQUS+iNhW489SRIY7xy8XkeGx3qu2QhEIRCQLwBMAzgTQA8AwEekRbKriVgLgBlXtAaAvgKucaxoHYI6qdgcwx1kH7Nq7O48xAJ5KfpLjdi2ALyPW7wPwiKoeDGATgFHO9lEANjnbH3GOSzePAnhbVQ8F8FPYdWfkZysi7QBcAyBPVXvChq0fisz5fCcDGBS1rUafpYg0A3AHbLrf3gDucINHQqhqxj8AHAdgZsT6rQBuDTpdCb7GNwEMALAMQBtnWxsAy5znzwAYFnH8j8elwwM2w90cAP0B/AuAwHpf1o3+jGFzYBznPK/rHCdBX0MNrrUJgG+j05zBn607d3kz5/P6F4AzMunzBdAZwBe1/SwBDAPwTMT2MsfF+whFjgDeF81V6GzLCE7W+GgAHwFopaprnV3rALRynqf73+BPAG4GUOqsNwewWVVLnPXI6/nxWp39W5zj00UXAEUAXnCKwiaJSANk6GerqmsAPAjgOwBrYZ/XQmTu5wvU/LP09TMOSyDIWCLSEMA/AFynqlsj96ndOqR9+2AROQfABlVdGHRakqQugF4AnlLVowHsgFd0ACBzPlsAcIo4hsACYFsADVC+KCVjpcJnGZZAsAZAh4j19s62tCYi9WBB4CVVnepsXi8ibZz9bQBscLan89/gBACDRWQlgFdhxUOPAsgVEXeWvcjr+fFanf1NABQnM8FxKgRQqKofOetTYIEhEz9bADgdwLeqWqSq+wBMhX3mmfr5AjX/LH39jMMSCBYA6O60QsiGVURNCzhNcRERgc35/KWqPhyxaxoAt0XBcFjdgbv9MqdVQl8AWyKypilNVW9V1faq2hn22b2rqpcCmAvgAuew6Gt1/wYXOMenzd2zqq4DsFpEfuJsOg3AUmTgZ+v4DkBfEanvfK/d683Iz9dR089yJoCBItLUyUENdLYlRtCVKEmsrDkLwNcAvgFwW9DpScD1nAjLTn4G4FPncRasrHQOgOUA3gHQzDleYC2nvgHwOayFRuDXUYvr7gfgX87zrgA+BlAA4O8ADnC25zjrBc7+rkGnuxbXeRSAfOfzfQNA00z+bAH8HsBXAL4A8FcAB2TK5wvgFVjdxz5Ybm9UbT5LAL9yrrkAwMhEppFDTBARhVxYioaIiKgCDARERCHHQEBEFHIMBEREIcdAQEQUcgwERBHERnX91hnkC0677W8TMcKliPwv3nMQ+YHNR4miiMjNAA5W1TEi8gyAlap6b9DpIvILcwRE5T0C6+l6Hazj3oOxDhKRN0RkoTOO/hhnWydnvPgWIlJHRN4XkYHOvu3Oso2IvCcinzrj75+UpOsiiok5AqIYROQMAG8DGKiqsys4ppmq/iAiB8KGMTlFVYtFZDRsGOWPYTmLK5zjt6tqQxG5AUCOqt7tzJVRX1W3JeXCiGJgjoAotjNhwwL0rOSYa0RkMYAPYQOCdQcAVZ0EoDGA/wNwY4zXLQAwUkTuBHAEgwAFjYGAKIqIHAWb5KcvgN+4o0RGHdMPNmrmcar6UwCLYGPgQETqw0aHBICG0a9V1fcAnAwbPXKyiFzmw2UQVRsDAVEEZ/TLp2DzO3wH4AHEriNoApsucaeIHAoLGq77ALwEYDyAZ2O8RycA61X1WQCTYENMEwWGgYCorMsBfBdRL/AkgMNE5JSo494GUFdEvgTwR1jxEJzjjgVwn6q+BGCviIyMem0/AItFZBGAi2FzKxAFhpXFREQhxxwBEVHIMRAQEYUcAwERUcgxEBARhRwDARFRyDEQEBGFHAMBEVHI/T8NwuLDZHiGnAAAAABJRU5ErkJggg==\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Test Accuracy of the model on 64 samples is: 48.4375%, 31 was correct\n","Epoch [1/15000], Step [1/1], Loss: 0.7202, lr: 0.000020\n","Epoch [11/15000], Step [1/1], Loss: 0.7056, lr: 0.000020\n","Epoch [21/15000], Step [1/1], Loss: 0.6971, lr: 0.000020\n","Epoch [31/15000], Step [1/1], Loss: 0.6835, lr: 0.000020\n","Epoch [41/15000], Step [1/1], Loss: 0.6876, lr: 0.000020\n","Epoch [51/15000], Step [1/1], Loss: 0.6883, lr: 0.000020\n","Epoch [61/15000], Step [1/1], Loss: 0.6824, lr: 0.000020\n","Epoch [71/15000], Step [1/1], Loss: 0.6781, lr: 0.000020\n","Epoch [81/15000], Step [1/1], Loss: 0.6839, lr: 0.000020\n","Epoch [91/15000], Step [1/1], Loss: 0.6765, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 42.1875%, 27 was correct\n","Epoch [101/15000], Step [1/1], Loss: 0.6936, lr: 0.000020\n","Epoch [111/15000], Step [1/1], Loss: 0.6729, lr: 0.000020\n","Epoch [121/15000], Step [1/1], Loss: 0.6771, lr: 0.000020\n","Epoch [131/15000], Step [1/1], Loss: 0.6705, lr: 0.000020\n","Epoch [141/15000], Step [1/1], Loss: 0.6662, lr: 0.000020\n","Epoch [151/15000], Step [1/1], Loss: 0.6668, lr: 0.000020\n","Epoch [161/15000], Step [1/1], Loss: 0.6610, lr: 0.000020\n","Epoch [171/15000], Step [1/1], Loss: 0.6638, lr: 0.000020\n","Epoch [181/15000], Step [1/1], Loss: 0.6633, lr: 0.000020\n","Epoch [191/15000], Step [1/1], Loss: 0.6549, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 95.3125%, 61 was correct\n","Epoch [201/15000], Step [1/1], Loss: 0.6585, lr: 0.000020\n","Epoch [211/15000], Step [1/1], Loss: 0.6580, lr: 0.000020\n","Epoch [221/15000], Step [1/1], Loss: 0.6497, lr: 0.000020\n","Epoch [231/15000], Step [1/1], Loss: 0.6498, lr: 0.000020\n","Epoch [241/15000], Step [1/1], Loss: 0.6441, lr: 0.000020\n","Epoch [251/15000], Step [1/1], Loss: 0.6409, lr: 0.000020\n","Epoch [261/15000], Step [1/1], Loss: 0.6398, lr: 0.000020\n","Epoch [271/15000], Step [1/1], Loss: 0.6366, lr: 0.000020\n","Epoch [281/15000], Step [1/1], Loss: 0.6328, lr: 0.000020\n","Epoch [291/15000], Step [1/1], Loss: 0.6353, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 81.25%, 52 was correct\n","Epoch [301/15000], Step [1/1], Loss: 0.6376, lr: 0.000020\n","Epoch [311/15000], Step [1/1], Loss: 0.6299, lr: 0.000020\n","Epoch [321/15000], Step [1/1], Loss: 0.6230, lr: 0.000020\n","Epoch [331/15000], Step [1/1], Loss: 0.6263, lr: 0.000020\n","Epoch [341/15000], Step [1/1], Loss: 0.6198, lr: 0.000020\n","Epoch [351/15000], Step [1/1], Loss: 0.6192, lr: 0.000020\n","Epoch [361/15000], Step [1/1], Loss: 0.6199, lr: 0.000020\n","Epoch [371/15000], Step [1/1], Loss: 0.6262, lr: 0.000020\n","Epoch [381/15000], Step [1/1], Loss: 0.6131, lr: 0.000020\n","Epoch [391/15000], Step [1/1], Loss: 0.6104, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 90.625%, 58 was correct\n","Epoch [401/15000], Step [1/1], Loss: 0.6091, lr: 0.000020\n","Epoch [411/15000], Step [1/1], Loss: 0.6074, lr: 0.000020\n","Epoch [421/15000], Step [1/1], Loss: 0.6024, lr: 0.000020\n","Epoch [431/15000], Step [1/1], Loss: 0.6089, lr: 0.000020\n","Epoch [441/15000], Step [1/1], Loss: 0.6039, lr: 0.000020\n","Epoch [451/15000], Step [1/1], Loss: 0.6039, lr: 0.000020\n","Epoch [461/15000], Step [1/1], Loss: 0.5951, lr: 0.000020\n","Epoch [471/15000], Step [1/1], Loss: 0.6061, lr: 0.000020\n","Epoch [481/15000], Step [1/1], Loss: 0.5969, lr: 0.000020\n","Epoch [491/15000], Step [1/1], Loss: 0.5895, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 90.625%, 58 was correct\n","Epoch [501/15000], Step [1/1], Loss: 0.5918, lr: 0.000020\n","Epoch [511/15000], Step [1/1], Loss: 0.5893, lr: 0.000020\n","Epoch [521/15000], Step [1/1], Loss: 0.5917, lr: 0.000020\n","Epoch [531/15000], Step [1/1], Loss: 0.5822, lr: 0.000020\n","Epoch [541/15000], Step [1/1], Loss: 0.5854, lr: 0.000020\n","Epoch [551/15000], Step [1/1], Loss: 0.5875, lr: 0.000020\n","Epoch [561/15000], Step [1/1], Loss: 0.5811, lr: 0.000020\n","Epoch [571/15000], Step [1/1], Loss: 0.5797, lr: 0.000020\n","Epoch [581/15000], Step [1/1], Loss: 0.5784, lr: 0.000020\n","Epoch [591/15000], Step [1/1], Loss: 0.5755, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 85.9375%, 55 was correct\n","Epoch [601/15000], Step [1/1], Loss: 0.5743, lr: 0.000020\n","Epoch [611/15000], Step [1/1], Loss: 0.5722, lr: 0.000020\n","Epoch [621/15000], Step [1/1], Loss: 0.5732, lr: 0.000020\n","Epoch [631/15000], Step [1/1], Loss: 0.5715, lr: 0.000020\n","Epoch [641/15000], Step [1/1], Loss: 0.5699, lr: 0.000020\n","Epoch [651/15000], Step [1/1], Loss: 0.5671, lr: 0.000020\n","Epoch [661/15000], Step [1/1], Loss: 0.5693, lr: 0.000020\n","Epoch [671/15000], Step [1/1], Loss: 0.5691, lr: 0.000020\n","Epoch [681/15000], Step [1/1], Loss: 0.5618, lr: 0.000020\n","Epoch [691/15000], Step [1/1], Loss: 0.5646, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 82.8125%, 53 was correct\n","Epoch [701/15000], Step [1/1], Loss: 0.5613, lr: 0.000020\n","Epoch [711/15000], Step [1/1], Loss: 0.5648, lr: 0.000020\n","Epoch [721/15000], Step [1/1], Loss: 0.5675, lr: 0.000020\n","Epoch [731/15000], Step [1/1], Loss: 0.5607, lr: 0.000020\n","Epoch [741/15000], Step [1/1], Loss: 0.5604, lr: 0.000020\n","Epoch [751/15000], Step [1/1], Loss: 0.5650, lr: 0.000020\n","Epoch [761/15000], Step [1/1], Loss: 0.5657, lr: 0.000020\n","Epoch [771/15000], Step [1/1], Loss: 0.5591, lr: 0.000020\n","Epoch [781/15000], Step [1/1], Loss: 0.5626, lr: 0.000020\n","Epoch [791/15000], Step [1/1], Loss: 0.5550, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","Epoch [801/15000], Step [1/1], Loss: 0.5562, lr: 0.000020\n","Epoch [811/15000], Step [1/1], Loss: 0.5537, lr: 0.000020\n","Epoch [821/15000], Step [1/1], Loss: 0.5545, lr: 0.000020\n","Epoch [831/15000], Step [1/1], Loss: 0.5495, lr: 0.000020\n","Epoch [841/15000], Step [1/1], Loss: 0.5566, lr: 0.000020\n","Epoch [851/15000], Step [1/1], Loss: 0.5514, lr: 0.000020\n","Epoch [861/15000], Step [1/1], Loss: 0.5502, lr: 0.000020\n","Epoch [871/15000], Step [1/1], Loss: 0.5521, lr: 0.000020\n","Epoch [881/15000], Step [1/1], Loss: 0.5494, lr: 0.000020\n","Epoch [891/15000], Step [1/1], Loss: 0.5529, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","Epoch [901/15000], Step [1/1], Loss: 0.5491, lr: 0.000020\n","Epoch [911/15000], Step [1/1], Loss: 0.5479, lr: 0.000020\n","Epoch [921/15000], Step [1/1], Loss: 0.5503, lr: 0.000020\n","Epoch [931/15000], Step [1/1], Loss: 0.5482, lr: 0.000020\n","Epoch [941/15000], Step [1/1], Loss: 0.5452, lr: 0.000020\n","Epoch [951/15000], Step [1/1], Loss: 0.5444, lr: 0.000020\n","Epoch [961/15000], Step [1/1], Loss: 0.5464, lr: 0.000020\n","Epoch [971/15000], Step [1/1], Loss: 0.5440, lr: 0.000020\n","Epoch [981/15000], Step [1/1], Loss: 0.5405, lr: 0.000020\n","Epoch [991/15000], Step [1/1], Loss: 0.5470, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 81.25%, 52 was correct\n","Epoch [1001/15000], Step [1/1], Loss: 0.5417, lr: 0.000020\n","Epoch [1011/15000], Step [1/1], Loss: 0.5410, lr: 0.000020\n","Epoch [1021/15000], Step [1/1], Loss: 0.5413, lr: 0.000020\n","Epoch [1031/15000], Step [1/1], Loss: 0.5399, lr: 0.000020\n","Epoch [1041/15000], Step [1/1], Loss: 0.5371, lr: 0.000020\n","Epoch [1051/15000], Step [1/1], Loss: 0.5359, lr: 0.000020\n","Epoch [1061/15000], Step [1/1], Loss: 0.5393, lr: 0.000020\n","Epoch [1071/15000], Step [1/1], Loss: 0.5375, lr: 0.000020\n","Epoch [1081/15000], Step [1/1], Loss: 0.5361, lr: 0.000020\n","Epoch [1091/15000], Step [1/1], Loss: 0.5338, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 89.0625%, 57 was correct\n","Epoch [1101/15000], Step [1/1], Loss: 0.5388, lr: 0.000020\n","Epoch [1111/15000], Step [1/1], Loss: 0.5368, lr: 0.000020\n","Epoch [1121/15000], Step [1/1], Loss: 0.5357, lr: 0.000020\n","Epoch [1131/15000], Step [1/1], Loss: 0.5358, lr: 0.000020\n","Epoch [1141/15000], Step [1/1], Loss: 0.5347, lr: 0.000020\n","Epoch [1151/15000], Step [1/1], Loss: 0.5332, lr: 0.000020\n","Epoch [1161/15000], Step [1/1], Loss: 0.5354, lr: 0.000020\n","Epoch [1171/15000], Step [1/1], Loss: 0.5333, lr: 0.000020\n","Epoch [1181/15000], Step [1/1], Loss: 0.5306, lr: 0.000020\n","Epoch [1191/15000], Step [1/1], Loss: 0.5317, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 85.9375%, 55 was correct\n","Epoch [1201/15000], Step [1/1], Loss: 0.5333, lr: 0.000020\n","Epoch [1211/15000], Step [1/1], Loss: 0.5321, lr: 0.000020\n","Epoch [1221/15000], Step [1/1], Loss: 0.5311, lr: 0.000020\n","Epoch [1231/15000], Step [1/1], Loss: 0.5301, lr: 0.000020\n","Epoch [1241/15000], Step [1/1], Loss: 0.5293, lr: 0.000020\n","Epoch [1251/15000], Step [1/1], Loss: 0.5314, lr: 0.000020\n","Epoch [1261/15000], Step [1/1], Loss: 0.5296, lr: 0.000020\n","Epoch [1271/15000], Step [1/1], Loss: 0.5284, lr: 0.000020\n","Epoch [1281/15000], Step [1/1], Loss: 0.5250, lr: 0.000020\n","Epoch [1291/15000], Step [1/1], Loss: 0.5284, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 85.9375%, 55 was correct\n","Epoch [1301/15000], Step [1/1], Loss: 0.5231, lr: 0.000020\n","Epoch [1311/15000], Step [1/1], Loss: 0.5264, lr: 0.000020\n","Epoch [1321/15000], Step [1/1], Loss: 0.5359, lr: 0.000020\n","Epoch [1331/15000], Step [1/1], Loss: 0.5208, lr: 0.000020\n","Epoch [1341/15000], Step [1/1], Loss: 0.5241, lr: 0.000020\n","Epoch [1351/15000], Step [1/1], Loss: 0.5237, lr: 0.000020\n","Epoch [1361/15000], Step [1/1], Loss: 0.5203, lr: 0.000020\n","Epoch [1371/15000], Step [1/1], Loss: 0.5211, lr: 0.000020\n","Epoch [1381/15000], Step [1/1], Loss: 0.5184, lr: 0.000020\n","Epoch [1391/15000], Step [1/1], Loss: 0.5199, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 89.0625%, 57 was correct\n","Epoch [1401/15000], Step [1/1], Loss: 0.5245, lr: 0.000020\n","Epoch [1411/15000], Step [1/1], Loss: 0.5187, lr: 0.000020\n","Epoch [1421/15000], Step [1/1], Loss: 0.5187, lr: 0.000020\n","Epoch [1431/15000], Step [1/1], Loss: 0.5171, lr: 0.000020\n","Epoch [1441/15000], Step [1/1], Loss: 0.5170, lr: 0.000020\n","Epoch [1451/15000], Step [1/1], Loss: 0.5166, lr: 0.000020\n","Epoch [1461/15000], Step [1/1], Loss: 0.5184, lr: 0.000020\n","Epoch [1471/15000], Step [1/1], Loss: 0.5153, lr: 0.000020\n","Epoch [1481/15000], Step [1/1], Loss: 0.5145, lr: 0.000020\n","Epoch [1491/15000], Step [1/1], Loss: 0.5101, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 82.8125%, 53 was correct\n","Epoch [1501/15000], Step [1/1], Loss: 0.5207, lr: 0.000020\n","Epoch [1511/15000], Step [1/1], Loss: 0.5112, lr: 0.000020\n","Epoch [1521/15000], Step [1/1], Loss: 0.5109, lr: 0.000020\n","Epoch [1531/15000], Step [1/1], Loss: 0.5128, lr: 0.000020\n","Epoch [1541/15000], Step [1/1], Loss: 0.5116, lr: 0.000020\n","Epoch [1551/15000], Step [1/1], Loss: 0.5107, lr: 0.000020\n","Epoch [1561/15000], Step [1/1], Loss: 0.5098, lr: 0.000020\n","Epoch [1571/15000], Step [1/1], Loss: 0.5127, lr: 0.000020\n","Epoch [1581/15000], Step [1/1], Loss: 0.5128, lr: 0.000020\n","Epoch [1591/15000], Step [1/1], Loss: 0.5094, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 89.0625%, 57 was correct\n","Epoch [1601/15000], Step [1/1], Loss: 0.5096, lr: 0.000020\n","Epoch [1611/15000], Step [1/1], Loss: 0.5130, lr: 0.000020\n","Epoch [1621/15000], Step [1/1], Loss: 0.5058, lr: 0.000020\n","Epoch [1631/15000], Step [1/1], Loss: 0.5076, lr: 0.000020\n","Epoch [1641/15000], Step [1/1], Loss: 0.5065, lr: 0.000020\n","Epoch [1651/15000], Step [1/1], Loss: 0.5075, lr: 0.000020\n","Epoch [1661/15000], Step [1/1], Loss: 0.5051, lr: 0.000020\n","Epoch [1671/15000], Step [1/1], Loss: 0.5052, lr: 0.000020\n","Epoch [1681/15000], Step [1/1], Loss: 0.5038, lr: 0.000020\n","Epoch [1691/15000], Step [1/1], Loss: 0.5031, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 81.25%, 52 was correct\n","Epoch [1701/15000], Step [1/1], Loss: 0.5028, lr: 0.000020\n","Epoch [1711/15000], Step [1/1], Loss: 0.5017, lr: 0.000020\n","Epoch [1721/15000], Step [1/1], Loss: 0.5027, lr: 0.000020\n","Epoch [1731/15000], Step [1/1], Loss: 0.5007, lr: 0.000020\n","Epoch [1741/15000], Step [1/1], Loss: 0.5022, lr: 0.000020\n","Epoch [1751/15000], Step [1/1], Loss: 0.5034, lr: 0.000020\n","Epoch [1761/15000], Step [1/1], Loss: 0.4955, lr: 0.000020\n","Epoch [1771/15000], Step [1/1], Loss: 0.4999, lr: 0.000020\n","Epoch [1781/15000], Step [1/1], Loss: 0.4976, lr: 0.000020\n","Epoch [1791/15000], Step [1/1], Loss: 0.4966, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 87.5%, 56 was correct\n","Epoch [1801/15000], Step [1/1], Loss: 0.4978, lr: 0.000020\n","Epoch [1811/15000], Step [1/1], Loss: 0.4964, lr: 0.000020\n","Epoch [1821/15000], Step [1/1], Loss: 0.4976, lr: 0.000020\n","Epoch [1831/15000], Step [1/1], Loss: 0.4946, lr: 0.000020\n","Epoch [1841/15000], Step [1/1], Loss: 0.4947, lr: 0.000020\n","Epoch [1851/15000], Step [1/1], Loss: 0.5021, lr: 0.000020\n","Epoch [1861/15000], Step [1/1], Loss: 0.4923, lr: 0.000020\n","Epoch [1871/15000], Step [1/1], Loss: 0.4948, lr: 0.000020\n","Epoch [1881/15000], Step [1/1], Loss: 0.4905, lr: 0.000020\n","Epoch [1891/15000], Step [1/1], Loss: 0.4918, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [1901/15000], Step [1/1], Loss: 0.4909, lr: 0.000020\n","Epoch [1911/15000], Step [1/1], Loss: 0.4960, lr: 0.000020\n","Epoch [1921/15000], Step [1/1], Loss: 0.4928, lr: 0.000020\n","Epoch [1931/15000], Step [1/1], Loss: 0.4910, lr: 0.000020\n","Epoch [1941/15000], Step [1/1], Loss: 0.4886, lr: 0.000020\n","Epoch [1951/15000], Step [1/1], Loss: 0.4916, lr: 0.000020\n","Epoch [1961/15000], Step [1/1], Loss: 0.4907, lr: 0.000020\n","Epoch [1971/15000], Step [1/1], Loss: 0.4893, lr: 0.000020\n","Epoch [1981/15000], Step [1/1], Loss: 0.4870, lr: 0.000020\n","Epoch [1991/15000], Step [1/1], Loss: 0.4907, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 90.625%, 58 was correct\n","Epoch [2001/15000], Step [1/1], Loss: 0.4885, lr: 0.000020\n","Epoch [2011/15000], Step [1/1], Loss: 0.4905, lr: 0.000020\n","Epoch [2021/15000], Step [1/1], Loss: 0.4848, lr: 0.000020\n","Epoch [2031/15000], Step [1/1], Loss: 0.4846, lr: 0.000020\n","Epoch [2041/15000], Step [1/1], Loss: 0.4849, lr: 0.000020\n","Epoch [2051/15000], Step [1/1], Loss: 0.4836, lr: 0.000020\n","Epoch [2061/15000], Step [1/1], Loss: 0.4844, lr: 0.000020\n","Epoch [2071/15000], Step [1/1], Loss: 0.4809, lr: 0.000020\n","Epoch [2081/15000], Step [1/1], Loss: 0.4803, lr: 0.000020\n","Epoch [2091/15000], Step [1/1], Loss: 0.4812, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 89.0625%, 57 was correct\n","Epoch [2101/15000], Step [1/1], Loss: 0.4820, lr: 0.000020\n","Epoch [2111/15000], Step [1/1], Loss: 0.4799, lr: 0.000020\n","Epoch [2121/15000], Step [1/1], Loss: 0.4814, lr: 0.000020\n","Epoch [2131/15000], Step [1/1], Loss: 0.4802, lr: 0.000020\n","Epoch [2141/15000], Step [1/1], Loss: 0.4818, lr: 0.000020\n","Epoch [2151/15000], Step [1/1], Loss: 0.4790, lr: 0.000020\n","Epoch [2161/15000], Step [1/1], Loss: 0.4794, lr: 0.000020\n","Epoch [2171/15000], Step [1/1], Loss: 0.4817, lr: 0.000020\n","Epoch [2181/15000], Step [1/1], Loss: 0.4753, lr: 0.000020\n","Epoch [2191/15000], Step [1/1], Loss: 0.4777, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 89.0625%, 57 was correct\n","Epoch [2201/15000], Step [1/1], Loss: 0.4733, lr: 0.000020\n","Epoch [2211/15000], Step [1/1], Loss: 0.4752, lr: 0.000020\n","Epoch [2221/15000], Step [1/1], Loss: 0.4764, lr: 0.000020\n","Epoch [2231/15000], Step [1/1], Loss: 0.4762, lr: 0.000020\n","Epoch [2241/15000], Step [1/1], Loss: 0.4748, lr: 0.000020\n","Epoch [2251/15000], Step [1/1], Loss: 0.4759, lr: 0.000020\n","Epoch [2261/15000], Step [1/1], Loss: 0.4734, lr: 0.000020\n","Epoch [2271/15000], Step [1/1], Loss: 0.4749, lr: 0.000020\n","Epoch [2281/15000], Step [1/1], Loss: 0.4741, lr: 0.000020\n","Epoch [2291/15000], Step [1/1], Loss: 0.4730, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 89.0625%, 57 was correct\n","Epoch [2301/15000], Step [1/1], Loss: 0.4710, lr: 0.000020\n","Epoch [2311/15000], Step [1/1], Loss: 0.4709, lr: 0.000020\n","Epoch [2321/15000], Step [1/1], Loss: 0.4744, lr: 0.000020\n","Epoch [2331/15000], Step [1/1], Loss: 0.4704, lr: 0.000020\n","Epoch [2341/15000], Step [1/1], Loss: 0.4704, lr: 0.000020\n","Epoch [2351/15000], Step [1/1], Loss: 0.4696, lr: 0.000020\n","Epoch [2361/15000], Step [1/1], Loss: 0.4686, lr: 0.000020\n","Epoch [2371/15000], Step [1/1], Loss: 0.4700, lr: 0.000020\n","Epoch [2381/15000], Step [1/1], Loss: 0.4709, lr: 0.000020\n","Epoch [2391/15000], Step [1/1], Loss: 0.4686, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 87.5%, 56 was correct\n","Epoch [2401/15000], Step [1/1], Loss: 0.4673, lr: 0.000020\n","Epoch [2411/15000], Step [1/1], Loss: 0.4654, lr: 0.000020\n","Epoch [2421/15000], Step [1/1], Loss: 0.4671, lr: 0.000020\n","Epoch [2431/15000], Step [1/1], Loss: 0.4663, lr: 0.000020\n","Epoch [2441/15000], Step [1/1], Loss: 0.4656, lr: 0.000020\n","Epoch [2451/15000], Step [1/1], Loss: 0.4645, lr: 0.000020\n","Epoch [2461/15000], Step [1/1], Loss: 0.4670, lr: 0.000020\n","Epoch [2471/15000], Step [1/1], Loss: 0.4643, lr: 0.000020\n","Epoch [2481/15000], Step [1/1], Loss: 0.4663, lr: 0.000020\n","Epoch [2491/15000], Step [1/1], Loss: 0.4628, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 87.5%, 56 was correct\n","Epoch [2501/15000], Step [1/1], Loss: 0.4627, lr: 0.000020\n","Epoch [2511/15000], Step [1/1], Loss: 0.4628, lr: 0.000020\n","Epoch [2521/15000], Step [1/1], Loss: 0.4660, lr: 0.000020\n","Epoch [2531/15000], Step [1/1], Loss: 0.4626, lr: 0.000020\n","Epoch [2541/15000], Step [1/1], Loss: 0.4614, lr: 0.000020\n","Epoch [2551/15000], Step [1/1], Loss: 0.4595, lr: 0.000020\n","Epoch [2561/15000], Step [1/1], Loss: 0.4605, lr: 0.000020\n","Epoch [2571/15000], Step [1/1], Loss: 0.4631, lr: 0.000020\n","Epoch [2581/15000], Step [1/1], Loss: 0.4590, lr: 0.000020\n","Epoch [2591/15000], Step [1/1], Loss: 0.4639, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 89.0625%, 57 was correct\n","Epoch [2601/15000], Step [1/1], Loss: 0.4583, lr: 0.000020\n","Epoch [2611/15000], Step [1/1], Loss: 0.4580, lr: 0.000020\n","Epoch [2621/15000], Step [1/1], Loss: 0.4571, lr: 0.000020\n","Epoch [2631/15000], Step [1/1], Loss: 0.4567, lr: 0.000020\n","Epoch [2641/15000], Step [1/1], Loss: 0.4594, lr: 0.000020\n","Epoch [2651/15000], Step [1/1], Loss: 0.4574, lr: 0.000020\n","Epoch [2661/15000], Step [1/1], Loss: 0.4549, lr: 0.000020\n","Epoch [2671/15000], Step [1/1], Loss: 0.4540, lr: 0.000020\n","Epoch [2681/15000], Step [1/1], Loss: 0.4571, lr: 0.000020\n","Epoch [2691/15000], Step [1/1], Loss: 0.4549, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 89.0625%, 57 was correct\n","Epoch [2701/15000], Step [1/1], Loss: 0.4548, lr: 0.000020\n","Epoch [2711/15000], Step [1/1], Loss: 0.4572, lr: 0.000020\n","Epoch [2721/15000], Step [1/1], Loss: 0.4544, lr: 0.000020\n","Epoch [2731/15000], Step [1/1], Loss: 0.4513, lr: 0.000020\n","Epoch [2741/15000], Step [1/1], Loss: 0.4513, lr: 0.000020\n","Epoch [2751/15000], Step [1/1], Loss: 0.4513, lr: 0.000020\n","Epoch [2761/15000], Step [1/1], Loss: 0.4483, lr: 0.000020\n","Epoch [2771/15000], Step [1/1], Loss: 0.4506, lr: 0.000020\n","Epoch [2781/15000], Step [1/1], Loss: 0.4484, lr: 0.000020\n","Epoch [2791/15000], Step [1/1], Loss: 0.4514, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 71.875%, 46 was correct\n","Epoch [2801/15000], Step [1/1], Loss: 0.4585, lr: 0.000020\n","Epoch [2811/15000], Step [1/1], Loss: 0.4485, lr: 0.000020\n","Epoch [2821/15000], Step [1/1], Loss: 0.4468, lr: 0.000020\n","Epoch [2831/15000], Step [1/1], Loss: 0.4479, lr: 0.000020\n","Epoch [2841/15000], Step [1/1], Loss: 0.4479, lr: 0.000020\n","Epoch [2851/15000], Step [1/1], Loss: 0.4486, lr: 0.000020\n","Epoch [2861/15000], Step [1/1], Loss: 0.4480, lr: 0.000020\n","Epoch [2871/15000], Step [1/1], Loss: 0.4462, lr: 0.000020\n","Epoch [2881/15000], Step [1/1], Loss: 0.4515, lr: 0.000020\n","Epoch [2891/15000], Step [1/1], Loss: 0.4432, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 85.9375%, 55 was correct\n","Epoch [2901/15000], Step [1/1], Loss: 0.4463, lr: 0.000020\n","Epoch [2911/15000], Step [1/1], Loss: 0.4423, lr: 0.000020\n","Epoch [2921/15000], Step [1/1], Loss: 0.4454, lr: 0.000020\n","Epoch [2931/15000], Step [1/1], Loss: 0.4433, lr: 0.000020\n","Epoch [2941/15000], Step [1/1], Loss: 0.4392, lr: 0.000020\n","Epoch [2951/15000], Step [1/1], Loss: 0.4409, lr: 0.000020\n","Epoch [2961/15000], Step [1/1], Loss: 0.4418, lr: 0.000020\n","Epoch [2971/15000], Step [1/1], Loss: 0.4415, lr: 0.000020\n","Epoch [2981/15000], Step [1/1], Loss: 0.4420, lr: 0.000020\n","Epoch [2991/15000], Step [1/1], Loss: 0.4381, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 90.625%, 58 was correct\n","Epoch [3001/15000], Step [1/1], Loss: 0.4331, lr: 0.000020\n","Epoch [3011/15000], Step [1/1], Loss: 0.4419, lr: 0.000020\n","Epoch [3021/15000], Step [1/1], Loss: 0.4377, lr: 0.000020\n","Epoch [3031/15000], Step [1/1], Loss: 0.4385, lr: 0.000020\n","Epoch [3041/15000], Step [1/1], Loss: 0.4368, lr: 0.000020\n","Epoch [3051/15000], Step [1/1], Loss: 0.4375, lr: 0.000020\n","Epoch [3061/15000], Step [1/1], Loss: 0.4360, lr: 0.000020\n","Epoch [3071/15000], Step [1/1], Loss: 0.4397, lr: 0.000020\n","Epoch [3081/15000], Step [1/1], Loss: 0.4335, lr: 0.000020\n","Epoch [3091/15000], Step [1/1], Loss: 0.4345, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 87.5%, 56 was correct\n","Epoch [3101/15000], Step [1/1], Loss: 0.4328, lr: 0.000020\n","Epoch [3111/15000], Step [1/1], Loss: 0.4315, lr: 0.000020\n","Epoch [3121/15000], Step [1/1], Loss: 0.4325, lr: 0.000020\n","Epoch [3131/15000], Step [1/1], Loss: 0.4351, lr: 0.000020\n","Epoch [3141/15000], Step [1/1], Loss: 0.4320, lr: 0.000020\n","Epoch [3151/15000], Step [1/1], Loss: 0.4329, lr: 0.000020\n","Epoch [3161/15000], Step [1/1], Loss: 0.4304, lr: 0.000020\n","Epoch [3171/15000], Step [1/1], Loss: 0.4351, lr: 0.000020\n","Epoch [3181/15000], Step [1/1], Loss: 0.4266, lr: 0.000020\n","Epoch [3191/15000], Step [1/1], Loss: 0.4321, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 90.625%, 58 was correct\n","Epoch [3201/15000], Step [1/1], Loss: 0.4285, lr: 0.000020\n","Epoch [3211/15000], Step [1/1], Loss: 0.4324, lr: 0.000020\n","Epoch [3221/15000], Step [1/1], Loss: 0.4315, lr: 0.000020\n","Epoch [3231/15000], Step [1/1], Loss: 0.4301, lr: 0.000020\n","Epoch [3241/15000], Step [1/1], Loss: 0.4259, lr: 0.000020\n","Epoch [3251/15000], Step [1/1], Loss: 0.4297, lr: 0.000020\n","Epoch [3261/15000], Step [1/1], Loss: 0.4266, lr: 0.000020\n","Epoch [3271/15000], Step [1/1], Loss: 0.4242, lr: 0.000020\n","Epoch [3281/15000], Step [1/1], Loss: 0.4218, lr: 0.000020\n","Epoch [3291/15000], Step [1/1], Loss: 0.4210, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 90.625%, 58 was correct\n","Epoch [3301/15000], Step [1/1], Loss: 0.4360, lr: 0.000020\n","Epoch [3311/15000], Step [1/1], Loss: 0.4238, lr: 0.000020\n","Epoch [3321/15000], Step [1/1], Loss: 0.4219, lr: 0.000020\n","Epoch [3331/15000], Step [1/1], Loss: 0.4228, lr: 0.000020\n","Epoch [3341/15000], Step [1/1], Loss: 0.4229, lr: 0.000020\n","Epoch [3351/15000], Step [1/1], Loss: 0.4199, lr: 0.000020\n","Epoch [3361/15000], Step [1/1], Loss: 0.4200, lr: 0.000020\n","Epoch [3371/15000], Step [1/1], Loss: 0.4196, lr: 0.000020\n","Epoch [3381/15000], Step [1/1], Loss: 0.4189, lr: 0.000020\n","Epoch [3391/15000], Step [1/1], Loss: 0.4187, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [3401/15000], Step [1/1], Loss: 0.4173, lr: 0.000020\n","Epoch [3411/15000], Step [1/1], Loss: 0.4169, lr: 0.000020\n","Epoch [3421/15000], Step [1/1], Loss: 0.4199, lr: 0.000020\n","Epoch [3431/15000], Step [1/1], Loss: 0.4176, lr: 0.000020\n","Epoch [3441/15000], Step [1/1], Loss: 0.4190, lr: 0.000020\n","Epoch [3451/15000], Step [1/1], Loss: 0.4170, lr: 0.000020\n","Epoch [3461/15000], Step [1/1], Loss: 0.4173, lr: 0.000020\n","Epoch [3471/15000], Step [1/1], Loss: 0.4161, lr: 0.000020\n","Epoch [3481/15000], Step [1/1], Loss: 0.4137, lr: 0.000020\n","Epoch [3491/15000], Step [1/1], Loss: 0.4132, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 89.0625%, 57 was correct\n","Epoch [3501/15000], Step [1/1], Loss: 0.4110, lr: 0.000020\n","Epoch [3511/15000], Step [1/1], Loss: 0.4098, lr: 0.000020\n","Epoch [3521/15000], Step [1/1], Loss: 0.4132, lr: 0.000020\n","Epoch [3531/15000], Step [1/1], Loss: 0.4123, lr: 0.000020\n","Epoch [3541/15000], Step [1/1], Loss: 0.4098, lr: 0.000020\n","Epoch [3551/15000], Step [1/1], Loss: 0.4089, lr: 0.000020\n","Epoch [3561/15000], Step [1/1], Loss: 0.4093, lr: 0.000020\n","Epoch [3571/15000], Step [1/1], Loss: 0.4129, lr: 0.000020\n","Epoch [3581/15000], Step [1/1], Loss: 0.4121, lr: 0.000020\n","Epoch [3591/15000], Step [1/1], Loss: 0.4079, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 89.0625%, 57 was correct\n","Epoch [3601/15000], Step [1/1], Loss: 0.4078, lr: 0.000020\n","Epoch [3611/15000], Step [1/1], Loss: 0.4088, lr: 0.000020\n","Epoch [3621/15000], Step [1/1], Loss: 0.4116, lr: 0.000020\n","Epoch [3631/15000], Step [1/1], Loss: 0.4068, lr: 0.000020\n","Epoch [3641/15000], Step [1/1], Loss: 0.4038, lr: 0.000020\n","Epoch [3651/15000], Step [1/1], Loss: 0.4043, lr: 0.000020\n","Epoch [3661/15000], Step [1/1], Loss: 0.4045, lr: 0.000020\n","Epoch [3671/15000], Step [1/1], Loss: 0.4027, lr: 0.000020\n","Epoch [3681/15000], Step [1/1], Loss: 0.4044, lr: 0.000020\n","Epoch [3691/15000], Step [1/1], Loss: 0.4028, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [3701/15000], Step [1/1], Loss: 0.4033, lr: 0.000020\n","Epoch [3711/15000], Step [1/1], Loss: 0.4016, lr: 0.000020\n","Epoch [3721/15000], Step [1/1], Loss: 0.4010, lr: 0.000020\n","Epoch [3731/15000], Step [1/1], Loss: 0.4011, lr: 0.000020\n","Epoch [3741/15000], Step [1/1], Loss: 0.4004, lr: 0.000020\n","Epoch [3751/15000], Step [1/1], Loss: 0.4000, lr: 0.000020\n","Epoch [3761/15000], Step [1/1], Loss: 0.4005, lr: 0.000020\n","Epoch [3771/15000], Step [1/1], Loss: 0.3995, lr: 0.000020\n","Epoch [3781/15000], Step [1/1], Loss: 0.4004, lr: 0.000020\n","Epoch [3791/15000], Step [1/1], Loss: 0.4007, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 89.0625%, 57 was correct\n","Epoch [3801/15000], Step [1/1], Loss: 0.3973, lr: 0.000020\n","Epoch [3811/15000], Step [1/1], Loss: 0.3989, lr: 0.000020\n","Epoch [3821/15000], Step [1/1], Loss: 0.3988, lr: 0.000020\n","Epoch [3831/15000], Step [1/1], Loss: 0.3965, lr: 0.000020\n","Epoch [3841/15000], Step [1/1], Loss: 0.3972, lr: 0.000020\n","Epoch [3851/15000], Step [1/1], Loss: 0.3938, lr: 0.000020\n","Epoch [3861/15000], Step [1/1], Loss: 0.3964, lr: 0.000020\n","Epoch [3871/15000], Step [1/1], Loss: 0.3937, lr: 0.000020\n","Epoch [3881/15000], Step [1/1], Loss: 0.3931, lr: 0.000020\n","Epoch [3891/15000], Step [1/1], Loss: 0.3980, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 87.5%, 56 was correct\n","Epoch [3901/15000], Step [1/1], Loss: 0.3929, lr: 0.000020\n","Epoch [3911/15000], Step [1/1], Loss: 0.3923, lr: 0.000020\n","Epoch [3921/15000], Step [1/1], Loss: 0.3906, lr: 0.000020\n","Epoch [3931/15000], Step [1/1], Loss: 0.3940, lr: 0.000020\n","Epoch [3941/15000], Step [1/1], Loss: 0.3922, lr: 0.000020\n","Epoch [3951/15000], Step [1/1], Loss: 0.3903, lr: 0.000020\n","Epoch [3961/15000], Step [1/1], Loss: 0.3914, lr: 0.000020\n","Epoch [3971/15000], Step [1/1], Loss: 0.3898, lr: 0.000020\n","Epoch [3981/15000], Step [1/1], Loss: 0.3921, lr: 0.000020\n","Epoch [3991/15000], Step [1/1], Loss: 0.3838, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 79.6875%, 51 was correct\n","Epoch [4001/15000], Step [1/1], Loss: 0.3890, lr: 0.000020\n","Epoch [4011/15000], Step [1/1], Loss: 0.3888, lr: 0.000020\n","Epoch [4021/15000], Step [1/1], Loss: 0.3910, lr: 0.000020\n","Epoch [4031/15000], Step [1/1], Loss: 0.3874, lr: 0.000020\n","Epoch [4041/15000], Step [1/1], Loss: 0.3955, lr: 0.000020\n","Epoch [4051/15000], Step [1/1], Loss: 0.3840, lr: 0.000020\n","Epoch [4061/15000], Step [1/1], Loss: 0.3853, lr: 0.000020\n","Epoch [4071/15000], Step [1/1], Loss: 0.3874, lr: 0.000020\n","Epoch [4081/15000], Step [1/1], Loss: 0.3842, lr: 0.000020\n","Epoch [4091/15000], Step [1/1], Loss: 0.3827, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 85.9375%, 55 was correct\n","Epoch [4101/15000], Step [1/1], Loss: 0.3824, lr: 0.000020\n","Epoch [4111/15000], Step [1/1], Loss: 0.3887, lr: 0.000020\n","Epoch [4121/15000], Step [1/1], Loss: 0.3818, lr: 0.000020\n","Epoch [4131/15000], Step [1/1], Loss: 0.3803, lr: 0.000020\n","Epoch [4141/15000], Step [1/1], Loss: 0.3823, lr: 0.000020\n","Epoch [4151/15000], Step [1/1], Loss: 0.3815, lr: 0.000020\n","Epoch [4161/15000], Step [1/1], Loss: 0.3787, lr: 0.000020\n","Epoch [4171/15000], Step [1/1], Loss: 0.3823, lr: 0.000020\n","Epoch [4181/15000], Step [1/1], Loss: 0.3796, lr: 0.000020\n","Epoch [4191/15000], Step [1/1], Loss: 0.3792, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [4201/15000], Step [1/1], Loss: 0.3778, lr: 0.000020\n","Epoch [4211/15000], Step [1/1], Loss: 0.3798, lr: 0.000020\n","Epoch [4221/15000], Step [1/1], Loss: 0.3780, lr: 0.000020\n","Epoch [4231/15000], Step [1/1], Loss: 0.3744, lr: 0.000020\n","Epoch [4241/15000], Step [1/1], Loss: 0.3782, lr: 0.000020\n","Epoch [4251/15000], Step [1/1], Loss: 0.3758, lr: 0.000020\n","Epoch [4261/15000], Step [1/1], Loss: 0.3760, lr: 0.000020\n","Epoch [4271/15000], Step [1/1], Loss: 0.3753, lr: 0.000020\n","Epoch [4281/15000], Step [1/1], Loss: 0.3751, lr: 0.000020\n","Epoch [4291/15000], Step [1/1], Loss: 0.3764, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 79.6875%, 51 was correct\n","Epoch [4301/15000], Step [1/1], Loss: 0.3753, lr: 0.000020\n","Epoch [4311/15000], Step [1/1], Loss: 0.3707, lr: 0.000020\n","Epoch [4321/15000], Step [1/1], Loss: 0.3757, lr: 0.000020\n","Epoch [4331/15000], Step [1/1], Loss: 0.3736, lr: 0.000020\n","Epoch [4341/15000], Step [1/1], Loss: 0.3724, lr: 0.000020\n","Epoch [4351/15000], Step [1/1], Loss: 0.3808, lr: 0.000020\n","Epoch [4361/15000], Step [1/1], Loss: 0.3741, lr: 0.000020\n","Epoch [4371/15000], Step [1/1], Loss: 0.3722, lr: 0.000020\n","Epoch [4381/15000], Step [1/1], Loss: 0.3710, lr: 0.000020\n","Epoch [4391/15000], Step [1/1], Loss: 0.3709, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 81.25%, 52 was correct\n","Epoch [4401/15000], Step [1/1], Loss: 0.3715, lr: 0.000020\n","Epoch [4411/15000], Step [1/1], Loss: 0.3700, lr: 0.000020\n","Epoch [4421/15000], Step [1/1], Loss: 0.3762, lr: 0.000020\n","Epoch [4431/15000], Step [1/1], Loss: 0.3693, lr: 0.000020\n","Epoch [4441/15000], Step [1/1], Loss: 0.3688, lr: 0.000020\n","Epoch [4451/15000], Step [1/1], Loss: 0.3678, lr: 0.000020\n","Epoch [4461/15000], Step [1/1], Loss: 0.3673, lr: 0.000020\n","Epoch [4471/15000], Step [1/1], Loss: 0.3672, lr: 0.000020\n","Epoch [4481/15000], Step [1/1], Loss: 0.3673, lr: 0.000020\n","Epoch [4491/15000], Step [1/1], Loss: 0.3687, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 78.125%, 50 was correct\n","Epoch [4501/15000], Step [1/1], Loss: 0.3696, lr: 0.000020\n","Epoch [4511/15000], Step [1/1], Loss: 0.3651, lr: 0.000020\n","Epoch [4521/15000], Step [1/1], Loss: 0.3683, lr: 0.000020\n","Epoch [4531/15000], Step [1/1], Loss: 0.3656, lr: 0.000020\n","Epoch [4541/15000], Step [1/1], Loss: 0.3658, lr: 0.000020\n","Epoch [4551/15000], Step [1/1], Loss: 0.3665, lr: 0.000020\n","Epoch [4561/15000], Step [1/1], Loss: 0.3618, lr: 0.000020\n","Epoch [4571/15000], Step [1/1], Loss: 0.3654, lr: 0.000020\n","Epoch [4581/15000], Step [1/1], Loss: 0.3644, lr: 0.000020\n","Epoch [4591/15000], Step [1/1], Loss: 0.3672, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 81.25%, 52 was correct\n","Epoch [4601/15000], Step [1/1], Loss: 0.3648, lr: 0.000020\n","Epoch [4611/15000], Step [1/1], Loss: 0.3634, lr: 0.000020\n","Epoch [4621/15000], Step [1/1], Loss: 0.3681, lr: 0.000020\n","Epoch [4631/15000], Step [1/1], Loss: 0.3663, lr: 0.000020\n","Epoch [4641/15000], Step [1/1], Loss: 0.3637, lr: 0.000020\n","Epoch [4651/15000], Step [1/1], Loss: 0.3614, lr: 0.000020\n","Epoch [4661/15000], Step [1/1], Loss: 0.3599, lr: 0.000020\n","Epoch [4671/15000], Step [1/1], Loss: 0.3612, lr: 0.000020\n","Epoch [4681/15000], Step [1/1], Loss: 0.3606, lr: 0.000020\n","Epoch [4691/15000], Step [1/1], Loss: 0.3564, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 78.125%, 50 was correct\n","Epoch [4701/15000], Step [1/1], Loss: 0.3600, lr: 0.000020\n","Epoch [4711/15000], Step [1/1], Loss: 0.3592, lr: 0.000020\n","Epoch [4721/15000], Step [1/1], Loss: 0.3612, lr: 0.000020\n","Epoch [4731/15000], Step [1/1], Loss: 0.3588, lr: 0.000020\n","Epoch [4741/15000], Step [1/1], Loss: 0.3586, lr: 0.000020\n","Epoch [4751/15000], Step [1/1], Loss: 0.3576, lr: 0.000020\n","Epoch [4761/15000], Step [1/1], Loss: 0.3592, lr: 0.000020\n","Epoch [4771/15000], Step [1/1], Loss: 0.3557, lr: 0.000020\n","Epoch [4781/15000], Step [1/1], Loss: 0.3600, lr: 0.000020\n","Epoch [4791/15000], Step [1/1], Loss: 0.3567, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 82.8125%, 53 was correct\n","Epoch [4801/15000], Step [1/1], Loss: 0.3540, lr: 0.000020\n","Epoch [4811/15000], Step [1/1], Loss: 0.3565, lr: 0.000020\n","Epoch [4821/15000], Step [1/1], Loss: 0.3596, lr: 0.000020\n","Epoch [4831/15000], Step [1/1], Loss: 0.3564, lr: 0.000020\n","Epoch [4841/15000], Step [1/1], Loss: 0.3551, lr: 0.000020\n","Epoch [4851/15000], Step [1/1], Loss: 0.3549, lr: 0.000020\n","Epoch [4861/15000], Step [1/1], Loss: 0.3572, lr: 0.000020\n","Epoch [4871/15000], Step [1/1], Loss: 0.3531, lr: 0.000020\n","Epoch [4881/15000], Step [1/1], Loss: 0.3570, lr: 0.000020\n","Epoch [4891/15000], Step [1/1], Loss: 0.3593, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 81.25%, 52 was correct\n","Epoch [4901/15000], Step [1/1], Loss: 0.3536, lr: 0.000020\n","Epoch [4911/15000], Step [1/1], Loss: 0.3540, lr: 0.000020\n","Epoch [4921/15000], Step [1/1], Loss: 0.3552, lr: 0.000020\n","Epoch [4931/15000], Step [1/1], Loss: 0.3519, lr: 0.000020\n","Epoch [4941/15000], Step [1/1], Loss: 0.3522, lr: 0.000020\n","Epoch [4951/15000], Step [1/1], Loss: 0.3521, lr: 0.000020\n","Epoch [4961/15000], Step [1/1], Loss: 0.3526, lr: 0.000020\n","Epoch [4971/15000], Step [1/1], Loss: 0.3501, lr: 0.000020\n","Epoch [4981/15000], Step [1/1], Loss: 0.3524, lr: 0.000020\n","Epoch [4991/15000], Step [1/1], Loss: 0.3516, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 81.25%, 52 was correct\n","Epoch [5001/15000], Step [1/1], Loss: 0.3513, lr: 0.000020\n","Epoch [5011/15000], Step [1/1], Loss: 0.3530, lr: 0.000020\n","Epoch [5021/15000], Step [1/1], Loss: 0.3504, lr: 0.000020\n","Epoch [5031/15000], Step [1/1], Loss: 0.3543, lr: 0.000020\n","Epoch [5041/15000], Step [1/1], Loss: 0.3491, lr: 0.000020\n","Epoch [5051/15000], Step [1/1], Loss: 0.3502, lr: 0.000020\n","Epoch [5061/15000], Step [1/1], Loss: 0.3526, lr: 0.000020\n","Epoch [5071/15000], Step [1/1], Loss: 0.3500, lr: 0.000020\n","Epoch [5081/15000], Step [1/1], Loss: 0.3489, lr: 0.000020\n","Epoch [5091/15000], Step [1/1], Loss: 0.3478, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 85.9375%, 55 was correct\n","Epoch [5101/15000], Step [1/1], Loss: 0.3564, lr: 0.000020\n","Epoch [5111/15000], Step [1/1], Loss: 0.3517, lr: 0.000020\n","Epoch [5121/15000], Step [1/1], Loss: 0.3476, lr: 0.000020\n","Epoch [5131/15000], Step [1/1], Loss: 0.3480, lr: 0.000020\n","Epoch [5141/15000], Step [1/1], Loss: 0.3468, lr: 0.000020\n","Epoch [5151/15000], Step [1/1], Loss: 0.3484, lr: 0.000020\n","Epoch [5161/15000], Step [1/1], Loss: 0.3500, lr: 0.000020\n","Epoch [5171/15000], Step [1/1], Loss: 0.3460, lr: 0.000020\n","Epoch [5181/15000], Step [1/1], Loss: 0.3501, lr: 0.000020\n","Epoch [5191/15000], Step [1/1], Loss: 0.3462, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [5201/15000], Step [1/1], Loss: 0.3464, lr: 0.000020\n","Epoch [5211/15000], Step [1/1], Loss: 0.3464, lr: 0.000020\n","Epoch [5221/15000], Step [1/1], Loss: 0.3453, lr: 0.000020\n","Epoch [5231/15000], Step [1/1], Loss: 0.3432, lr: 0.000020\n","Epoch [5241/15000], Step [1/1], Loss: 0.3455, lr: 0.000020\n","Epoch [5251/15000], Step [1/1], Loss: 0.3451, lr: 0.000020\n","Epoch [5261/15000], Step [1/1], Loss: 0.3446, lr: 0.000020\n","Epoch [5271/15000], Step [1/1], Loss: 0.3463, lr: 0.000020\n","Epoch [5281/15000], Step [1/1], Loss: 0.3426, lr: 0.000020\n","Epoch [5291/15000], Step [1/1], Loss: 0.3444, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 82.8125%, 53 was correct\n","Epoch [5301/15000], Step [1/1], Loss: 0.3486, lr: 0.000020\n","Epoch [5311/15000], Step [1/1], Loss: 0.3433, lr: 0.000020\n","Epoch [5321/15000], Step [1/1], Loss: 0.3447, lr: 0.000020\n","Epoch [5331/15000], Step [1/1], Loss: 0.3426, lr: 0.000020\n","Epoch [5341/15000], Step [1/1], Loss: 0.3435, lr: 0.000020\n","Epoch [5351/15000], Step [1/1], Loss: 0.3428, lr: 0.000020\n","Epoch [5361/15000], Step [1/1], Loss: 0.3423, lr: 0.000020\n","Epoch [5371/15000], Step [1/1], Loss: 0.3404, lr: 0.000020\n","Epoch [5381/15000], Step [1/1], Loss: 0.3444, lr: 0.000020\n","Epoch [5391/15000], Step [1/1], Loss: 0.3463, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [5401/15000], Step [1/1], Loss: 0.3401, lr: 0.000020\n","Epoch [5411/15000], Step [1/1], Loss: 0.3422, lr: 0.000020\n","Epoch [5421/15000], Step [1/1], Loss: 0.3391, lr: 0.000020\n","Epoch [5431/15000], Step [1/1], Loss: 0.3419, lr: 0.000020\n","Epoch [5441/15000], Step [1/1], Loss: 0.3421, lr: 0.000020\n","Epoch [5451/15000], Step [1/1], Loss: 0.3397, lr: 0.000020\n","Epoch [5461/15000], Step [1/1], Loss: 0.3367, lr: 0.000020\n","Epoch [5471/15000], Step [1/1], Loss: 0.3396, lr: 0.000020\n","Epoch [5481/15000], Step [1/1], Loss: 0.3424, lr: 0.000020\n","Epoch [5491/15000], Step [1/1], Loss: 0.3468, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [5501/15000], Step [1/1], Loss: 0.3389, lr: 0.000020\n","Epoch [5511/15000], Step [1/1], Loss: 0.3413, lr: 0.000020\n","Epoch [5521/15000], Step [1/1], Loss: 0.3397, lr: 0.000020\n","Epoch [5531/15000], Step [1/1], Loss: 0.3386, lr: 0.000020\n","Epoch [5541/15000], Step [1/1], Loss: 0.3373, lr: 0.000020\n","Epoch [5551/15000], Step [1/1], Loss: 0.3391, lr: 0.000020\n","Epoch [5561/15000], Step [1/1], Loss: 0.3380, lr: 0.000020\n","Epoch [5571/15000], Step [1/1], Loss: 0.3383, lr: 0.000020\n","Epoch [5581/15000], Step [1/1], Loss: 0.3389, lr: 0.000020\n","Epoch [5591/15000], Step [1/1], Loss: 0.3409, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 87.5%, 56 was correct\n","Epoch [5601/15000], Step [1/1], Loss: 0.3368, lr: 0.000020\n","Epoch [5611/15000], Step [1/1], Loss: 0.3371, lr: 0.000020\n","Epoch [5621/15000], Step [1/1], Loss: 0.3374, lr: 0.000020\n","Epoch [5631/15000], Step [1/1], Loss: 0.3389, lr: 0.000020\n","Epoch [5641/15000], Step [1/1], Loss: 0.3354, lr: 0.000020\n","Epoch [5651/15000], Step [1/1], Loss: 0.3347, lr: 0.000020\n","Epoch [5661/15000], Step [1/1], Loss: 0.3380, lr: 0.000020\n","Epoch [5671/15000], Step [1/1], Loss: 0.3359, lr: 0.000020\n","Epoch [5681/15000], Step [1/1], Loss: 0.3333, lr: 0.000020\n","Epoch [5691/15000], Step [1/1], Loss: 0.3372, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 81.25%, 52 was correct\n","Epoch [5701/15000], Step [1/1], Loss: 0.3374, lr: 0.000020\n","Epoch [5711/15000], Step [1/1], Loss: 0.3338, lr: 0.000020\n","Epoch [5721/15000], Step [1/1], Loss: 0.3354, lr: 0.000020\n","Epoch [5731/15000], Step [1/1], Loss: 0.3344, lr: 0.000020\n","Epoch [5741/15000], Step [1/1], Loss: 0.3344, lr: 0.000020\n","Epoch [5751/15000], Step [1/1], Loss: 0.3367, lr: 0.000020\n","Epoch [5761/15000], Step [1/1], Loss: 0.3347, lr: 0.000020\n","Epoch [5771/15000], Step [1/1], Loss: 0.3332, lr: 0.000020\n","Epoch [5781/15000], Step [1/1], Loss: 0.3366, lr: 0.000020\n","Epoch [5791/15000], Step [1/1], Loss: 0.3315, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 85.9375%, 55 was correct\n","Epoch [5801/15000], Step [1/1], Loss: 0.3363, lr: 0.000020\n","Epoch [5811/15000], Step [1/1], Loss: 0.3342, lr: 0.000020\n","Epoch [5821/15000], Step [1/1], Loss: 0.3335, lr: 0.000020\n","Epoch [5831/15000], Step [1/1], Loss: 0.3319, lr: 0.000020\n","Epoch [5841/15000], Step [1/1], Loss: 0.3329, lr: 0.000020\n","Epoch [5851/15000], Step [1/1], Loss: 0.3328, lr: 0.000020\n","Epoch [5861/15000], Step [1/1], Loss: 0.3314, lr: 0.000020\n","Epoch [5871/15000], Step [1/1], Loss: 0.3338, lr: 0.000020\n","Epoch [5881/15000], Step [1/1], Loss: 0.3327, lr: 0.000020\n","Epoch [5891/15000], Step [1/1], Loss: 0.3322, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 87.5%, 56 was correct\n","Epoch [5901/15000], Step [1/1], Loss: 0.3319, lr: 0.000020\n","Epoch [5911/15000], Step [1/1], Loss: 0.3322, lr: 0.000020\n","Epoch [5921/15000], Step [1/1], Loss: 0.3328, lr: 0.000020\n","Epoch [5931/15000], Step [1/1], Loss: 0.3307, lr: 0.000020\n","Epoch [5941/15000], Step [1/1], Loss: 0.3302, lr: 0.000020\n","Epoch [5951/15000], Step [1/1], Loss: 0.3304, lr: 0.000020\n","Epoch [5961/15000], Step [1/1], Loss: 0.3312, lr: 0.000020\n","Epoch [5971/15000], Step [1/1], Loss: 0.3306, lr: 0.000020\n","Epoch [5981/15000], Step [1/1], Loss: 0.3286, lr: 0.000020\n","Epoch [5991/15000], Step [1/1], Loss: 0.3309, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 87.5%, 56 was correct\n","Epoch [6001/15000], Step [1/1], Loss: 0.3322, lr: 0.000020\n","Epoch [6011/15000], Step [1/1], Loss: 0.3303, lr: 0.000020\n","Epoch [6021/15000], Step [1/1], Loss: 0.3290, lr: 0.000020\n","Epoch [6031/15000], Step [1/1], Loss: 0.3299, lr: 0.000020\n","Epoch [6041/15000], Step [1/1], Loss: 0.3295, lr: 0.000020\n","Epoch [6051/15000], Step [1/1], Loss: 0.3277, lr: 0.000020\n","Epoch [6061/15000], Step [1/1], Loss: 0.3316, lr: 0.000020\n","Epoch [6071/15000], Step [1/1], Loss: 0.3300, lr: 0.000020\n","Epoch [6081/15000], Step [1/1], Loss: 0.3337, lr: 0.000020\n","Epoch [6091/15000], Step [1/1], Loss: 0.3283, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 85.9375%, 55 was correct\n","Epoch [6101/15000], Step [1/1], Loss: 0.3285, lr: 0.000020\n","Epoch [6111/15000], Step [1/1], Loss: 0.3296, lr: 0.000020\n","Epoch [6121/15000], Step [1/1], Loss: 0.3289, lr: 0.000020\n","Epoch [6131/15000], Step [1/1], Loss: 0.3290, lr: 0.000020\n","Epoch [6141/15000], Step [1/1], Loss: 0.3280, lr: 0.000020\n","Epoch [6151/15000], Step [1/1], Loss: 0.3277, lr: 0.000020\n","Epoch [6161/15000], Step [1/1], Loss: 0.3276, lr: 0.000020\n","Epoch [6171/15000], Step [1/1], Loss: 0.3284, lr: 0.000020\n","Epoch [6181/15000], Step [1/1], Loss: 0.3257, lr: 0.000020\n","Epoch [6191/15000], Step [1/1], Loss: 0.3268, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 82.8125%, 53 was correct\n","Epoch [6201/15000], Step [1/1], Loss: 0.3240, lr: 0.000020\n","Epoch [6211/15000], Step [1/1], Loss: 0.3281, lr: 0.000020\n","Epoch [6221/15000], Step [1/1], Loss: 0.3250, lr: 0.000020\n","Epoch [6231/15000], Step [1/1], Loss: 0.3313, lr: 0.000020\n","Epoch [6241/15000], Step [1/1], Loss: 0.3270, lr: 0.000020\n","Epoch [6251/15000], Step [1/1], Loss: 0.3234, lr: 0.000020\n","Epoch [6261/15000], Step [1/1], Loss: 0.3273, lr: 0.000020\n","Epoch [6271/15000], Step [1/1], Loss: 0.3247, lr: 0.000020\n","Epoch [6281/15000], Step [1/1], Loss: 0.3269, lr: 0.000020\n","Epoch [6291/15000], Step [1/1], Loss: 0.3252, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 87.5%, 56 was correct\n","Epoch [6301/15000], Step [1/1], Loss: 0.3278, lr: 0.000020\n","Epoch [6311/15000], Step [1/1], Loss: 0.3266, lr: 0.000020\n","Epoch [6321/15000], Step [1/1], Loss: 0.3274, lr: 0.000020\n","Epoch [6331/15000], Step [1/1], Loss: 0.3262, lr: 0.000020\n","Epoch [6341/15000], Step [1/1], Loss: 0.3274, lr: 0.000020\n","Epoch [6351/15000], Step [1/1], Loss: 0.3239, lr: 0.000020\n","Epoch [6361/15000], Step [1/1], Loss: 0.3247, lr: 0.000020\n","Epoch [6371/15000], Step [1/1], Loss: 0.3251, lr: 0.000020\n","Epoch [6381/15000], Step [1/1], Loss: 0.3233, lr: 0.000020\n","Epoch [6391/15000], Step [1/1], Loss: 0.3234, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 87.5%, 56 was correct\n","Epoch [6401/15000], Step [1/1], Loss: 0.3229, lr: 0.000020\n","Epoch [6411/15000], Step [1/1], Loss: 0.3221, lr: 0.000020\n","Epoch [6421/15000], Step [1/1], Loss: 0.3250, lr: 0.000020\n","Epoch [6431/15000], Step [1/1], Loss: 0.3230, lr: 0.000020\n","Epoch [6441/15000], Step [1/1], Loss: 0.3203, lr: 0.000020\n","Epoch [6451/15000], Step [1/1], Loss: 0.3210, lr: 0.000020\n","Epoch [6461/15000], Step [1/1], Loss: 0.3229, lr: 0.000020\n","Epoch [6471/15000], Step [1/1], Loss: 0.3218, lr: 0.000020\n","Epoch [6481/15000], Step [1/1], Loss: 0.3252, lr: 0.000020\n","Epoch [6491/15000], Step [1/1], Loss: 0.3221, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 82.8125%, 53 was correct\n","Epoch [6501/15000], Step [1/1], Loss: 0.3237, lr: 0.000020\n","Epoch [6511/15000], Step [1/1], Loss: 0.3232, lr: 0.000020\n","Epoch [6521/15000], Step [1/1], Loss: 0.3205, lr: 0.000020\n","Epoch [6531/15000], Step [1/1], Loss: 0.3214, lr: 0.000020\n","Epoch [6541/15000], Step [1/1], Loss: 0.3236, lr: 0.000020\n","Epoch [6551/15000], Step [1/1], Loss: 0.3244, lr: 0.000020\n","Epoch [6561/15000], Step [1/1], Loss: 0.3214, lr: 0.000020\n","Epoch [6571/15000], Step [1/1], Loss: 0.3233, lr: 0.000020\n","Epoch [6581/15000], Step [1/1], Loss: 0.3215, lr: 0.000020\n","Epoch [6591/15000], Step [1/1], Loss: 0.3224, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 87.5%, 56 was correct\n","Epoch [6601/15000], Step [1/1], Loss: 0.3202, lr: 0.000020\n","Epoch [6611/15000], Step [1/1], Loss: 0.3225, lr: 0.000020\n","Epoch [6621/15000], Step [1/1], Loss: 0.3197, lr: 0.000020\n","Epoch [6631/15000], Step [1/1], Loss: 0.3230, lr: 0.000020\n","Epoch [6641/15000], Step [1/1], Loss: 0.3247, lr: 0.000020\n","Epoch [6651/15000], Step [1/1], Loss: 0.3225, lr: 0.000020\n","Epoch [6661/15000], Step [1/1], Loss: 0.3237, lr: 0.000020\n","Epoch [6671/15000], Step [1/1], Loss: 0.3199, lr: 0.000020\n","Epoch [6681/15000], Step [1/1], Loss: 0.3192, lr: 0.000020\n","Epoch [6691/15000], Step [1/1], Loss: 0.3227, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [6701/15000], Step [1/1], Loss: 0.3200, lr: 0.000020\n","Epoch [6711/15000], Step [1/1], Loss: 0.3205, lr: 0.000020\n","Epoch [6721/15000], Step [1/1], Loss: 0.3184, lr: 0.000020\n","Epoch [6731/15000], Step [1/1], Loss: 0.3191, lr: 0.000020\n","Epoch [6741/15000], Step [1/1], Loss: 0.3208, lr: 0.000020\n","Epoch [6751/15000], Step [1/1], Loss: 0.3211, lr: 0.000020\n","Epoch [6761/15000], Step [1/1], Loss: 0.3195, lr: 0.000020\n","Epoch [6771/15000], Step [1/1], Loss: 0.3174, lr: 0.000020\n","Epoch [6781/15000], Step [1/1], Loss: 0.3180, lr: 0.000020\n","Epoch [6791/15000], Step [1/1], Loss: 0.3199, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [6801/15000], Step [1/1], Loss: 0.3229, lr: 0.000020\n","Epoch [6811/15000], Step [1/1], Loss: 0.3174, lr: 0.000020\n","Epoch [6821/15000], Step [1/1], Loss: 0.3180, lr: 0.000020\n","Epoch [6831/15000], Step [1/1], Loss: 0.3158, lr: 0.000020\n","Epoch [6841/15000], Step [1/1], Loss: 0.3192, lr: 0.000020\n","Epoch [6851/15000], Step [1/1], Loss: 0.3180, lr: 0.000020\n","Epoch [6861/15000], Step [1/1], Loss: 0.3163, lr: 0.000020\n","Epoch [6871/15000], Step [1/1], Loss: 0.3178, lr: 0.000020\n","Epoch [6881/15000], Step [1/1], Loss: 0.3152, lr: 0.000020\n","Epoch [6891/15000], Step [1/1], Loss: 0.3159, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 87.5%, 56 was correct\n","Epoch [6901/15000], Step [1/1], Loss: 0.3164, lr: 0.000020\n","Epoch [6911/15000], Step [1/1], Loss: 0.3155, lr: 0.000020\n","Epoch [6921/15000], Step [1/1], Loss: 0.3148, lr: 0.000020\n","Epoch [6931/15000], Step [1/1], Loss: 0.3163, lr: 0.000020\n","Epoch [6941/15000], Step [1/1], Loss: 0.3158, lr: 0.000020\n","Epoch [6951/15000], Step [1/1], Loss: 0.3148, lr: 0.000020\n","Epoch [6961/15000], Step [1/1], Loss: 0.3141, lr: 0.000020\n","Epoch [6971/15000], Step [1/1], Loss: 0.3173, lr: 0.000020\n","Epoch [6981/15000], Step [1/1], Loss: 0.3278, lr: 0.000020\n","Epoch [6991/15000], Step [1/1], Loss: 0.3105, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 82.8125%, 53 was correct\n","Epoch [7001/15000], Step [1/1], Loss: 0.3153, lr: 0.000020\n","Epoch [7011/15000], Step [1/1], Loss: 0.3143, lr: 0.000020\n","Epoch [7021/15000], Step [1/1], Loss: 0.3128, lr: 0.000020\n","Epoch [7031/15000], Step [1/1], Loss: 0.3140, lr: 0.000020\n","Epoch [7041/15000], Step [1/1], Loss: 0.3145, lr: 0.000020\n","Epoch [7051/15000], Step [1/1], Loss: 0.3120, lr: 0.000020\n","Epoch [7061/15000], Step [1/1], Loss: 0.3143, lr: 0.000020\n","Epoch [7071/15000], Step [1/1], Loss: 0.3137, lr: 0.000020\n","Epoch [7081/15000], Step [1/1], Loss: 0.3128, lr: 0.000020\n","Epoch [7091/15000], Step [1/1], Loss: 0.3140, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 89.0625%, 57 was correct\n","Epoch [7101/15000], Step [1/1], Loss: 0.3154, lr: 0.000020\n","Epoch [7111/15000], Step [1/1], Loss: 0.3106, lr: 0.000020\n","Epoch [7121/15000], Step [1/1], Loss: 0.3129, lr: 0.000020\n","Epoch [7131/15000], Step [1/1], Loss: 0.3150, lr: 0.000020\n","Epoch [7141/15000], Step [1/1], Loss: 0.3127, lr: 0.000020\n","Epoch [7151/15000], Step [1/1], Loss: 0.3119, lr: 0.000020\n","Epoch [7161/15000], Step [1/1], Loss: 0.3114, lr: 0.000020\n","Epoch [7171/15000], Step [1/1], Loss: 0.3148, lr: 0.000020\n","Epoch [7181/15000], Step [1/1], Loss: 0.3120, lr: 0.000020\n","Epoch [7191/15000], Step [1/1], Loss: 0.3115, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [7201/15000], Step [1/1], Loss: 0.3111, lr: 0.000020\n","Epoch [7211/15000], Step [1/1], Loss: 0.3104, lr: 0.000020\n","Epoch [7221/15000], Step [1/1], Loss: 0.3140, lr: 0.000020\n","Epoch [7231/15000], Step [1/1], Loss: 0.3139, lr: 0.000020\n","Epoch [7241/15000], Step [1/1], Loss: 0.3112, lr: 0.000020\n","Epoch [7251/15000], Step [1/1], Loss: 0.3138, lr: 0.000020\n","Epoch [7261/15000], Step [1/1], Loss: 0.3128, lr: 0.000020\n","Epoch [7271/15000], Step [1/1], Loss: 0.3109, lr: 0.000020\n","Epoch [7281/15000], Step [1/1], Loss: 0.3101, lr: 0.000020\n","Epoch [7291/15000], Step [1/1], Loss: 0.3092, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 87.5%, 56 was correct\n","Epoch [7301/15000], Step [1/1], Loss: 0.3107, lr: 0.000020\n","Epoch [7311/15000], Step [1/1], Loss: 0.3100, lr: 0.000020\n","Epoch [7321/15000], Step [1/1], Loss: 0.3107, lr: 0.000020\n","Epoch [7331/15000], Step [1/1], Loss: 0.3123, lr: 0.000020\n","Epoch [7341/15000], Step [1/1], Loss: 0.3078, lr: 0.000020\n","Epoch [7351/15000], Step [1/1], Loss: 0.3116, lr: 0.000020\n","Epoch [7361/15000], Step [1/1], Loss: 0.3132, lr: 0.000020\n","Epoch [7371/15000], Step [1/1], Loss: 0.3110, lr: 0.000020\n","Epoch [7381/15000], Step [1/1], Loss: 0.3141, lr: 0.000020\n","Epoch [7391/15000], Step [1/1], Loss: 0.3098, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 85.9375%, 55 was correct\n","Epoch [7401/15000], Step [1/1], Loss: 0.3080, lr: 0.000020\n","Epoch [7411/15000], Step [1/1], Loss: 0.3079, lr: 0.000020\n","Epoch [7421/15000], Step [1/1], Loss: 0.3107, lr: 0.000020\n","Epoch [7431/15000], Step [1/1], Loss: 0.3081, lr: 0.000020\n","Epoch [7441/15000], Step [1/1], Loss: 0.3085, lr: 0.000020\n","Epoch [7451/15000], Step [1/1], Loss: 0.3099, lr: 0.000020\n","Epoch [7461/15000], Step [1/1], Loss: 0.3067, lr: 0.000020\n","Epoch [7471/15000], Step [1/1], Loss: 0.3062, lr: 0.000020\n","Epoch [7481/15000], Step [1/1], Loss: 0.3083, lr: 0.000020\n","Epoch [7491/15000], Step [1/1], Loss: 0.3087, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 85.9375%, 55 was correct\n","Epoch [7501/15000], Step [1/1], Loss: 0.3070, lr: 0.000020\n","Epoch [7511/15000], Step [1/1], Loss: 0.3071, lr: 0.000020\n","Epoch [7521/15000], Step [1/1], Loss: 0.3083, lr: 0.000020\n","Epoch [7531/15000], Step [1/1], Loss: 0.3110, lr: 0.000020\n","Epoch [7541/15000], Step [1/1], Loss: 0.3070, lr: 0.000020\n","Epoch [7551/15000], Step [1/1], Loss: 0.3069, lr: 0.000020\n","Epoch [7561/15000], Step [1/1], Loss: 0.3047, lr: 0.000020\n","Epoch [7571/15000], Step [1/1], Loss: 0.3125, lr: 0.000020\n","Epoch [7581/15000], Step [1/1], Loss: 0.3097, lr: 0.000020\n","Epoch [7591/15000], Step [1/1], Loss: 0.3062, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 85.9375%, 55 was correct\n","Epoch [7601/15000], Step [1/1], Loss: 0.3059, lr: 0.000020\n","Epoch [7611/15000], Step [1/1], Loss: 0.3111, lr: 0.000020\n","Epoch [7621/15000], Step [1/1], Loss: 0.3063, lr: 0.000020\n","Epoch [7631/15000], Step [1/1], Loss: 0.3083, lr: 0.000020\n","Epoch [7641/15000], Step [1/1], Loss: 0.3048, lr: 0.000020\n","Epoch [7651/15000], Step [1/1], Loss: 0.3084, lr: 0.000020\n","Epoch [7661/15000], Step [1/1], Loss: 0.3063, lr: 0.000020\n","Epoch [7671/15000], Step [1/1], Loss: 0.3055, lr: 0.000020\n","Epoch [7681/15000], Step [1/1], Loss: 0.3043, lr: 0.000020\n","Epoch [7691/15000], Step [1/1], Loss: 0.3030, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 85.9375%, 55 was correct\n","Epoch [7701/15000], Step [1/1], Loss: 0.3045, lr: 0.000020\n","Epoch [7711/15000], Step [1/1], Loss: 0.3028, lr: 0.000020\n","Epoch [7721/15000], Step [1/1], Loss: 0.3050, lr: 0.000020\n","Epoch [7731/15000], Step [1/1], Loss: 0.3036, lr: 0.000020\n","Epoch [7741/15000], Step [1/1], Loss: 0.3061, lr: 0.000020\n","Epoch [7751/15000], Step [1/1], Loss: 0.3017, lr: 0.000020\n","Epoch [7761/15000], Step [1/1], Loss: 0.3041, lr: 0.000020\n","Epoch [7771/15000], Step [1/1], Loss: 0.3065, lr: 0.000020\n","Epoch [7781/15000], Step [1/1], Loss: 0.3027, lr: 0.000020\n","Epoch [7791/15000], Step [1/1], Loss: 0.3022, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 87.5%, 56 was correct\n","Epoch [7801/15000], Step [1/1], Loss: 0.3019, lr: 0.000020\n","Epoch [7811/15000], Step [1/1], Loss: 0.3024, lr: 0.000020\n","Epoch [7821/15000], Step [1/1], Loss: 0.3017, lr: 0.000020\n","Epoch [7831/15000], Step [1/1], Loss: 0.3028, lr: 0.000020\n","Epoch [7841/15000], Step [1/1], Loss: 0.3035, lr: 0.000020\n","Epoch [7851/15000], Step [1/1], Loss: 0.3014, lr: 0.000020\n","Epoch [7861/15000], Step [1/1], Loss: 0.3021, lr: 0.000020\n","Epoch [7871/15000], Step [1/1], Loss: 0.3014, lr: 0.000020\n","Epoch [7881/15000], Step [1/1], Loss: 0.3044, lr: 0.000020\n","Epoch [7891/15000], Step [1/1], Loss: 0.3033, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [7901/15000], Step [1/1], Loss: 0.3006, lr: 0.000020\n","Epoch [7911/15000], Step [1/1], Loss: 0.3012, lr: 0.000020\n","Epoch [7921/15000], Step [1/1], Loss: 0.2999, lr: 0.000020\n","Epoch [7931/15000], Step [1/1], Loss: 0.2988, lr: 0.000020\n","Epoch [7941/15000], Step [1/1], Loss: 0.3026, lr: 0.000020\n","Epoch [7951/15000], Step [1/1], Loss: 0.3006, lr: 0.000020\n","Epoch [7961/15000], Step [1/1], Loss: 0.3016, lr: 0.000020\n","Epoch [7971/15000], Step [1/1], Loss: 0.2997, lr: 0.000020\n","Epoch [7981/15000], Step [1/1], Loss: 0.3008, lr: 0.000020\n","Epoch [7991/15000], Step [1/1], Loss: 0.3008, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 85.9375%, 55 was correct\n","Epoch [8001/15000], Step [1/1], Loss: 0.3010, lr: 0.000020\n","Epoch [8011/15000], Step [1/1], Loss: 0.3015, lr: 0.000020\n","Epoch [8021/15000], Step [1/1], Loss: 0.3008, lr: 0.000020\n","Epoch [8031/15000], Step [1/1], Loss: 0.2987, lr: 0.000020\n","Epoch [8041/15000], Step [1/1], Loss: 0.2993, lr: 0.000020\n","Epoch [8051/15000], Step [1/1], Loss: 0.3002, lr: 0.000020\n","Epoch [8061/15000], Step [1/1], Loss: 0.2995, lr: 0.000020\n","Epoch [8071/15000], Step [1/1], Loss: 0.2987, lr: 0.000020\n","Epoch [8081/15000], Step [1/1], Loss: 0.2986, lr: 0.000020\n","Epoch [8091/15000], Step [1/1], Loss: 0.2987, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 82.8125%, 53 was correct\n","Epoch [8101/15000], Step [1/1], Loss: 0.2962, lr: 0.000020\n","Epoch [8111/15000], Step [1/1], Loss: 0.3016, lr: 0.000020\n","Epoch [8121/15000], Step [1/1], Loss: 0.2977, lr: 0.000020\n","Epoch [8131/15000], Step [1/1], Loss: 0.2984, lr: 0.000020\n","Epoch [8141/15000], Step [1/1], Loss: 0.3001, lr: 0.000020\n","Epoch [8151/15000], Step [1/1], Loss: 0.2983, lr: 0.000020\n","Epoch [8161/15000], Step [1/1], Loss: 0.3012, lr: 0.000020\n","Epoch [8171/15000], Step [1/1], Loss: 0.2974, lr: 0.000020\n","Epoch [8181/15000], Step [1/1], Loss: 0.2961, lr: 0.000020\n","Epoch [8191/15000], Step [1/1], Loss: 0.2953, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 87.5%, 56 was correct\n","Epoch [8201/15000], Step [1/1], Loss: 0.2972, lr: 0.000020\n","Epoch [8211/15000], Step [1/1], Loss: 0.2967, lr: 0.000020\n","Epoch [8221/15000], Step [1/1], Loss: 0.2951, lr: 0.000020\n","Epoch [8231/15000], Step [1/1], Loss: 0.2961, lr: 0.000020\n","Epoch [8241/15000], Step [1/1], Loss: 0.3001, lr: 0.000020\n","Epoch [8251/15000], Step [1/1], Loss: 0.2979, lr: 0.000020\n","Epoch [8261/15000], Step [1/1], Loss: 0.2961, lr: 0.000020\n","Epoch [8271/15000], Step [1/1], Loss: 0.2961, lr: 0.000020\n","Epoch [8281/15000], Step [1/1], Loss: 0.2986, lr: 0.000020\n","Epoch [8291/15000], Step [1/1], Loss: 0.2954, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [8301/15000], Step [1/1], Loss: 0.2951, lr: 0.000020\n","Epoch [8311/15000], Step [1/1], Loss: 0.2970, lr: 0.000020\n","Epoch [8321/15000], Step [1/1], Loss: 0.2984, lr: 0.000020\n","Epoch [8331/15000], Step [1/1], Loss: 0.2974, lr: 0.000020\n","Epoch [8341/15000], Step [1/1], Loss: 0.2956, lr: 0.000020\n","Epoch [8351/15000], Step [1/1], Loss: 0.2947, lr: 0.000020\n","Epoch [8361/15000], Step [1/1], Loss: 0.2950, lr: 0.000020\n","Epoch [8371/15000], Step [1/1], Loss: 0.2947, lr: 0.000020\n","Epoch [8381/15000], Step [1/1], Loss: 0.2914, lr: 0.000020\n","Epoch [8391/15000], Step [1/1], Loss: 0.3030, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 87.5%, 56 was correct\n","Epoch [8401/15000], Step [1/1], Loss: 0.2938, lr: 0.000020\n","Epoch [8411/15000], Step [1/1], Loss: 0.2949, lr: 0.000020\n","Epoch [8421/15000], Step [1/1], Loss: 0.2949, lr: 0.000020\n","Epoch [8431/15000], Step [1/1], Loss: 0.2944, lr: 0.000020\n","Epoch [8441/15000], Step [1/1], Loss: 0.2942, lr: 0.000020\n","Epoch [8451/15000], Step [1/1], Loss: 0.2923, lr: 0.000020\n","Epoch [8461/15000], Step [1/1], Loss: 0.2936, lr: 0.000020\n","Epoch [8471/15000], Step [1/1], Loss: 0.2926, lr: 0.000020\n","Epoch [8481/15000], Step [1/1], Loss: 0.2938, lr: 0.000020\n","Epoch [8491/15000], Step [1/1], Loss: 0.2931, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 85.9375%, 55 was correct\n","Epoch [8501/15000], Step [1/1], Loss: 0.2918, lr: 0.000020\n","Epoch [8511/15000], Step [1/1], Loss: 0.2887, lr: 0.000020\n","Epoch [8521/15000], Step [1/1], Loss: 0.2939, lr: 0.000020\n","Epoch [8531/15000], Step [1/1], Loss: 0.2893, lr: 0.000020\n","Epoch [8541/15000], Step [1/1], Loss: 0.2924, lr: 0.000020\n","Epoch [8551/15000], Step [1/1], Loss: 0.2921, lr: 0.000020\n","Epoch [8561/15000], Step [1/1], Loss: 0.2931, lr: 0.000020\n","Epoch [8571/15000], Step [1/1], Loss: 0.2919, lr: 0.000020\n","Epoch [8581/15000], Step [1/1], Loss: 0.2910, lr: 0.000020\n","Epoch [8591/15000], Step [1/1], Loss: 0.2919, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 85.9375%, 55 was correct\n","Epoch [8601/15000], Step [1/1], Loss: 0.2929, lr: 0.000020\n","Epoch [8611/15000], Step [1/1], Loss: 0.2906, lr: 0.000020\n","Epoch [8621/15000], Step [1/1], Loss: 0.2912, lr: 0.000020\n","Epoch [8631/15000], Step [1/1], Loss: 0.2945, lr: 0.000020\n","Epoch [8641/15000], Step [1/1], Loss: 0.2927, lr: 0.000020\n","Epoch [8651/15000], Step [1/1], Loss: 0.2922, lr: 0.000020\n","Epoch [8661/15000], Step [1/1], Loss: 0.2910, lr: 0.000020\n","Epoch [8671/15000], Step [1/1], Loss: 0.2928, lr: 0.000020\n","Epoch [8681/15000], Step [1/1], Loss: 0.2914, lr: 0.000020\n","Epoch [8691/15000], Step [1/1], Loss: 0.2903, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [8701/15000], Step [1/1], Loss: 0.2916, lr: 0.000020\n","Epoch [8711/15000], Step [1/1], Loss: 0.2901, lr: 0.000020\n","Epoch [8721/15000], Step [1/1], Loss: 0.2897, lr: 0.000020\n","Epoch [8731/15000], Step [1/1], Loss: 0.2933, lr: 0.000020\n","Epoch [8741/15000], Step [1/1], Loss: 0.2903, lr: 0.000020\n","Epoch [8751/15000], Step [1/1], Loss: 0.2917, lr: 0.000020\n","Epoch [8761/15000], Step [1/1], Loss: 0.2907, lr: 0.000020\n","Epoch [8771/15000], Step [1/1], Loss: 0.2896, lr: 0.000020\n","Epoch [8781/15000], Step [1/1], Loss: 0.2900, lr: 0.000020\n","Epoch [8791/15000], Step [1/1], Loss: 0.2890, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [8801/15000], Step [1/1], Loss: 0.2884, lr: 0.000020\n","Epoch [8811/15000], Step [1/1], Loss: 0.2876, lr: 0.000020\n","Epoch [8821/15000], Step [1/1], Loss: 0.2908, lr: 0.000020\n","Epoch [8831/15000], Step [1/1], Loss: 0.2873, lr: 0.000020\n","Epoch [8841/15000], Step [1/1], Loss: 0.2891, lr: 0.000020\n","Epoch [8851/15000], Step [1/1], Loss: 0.2885, lr: 0.000020\n","Epoch [8861/15000], Step [1/1], Loss: 0.2889, lr: 0.000020\n","Epoch [8871/15000], Step [1/1], Loss: 0.2890, lr: 0.000020\n","Epoch [8881/15000], Step [1/1], Loss: 0.2898, lr: 0.000020\n","Epoch [8891/15000], Step [1/1], Loss: 0.2907, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [8901/15000], Step [1/1], Loss: 0.2881, lr: 0.000020\n","Epoch [8911/15000], Step [1/1], Loss: 0.2851, lr: 0.000020\n","Epoch [8921/15000], Step [1/1], Loss: 0.2856, lr: 0.000020\n","Epoch [8931/15000], Step [1/1], Loss: 0.2905, lr: 0.000020\n","Epoch [8941/15000], Step [1/1], Loss: 0.2850, lr: 0.000020\n","Epoch [8951/15000], Step [1/1], Loss: 0.2870, lr: 0.000020\n","Epoch [8961/15000], Step [1/1], Loss: 0.2886, lr: 0.000020\n","Epoch [8971/15000], Step [1/1], Loss: 0.2875, lr: 0.000020\n","Epoch [8981/15000], Step [1/1], Loss: 0.2865, lr: 0.000020\n","Epoch [8991/15000], Step [1/1], Loss: 0.2865, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [9001/15000], Step [1/1], Loss: 0.2832, lr: 0.000020\n","Epoch [9011/15000], Step [1/1], Loss: 0.2884, lr: 0.000020\n","Epoch [9021/15000], Step [1/1], Loss: 0.2863, lr: 0.000020\n","Epoch [9031/15000], Step [1/1], Loss: 0.2891, lr: 0.000020\n","Epoch [9041/15000], Step [1/1], Loss: 0.2849, lr: 0.000020\n","Epoch [9051/15000], Step [1/1], Loss: 0.2846, lr: 0.000020\n","Epoch [9061/15000], Step [1/1], Loss: 0.2859, lr: 0.000020\n","Epoch [9071/15000], Step [1/1], Loss: 0.2849, lr: 0.000020\n","Epoch [9081/15000], Step [1/1], Loss: 0.2831, lr: 0.000020\n","Epoch [9091/15000], Step [1/1], Loss: 0.2843, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [9101/15000], Step [1/1], Loss: 0.2836, lr: 0.000020\n","Epoch [9111/15000], Step [1/1], Loss: 0.2874, lr: 0.000020\n","Epoch [9121/15000], Step [1/1], Loss: 0.2851, lr: 0.000020\n","Epoch [9131/15000], Step [1/1], Loss: 0.2844, lr: 0.000020\n","Epoch [9141/15000], Step [1/1], Loss: 0.2845, lr: 0.000020\n","Epoch [9151/15000], Step [1/1], Loss: 0.2831, lr: 0.000020\n","Epoch [9161/15000], Step [1/1], Loss: 0.2863, lr: 0.000020\n","Epoch [9171/15000], Step [1/1], Loss: 0.2835, lr: 0.000020\n","Epoch [9181/15000], Step [1/1], Loss: 0.2823, lr: 0.000020\n","Epoch [9191/15000], Step [1/1], Loss: 0.2838, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [9201/15000], Step [1/1], Loss: 0.2825, lr: 0.000020\n","Epoch [9211/15000], Step [1/1], Loss: 0.2820, lr: 0.000020\n","Epoch [9221/15000], Step [1/1], Loss: 0.2825, lr: 0.000020\n","Epoch [9231/15000], Step [1/1], Loss: 0.2840, lr: 0.000020\n","Epoch [9241/15000], Step [1/1], Loss: 0.2864, lr: 0.000020\n","Epoch [9251/15000], Step [1/1], Loss: 0.2806, lr: 0.000020\n","Epoch [9261/15000], Step [1/1], Loss: 0.2814, lr: 0.000020\n","Epoch [9271/15000], Step [1/1], Loss: 0.2842, lr: 0.000020\n","Epoch [9281/15000], Step [1/1], Loss: 0.2822, lr: 0.000020\n","Epoch [9291/15000], Step [1/1], Loss: 0.2828, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [9301/15000], Step [1/1], Loss: 0.2811, lr: 0.000020\n","Epoch [9311/15000], Step [1/1], Loss: 0.2818, lr: 0.000020\n","Epoch [9321/15000], Step [1/1], Loss: 0.2784, lr: 0.000020\n","Epoch [9331/15000], Step [1/1], Loss: 0.2811, lr: 0.000020\n","Epoch [9341/15000], Step [1/1], Loss: 0.2819, lr: 0.000020\n","Epoch [9351/15000], Step [1/1], Loss: 0.2808, lr: 0.000020\n","Epoch [9361/15000], Step [1/1], Loss: 0.2807, lr: 0.000020\n","Epoch [9371/15000], Step [1/1], Loss: 0.2808, lr: 0.000020\n","Epoch [9381/15000], Step [1/1], Loss: 0.2772, lr: 0.000020\n","Epoch [9391/15000], Step [1/1], Loss: 0.2842, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [9401/15000], Step [1/1], Loss: 0.2796, lr: 0.000020\n","Epoch [9411/15000], Step [1/1], Loss: 0.2800, lr: 0.000020\n","Epoch [9421/15000], Step [1/1], Loss: 0.2792, lr: 0.000020\n","Epoch [9431/15000], Step [1/1], Loss: 0.2780, lr: 0.000020\n","Epoch [9441/15000], Step [1/1], Loss: 0.2789, lr: 0.000020\n","Epoch [9451/15000], Step [1/1], Loss: 0.2799, lr: 0.000020\n","Epoch [9461/15000], Step [1/1], Loss: 0.2789, lr: 0.000020\n","Epoch [9471/15000], Step [1/1], Loss: 0.2779, lr: 0.000020\n","Epoch [9481/15000], Step [1/1], Loss: 0.2789, lr: 0.000020\n","Epoch [9491/15000], Step [1/1], Loss: 0.2778, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [9501/15000], Step [1/1], Loss: 0.2780, lr: 0.000020\n","Epoch [9511/15000], Step [1/1], Loss: 0.2819, lr: 0.000020\n","Epoch [9521/15000], Step [1/1], Loss: 0.2767, lr: 0.000020\n","Epoch [9531/15000], Step [1/1], Loss: 0.2793, lr: 0.000020\n","Epoch [9541/15000], Step [1/1], Loss: 0.2775, lr: 0.000020\n","Epoch [9551/15000], Step [1/1], Loss: 0.2775, lr: 0.000020\n","Epoch [9561/15000], Step [1/1], Loss: 0.2801, lr: 0.000020\n","Epoch [9571/15000], Step [1/1], Loss: 0.2771, lr: 0.000020\n","Epoch [9581/15000], Step [1/1], Loss: 0.2772, lr: 0.000020\n","Epoch [9591/15000], Step [1/1], Loss: 0.2758, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [9601/15000], Step [1/1], Loss: 0.2772, lr: 0.000020\n","Epoch [9611/15000], Step [1/1], Loss: 0.2757, lr: 0.000020\n","Epoch [9621/15000], Step [1/1], Loss: 0.2774, lr: 0.000020\n","Epoch [9631/15000], Step [1/1], Loss: 0.2738, lr: 0.000020\n","Epoch [9641/15000], Step [1/1], Loss: 0.2763, lr: 0.000020\n","Epoch [9651/15000], Step [1/1], Loss: 0.2795, lr: 0.000020\n","Epoch [9661/15000], Step [1/1], Loss: 0.2763, lr: 0.000020\n","Epoch [9671/15000], Step [1/1], Loss: 0.2762, lr: 0.000020\n","Epoch [9681/15000], Step [1/1], Loss: 0.2758, lr: 0.000020\n","Epoch [9691/15000], Step [1/1], Loss: 0.2744, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [9701/15000], Step [1/1], Loss: 0.2773, lr: 0.000020\n","Epoch [9711/15000], Step [1/1], Loss: 0.2743, lr: 0.000020\n","Epoch [9721/15000], Step [1/1], Loss: 0.2757, lr: 0.000020\n","Epoch [9731/15000], Step [1/1], Loss: 0.2749, lr: 0.000020\n","Epoch [9741/15000], Step [1/1], Loss: 0.2761, lr: 0.000020\n","Epoch [9751/15000], Step [1/1], Loss: 0.2744, lr: 0.000020\n","Epoch [9761/15000], Step [1/1], Loss: 0.2740, lr: 0.000020\n","Epoch [9771/15000], Step [1/1], Loss: 0.2772, lr: 0.000020\n","Epoch [9781/15000], Step [1/1], Loss: 0.2747, lr: 0.000020\n","Epoch [9791/15000], Step [1/1], Loss: 0.2760, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [9801/15000], Step [1/1], Loss: 0.2769, lr: 0.000020\n","Epoch [9811/15000], Step [1/1], Loss: 0.2717, lr: 0.000020\n","Epoch [9821/15000], Step [1/1], Loss: 0.2764, lr: 0.000020\n","Epoch [9831/15000], Step [1/1], Loss: 0.2790, lr: 0.000020\n","Epoch [9841/15000], Step [1/1], Loss: 0.2742, lr: 0.000020\n","Epoch [9851/15000], Step [1/1], Loss: 0.2720, lr: 0.000020\n","Epoch [9861/15000], Step [1/1], Loss: 0.2736, lr: 0.000020\n","Epoch [9871/15000], Step [1/1], Loss: 0.2713, lr: 0.000020\n","Epoch [9881/15000], Step [1/1], Loss: 0.2804, lr: 0.000020\n","Epoch [9891/15000], Step [1/1], Loss: 0.2719, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [9901/15000], Step [1/1], Loss: 0.2726, lr: 0.000020\n","Epoch [9911/15000], Step [1/1], Loss: 0.2715, lr: 0.000020\n","Epoch [9921/15000], Step [1/1], Loss: 0.2732, lr: 0.000020\n","Epoch [9931/15000], Step [1/1], Loss: 0.2716, lr: 0.000020\n","Epoch [9941/15000], Step [1/1], Loss: 0.2717, lr: 0.000020\n","Epoch [9951/15000], Step [1/1], Loss: 0.2728, lr: 0.000020\n","Epoch [9961/15000], Step [1/1], Loss: 0.2707, lr: 0.000020\n","Epoch [9971/15000], Step [1/1], Loss: 0.2734, lr: 0.000020\n","Epoch [9981/15000], Step [1/1], Loss: 0.2724, lr: 0.000020\n","Epoch [9991/15000], Step [1/1], Loss: 0.2722, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 82.8125%, 53 was correct\n","Epoch [10001/15000], Step [1/1], Loss: 0.2725, lr: 0.000020\n","Epoch [10011/15000], Step [1/1], Loss: 0.2713, lr: 0.000020\n","Epoch [10021/15000], Step [1/1], Loss: 0.2715, lr: 0.000020\n","Epoch [10031/15000], Step [1/1], Loss: 0.2713, lr: 0.000020\n","Epoch [10041/15000], Step [1/1], Loss: 0.2710, lr: 0.000020\n","Epoch [10051/15000], Step [1/1], Loss: 0.2702, lr: 0.000020\n","Epoch [10061/15000], Step [1/1], Loss: 0.2721, lr: 0.000020\n","Epoch [10071/15000], Step [1/1], Loss: 0.2705, lr: 0.000020\n","Epoch [10081/15000], Step [1/1], Loss: 0.2722, lr: 0.000020\n","Epoch [10091/15000], Step [1/1], Loss: 0.2681, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [10101/15000], Step [1/1], Loss: 0.2706, lr: 0.000020\n","Epoch [10111/15000], Step [1/1], Loss: 0.2692, lr: 0.000020\n","Epoch [10121/15000], Step [1/1], Loss: 0.2674, lr: 0.000020\n","Epoch [10131/15000], Step [1/1], Loss: 0.2676, lr: 0.000020\n","Epoch [10141/15000], Step [1/1], Loss: 0.2704, lr: 0.000020\n","Epoch [10151/15000], Step [1/1], Loss: 0.2704, lr: 0.000020\n","Epoch [10161/15000], Step [1/1], Loss: 0.2698, lr: 0.000020\n","Epoch [10171/15000], Step [1/1], Loss: 0.2694, lr: 0.000020\n","Epoch [10181/15000], Step [1/1], Loss: 0.2680, lr: 0.000020\n","Epoch [10191/15000], Step [1/1], Loss: 0.2676, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 82.8125%, 53 was correct\n","Epoch [10201/15000], Step [1/1], Loss: 0.2685, lr: 0.000020\n","Epoch [10211/15000], Step [1/1], Loss: 0.2686, lr: 0.000020\n","Epoch [10221/15000], Step [1/1], Loss: 0.2674, lr: 0.000020\n","Epoch [10231/15000], Step [1/1], Loss: 0.2677, lr: 0.000020\n","Epoch [10241/15000], Step [1/1], Loss: 0.2697, lr: 0.000020\n","Epoch [10251/15000], Step [1/1], Loss: 0.2670, lr: 0.000020\n","Epoch [10261/15000], Step [1/1], Loss: 0.2667, lr: 0.000020\n","Epoch [10271/15000], Step [1/1], Loss: 0.2678, lr: 0.000020\n","Epoch [10281/15000], Step [1/1], Loss: 0.2682, lr: 0.000020\n","Epoch [10291/15000], Step [1/1], Loss: 0.2698, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 84.375%, 54 was correct\n","Epoch [10301/15000], Step [1/1], Loss: 0.2659, lr: 0.000020\n","Epoch [10311/15000], Step [1/1], Loss: 0.2663, lr: 0.000020\n","Epoch [10321/15000], Step [1/1], Loss: 0.2681, lr: 0.000020\n","Epoch [10331/15000], Step [1/1], Loss: 0.2675, lr: 0.000020\n","Epoch [10341/15000], Step [1/1], Loss: 0.2684, lr: 0.000020\n","Epoch [10351/15000], Step [1/1], Loss: 0.2666, lr: 0.000020\n","Epoch [10361/15000], Step [1/1], Loss: 0.2676, lr: 0.000020\n","Epoch [10371/15000], Step [1/1], Loss: 0.2663, lr: 0.000020\n","Epoch [10381/15000], Step [1/1], Loss: 0.2656, lr: 0.000020\n","Epoch [10391/15000], Step [1/1], Loss: 0.2643, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 82.8125%, 53 was correct\n","Epoch [10401/15000], Step [1/1], Loss: 0.2673, lr: 0.000020\n","Epoch [10411/15000], Step [1/1], Loss: 0.2647, lr: 0.000020\n","Epoch [10421/15000], Step [1/1], Loss: 0.2701, lr: 0.000020\n","Epoch [10431/15000], Step [1/1], Loss: 0.2665, lr: 0.000020\n","Epoch [10441/15000], Step [1/1], Loss: 0.2653, lr: 0.000020\n","Epoch [10451/15000], Step [1/1], Loss: 0.2655, lr: 0.000020\n","Epoch [10461/15000], Step [1/1], Loss: 0.2648, lr: 0.000020\n","Epoch [10471/15000], Step [1/1], Loss: 0.2647, lr: 0.000020\n","Epoch [10481/15000], Step [1/1], Loss: 0.2645, lr: 0.000020\n","Epoch [10491/15000], Step [1/1], Loss: 0.2652, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 82.8125%, 53 was correct\n","Epoch [10501/15000], Step [1/1], Loss: 0.2648, lr: 0.000020\n","Epoch [10511/15000], Step [1/1], Loss: 0.2646, lr: 0.000020\n","Epoch [10521/15000], Step [1/1], Loss: 0.2634, lr: 0.000020\n","Epoch [10531/15000], Step [1/1], Loss: 0.2641, lr: 0.000020\n","Epoch [10541/15000], Step [1/1], Loss: 0.2639, lr: 0.000020\n","Epoch [10551/15000], Step [1/1], Loss: 0.2621, lr: 0.000020\n","Epoch [10561/15000], Step [1/1], Loss: 0.2634, lr: 0.000020\n","Epoch [10571/15000], Step [1/1], Loss: 0.2629, lr: 0.000020\n","Epoch [10581/15000], Step [1/1], Loss: 0.2634, lr: 0.000020\n","Epoch [10591/15000], Step [1/1], Loss: 0.2632, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 81.25%, 52 was correct\n","Epoch [10601/15000], Step [1/1], Loss: 0.2665, lr: 0.000020\n","Epoch [10611/15000], Step [1/1], Loss: 0.2617, lr: 0.000020\n","Epoch [10621/15000], Step [1/1], Loss: 0.2636, lr: 0.000020\n","Epoch [10631/15000], Step [1/1], Loss: 0.2617, lr: 0.000020\n","Epoch [10641/15000], Step [1/1], Loss: 0.2612, lr: 0.000020\n","Epoch [10651/15000], Step [1/1], Loss: 0.2627, lr: 0.000020\n","Epoch [10661/15000], Step [1/1], Loss: 0.2632, lr: 0.000020\n","Epoch [10671/15000], Step [1/1], Loss: 0.2639, lr: 0.000020\n","Epoch [10681/15000], Step [1/1], Loss: 0.2631, lr: 0.000020\n","Epoch [10691/15000], Step [1/1], Loss: 0.2617, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 82.8125%, 53 was correct\n","Epoch [10701/15000], Step [1/1], Loss: 0.2654, lr: 0.000020\n","Epoch [10711/15000], Step [1/1], Loss: 0.2634, lr: 0.000020\n","Epoch [10721/15000], Step [1/1], Loss: 0.2612, lr: 0.000020\n","Epoch [10731/15000], Step [1/1], Loss: 0.2619, lr: 0.000020\n","Epoch [10741/15000], Step [1/1], Loss: 0.2616, lr: 0.000020\n","Epoch [10751/15000], Step [1/1], Loss: 0.2602, lr: 0.000020\n","Epoch [10761/15000], Step [1/1], Loss: 0.2607, lr: 0.000020\n","Epoch [10771/15000], Step [1/1], Loss: 0.2610, lr: 0.000020\n","Epoch [10781/15000], Step [1/1], Loss: 0.2608, lr: 0.000020\n","Epoch [10791/15000], Step [1/1], Loss: 0.2596, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 81.25%, 52 was correct\n","Epoch [10801/15000], Step [1/1], Loss: 0.2618, lr: 0.000020\n","Epoch [10811/15000], Step [1/1], Loss: 0.2598, lr: 0.000020\n","Epoch [10821/15000], Step [1/1], Loss: 0.2621, lr: 0.000020\n","Epoch [10831/15000], Step [1/1], Loss: 0.2592, lr: 0.000020\n","Epoch [10841/15000], Step [1/1], Loss: 0.2610, lr: 0.000020\n","Epoch [10851/15000], Step [1/1], Loss: 0.2628, lr: 0.000020\n","Epoch [10861/15000], Step [1/1], Loss: 0.2572, lr: 0.000020\n","Epoch [10871/15000], Step [1/1], Loss: 0.2596, lr: 0.000020\n","Epoch [10881/15000], Step [1/1], Loss: 0.2593, lr: 0.000020\n","Epoch [10891/15000], Step [1/1], Loss: 0.2586, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 81.25%, 52 was correct\n","Epoch [10901/15000], Step [1/1], Loss: 0.2611, lr: 0.000020\n","Epoch [10911/15000], Step [1/1], Loss: 0.2607, lr: 0.000020\n","Epoch [10921/15000], Step [1/1], Loss: 0.2587, lr: 0.000020\n","Epoch [10931/15000], Step [1/1], Loss: 0.2573, lr: 0.000020\n","Epoch [10941/15000], Step [1/1], Loss: 0.2575, lr: 0.000020\n","Epoch [10951/15000], Step [1/1], Loss: 0.2579, lr: 0.000020\n","Epoch [10961/15000], Step [1/1], Loss: 0.2570, lr: 0.000020\n","Epoch [10971/15000], Step [1/1], Loss: 0.2569, lr: 0.000020\n","Epoch [10981/15000], Step [1/1], Loss: 0.2570, lr: 0.000020\n","Epoch [10991/15000], Step [1/1], Loss: 0.2576, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 79.6875%, 51 was correct\n","Epoch [11001/15000], Step [1/1], Loss: 0.2596, lr: 0.000020\n","Epoch [11011/15000], Step [1/1], Loss: 0.2596, lr: 0.000020\n","Epoch [11021/15000], Step [1/1], Loss: 0.2579, lr: 0.000020\n","Epoch [11031/15000], Step [1/1], Loss: 0.2563, lr: 0.000020\n","Epoch [11041/15000], Step [1/1], Loss: 0.2594, lr: 0.000020\n","Epoch [11051/15000], Step [1/1], Loss: 0.2557, lr: 0.000020\n","Epoch [11061/15000], Step [1/1], Loss: 0.2589, lr: 0.000020\n","Epoch [11071/15000], Step [1/1], Loss: 0.2537, lr: 0.000020\n","Epoch [11081/15000], Step [1/1], Loss: 0.2562, lr: 0.000020\n","Epoch [11091/15000], Step [1/1], Loss: 0.2555, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 81.25%, 52 was correct\n","Epoch [11101/15000], Step [1/1], Loss: 0.2560, lr: 0.000020\n","Epoch [11111/15000], Step [1/1], Loss: 0.2565, lr: 0.000020\n","Epoch [11121/15000], Step [1/1], Loss: 0.2564, lr: 0.000020\n","Epoch [11131/15000], Step [1/1], Loss: 0.2552, lr: 0.000020\n","Epoch [11141/15000], Step [1/1], Loss: 0.2567, lr: 0.000020\n","Epoch [11151/15000], Step [1/1], Loss: 0.2550, lr: 0.000020\n","Epoch [11161/15000], Step [1/1], Loss: 0.2560, lr: 0.000020\n","Epoch [11171/15000], Step [1/1], Loss: 0.2561, lr: 0.000020\n","Epoch [11181/15000], Step [1/1], Loss: 0.2555, lr: 0.000020\n","Epoch [11191/15000], Step [1/1], Loss: 0.2565, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 81.25%, 52 was correct\n","Epoch [11201/15000], Step [1/1], Loss: 0.2542, lr: 0.000020\n","Epoch [11211/15000], Step [1/1], Loss: 0.2559, lr: 0.000020\n","Epoch [11221/15000], Step [1/1], Loss: 0.2530, lr: 0.000020\n","Epoch [11231/15000], Step [1/1], Loss: 0.2549, lr: 0.000020\n","Epoch [11241/15000], Step [1/1], Loss: 0.2537, lr: 0.000020\n","Epoch [11251/15000], Step [1/1], Loss: 0.2544, lr: 0.000020\n","Epoch [11261/15000], Step [1/1], Loss: 0.2517, lr: 0.000020\n","Epoch [11271/15000], Step [1/1], Loss: 0.2547, lr: 0.000020\n","Epoch [11281/15000], Step [1/1], Loss: 0.2544, lr: 0.000020\n","Epoch [11291/15000], Step [1/1], Loss: 0.2532, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 81.25%, 52 was correct\n","Epoch [11301/15000], Step [1/1], Loss: 0.2554, lr: 0.000020\n","Epoch [11311/15000], Step [1/1], Loss: 0.2538, lr: 0.000020\n","Epoch [11321/15000], Step [1/1], Loss: 0.2529, lr: 0.000020\n","Epoch [11331/15000], Step [1/1], Loss: 0.2540, lr: 0.000020\n","Epoch [11341/15000], Step [1/1], Loss: 0.2522, lr: 0.000020\n","Epoch [11351/15000], Step [1/1], Loss: 0.2530, lr: 0.000020\n","Epoch [11361/15000], Step [1/1], Loss: 0.2519, lr: 0.000020\n","Epoch [11371/15000], Step [1/1], Loss: 0.2529, lr: 0.000020\n","Epoch [11381/15000], Step [1/1], Loss: 0.2519, lr: 0.000020\n","Epoch [11391/15000], Step [1/1], Loss: 0.2558, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 81.25%, 52 was correct\n","Epoch [11401/15000], Step [1/1], Loss: 0.2514, lr: 0.000020\n","Epoch [11411/15000], Step [1/1], Loss: 0.2515, lr: 0.000020\n","Epoch [11421/15000], Step [1/1], Loss: 0.2511, lr: 0.000020\n","Epoch [11431/15000], Step [1/1], Loss: 0.2516, lr: 0.000020\n","Epoch [11441/15000], Step [1/1], Loss: 0.2511, lr: 0.000020\n","Epoch [11451/15000], Step [1/1], Loss: 0.2505, lr: 0.000020\n","Epoch [11461/15000], Step [1/1], Loss: 0.2491, lr: 0.000020\n","Epoch [11471/15000], Step [1/1], Loss: 0.2522, lr: 0.000020\n","Epoch [11481/15000], Step [1/1], Loss: 0.2511, lr: 0.000020\n","Epoch [11491/15000], Step [1/1], Loss: 0.2501, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 82.8125%, 53 was correct\n","Epoch [11501/15000], Step [1/1], Loss: 0.2515, lr: 0.000020\n","Epoch [11511/15000], Step [1/1], Loss: 0.2482, lr: 0.000020\n","Epoch [11521/15000], Step [1/1], Loss: 0.2501, lr: 0.000020\n","Epoch [11531/15000], Step [1/1], Loss: 0.2505, lr: 0.000020\n","Epoch [11541/15000], Step [1/1], Loss: 0.2485, lr: 0.000020\n","Epoch [11551/15000], Step [1/1], Loss: 0.2510, lr: 0.000020\n","Epoch [11561/15000], Step [1/1], Loss: 0.2487, lr: 0.000020\n","Epoch [11571/15000], Step [1/1], Loss: 0.2498, lr: 0.000020\n","Epoch [11581/15000], Step [1/1], Loss: 0.2520, lr: 0.000020\n","Epoch [11591/15000], Step [1/1], Loss: 0.2504, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 81.25%, 52 was correct\n","Epoch [11601/15000], Step [1/1], Loss: 0.2490, lr: 0.000020\n","Epoch [11611/15000], Step [1/1], Loss: 0.2503, lr: 0.000020\n","Epoch [11621/15000], Step [1/1], Loss: 0.2480, lr: 0.000020\n","Epoch [11631/15000], Step [1/1], Loss: 0.2522, lr: 0.000020\n","Epoch [11641/15000], Step [1/1], Loss: 0.2495, lr: 0.000020\n","Epoch [11651/15000], Step [1/1], Loss: 0.2482, lr: 0.000020\n","Epoch [11661/15000], Step [1/1], Loss: 0.2502, lr: 0.000020\n","Epoch [11671/15000], Step [1/1], Loss: 0.2474, lr: 0.000020\n","Epoch [11681/15000], Step [1/1], Loss: 0.2490, lr: 0.000020\n","Epoch [11691/15000], Step [1/1], Loss: 0.2476, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 81.25%, 52 was correct\n","Epoch [11701/15000], Step [1/1], Loss: 0.2483, lr: 0.000020\n","Epoch [11711/15000], Step [1/1], Loss: 0.2490, lr: 0.000020\n","Epoch [11721/15000], Step [1/1], Loss: 0.2505, lr: 0.000020\n","Epoch [11731/15000], Step [1/1], Loss: 0.2463, lr: 0.000020\n","Epoch [11741/15000], Step [1/1], Loss: 0.2466, lr: 0.000020\n","Epoch [11751/15000], Step [1/1], Loss: 0.2463, lr: 0.000020\n","Epoch [11761/15000], Step [1/1], Loss: 0.2458, lr: 0.000020\n","Epoch [11771/15000], Step [1/1], Loss: 0.2512, lr: 0.000020\n","Epoch [11781/15000], Step [1/1], Loss: 0.2475, lr: 0.000020\n","Epoch [11791/15000], Step [1/1], Loss: 0.2453, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 79.6875%, 51 was correct\n","Epoch [11801/15000], Step [1/1], Loss: 0.2466, lr: 0.000020\n","Epoch [11811/15000], Step [1/1], Loss: 0.2454, lr: 0.000020\n","Epoch [11821/15000], Step [1/1], Loss: 0.2474, lr: 0.000020\n","Epoch [11831/15000], Step [1/1], Loss: 0.2458, lr: 0.000020\n","Epoch [11841/15000], Step [1/1], Loss: 0.2467, lr: 0.000020\n","Epoch [11851/15000], Step [1/1], Loss: 0.2455, lr: 0.000020\n","Epoch [11861/15000], Step [1/1], Loss: 0.2454, lr: 0.000020\n","Epoch [11871/15000], Step [1/1], Loss: 0.2465, lr: 0.000020\n","Epoch [11881/15000], Step [1/1], Loss: 0.2447, lr: 0.000020\n","Epoch [11891/15000], Step [1/1], Loss: 0.2447, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 81.25%, 52 was correct\n","Epoch [11901/15000], Step [1/1], Loss: 0.2451, lr: 0.000020\n","Epoch [11911/15000], Step [1/1], Loss: 0.2459, lr: 0.000020\n","Epoch [11921/15000], Step [1/1], Loss: 0.2453, lr: 0.000020\n","Epoch [11931/15000], Step [1/1], Loss: 0.2445, lr: 0.000020\n","Epoch [11941/15000], Step [1/1], Loss: 0.2441, lr: 0.000020\n","Epoch [11951/15000], Step [1/1], Loss: 0.2445, lr: 0.000020\n","Epoch [11961/15000], Step [1/1], Loss: 0.2441, lr: 0.000020\n","Epoch [11971/15000], Step [1/1], Loss: 0.2433, lr: 0.000020\n","Epoch [11981/15000], Step [1/1], Loss: 0.2454, lr: 0.000020\n","Epoch [11991/15000], Step [1/1], Loss: 0.2440, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 81.25%, 52 was correct\n","Epoch [12001/15000], Step [1/1], Loss: 0.2436, lr: 0.000020\n","Epoch [12011/15000], Step [1/1], Loss: 0.2436, lr: 0.000020\n","Epoch [12021/15000], Step [1/1], Loss: 0.2431, lr: 0.000020\n","Epoch [12031/15000], Step [1/1], Loss: 0.2439, lr: 0.000020\n","Epoch [12041/15000], Step [1/1], Loss: 0.2440, lr: 0.000020\n","Epoch [12051/15000], Step [1/1], Loss: 0.2439, lr: 0.000020\n","Epoch [12061/15000], Step [1/1], Loss: 0.2427, lr: 0.000020\n","Epoch [12071/15000], Step [1/1], Loss: 0.2421, lr: 0.000020\n","Epoch [12081/15000], Step [1/1], Loss: 0.2437, lr: 0.000020\n","Epoch [12091/15000], Step [1/1], Loss: 0.2437, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 79.6875%, 51 was correct\n","Epoch [12101/15000], Step [1/1], Loss: 0.2423, lr: 0.000020\n","Epoch [12111/15000], Step [1/1], Loss: 0.2431, lr: 0.000020\n","Epoch [12121/15000], Step [1/1], Loss: 0.2401, lr: 0.000020\n","Epoch [12131/15000], Step [1/1], Loss: 0.2446, lr: 0.000020\n","Epoch [12141/15000], Step [1/1], Loss: 0.2413, lr: 0.000020\n","Epoch [12151/15000], Step [1/1], Loss: 0.2418, lr: 0.000020\n","Epoch [12161/15000], Step [1/1], Loss: 0.2434, lr: 0.000020\n","Epoch [12171/15000], Step [1/1], Loss: 0.2421, lr: 0.000020\n","Epoch [12181/15000], Step [1/1], Loss: 0.2409, lr: 0.000020\n","Epoch [12191/15000], Step [1/1], Loss: 0.2420, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 78.125%, 50 was correct\n","Epoch [12201/15000], Step [1/1], Loss: 0.2417, lr: 0.000020\n","Epoch [12211/15000], Step [1/1], Loss: 0.2413, lr: 0.000020\n","Epoch [12221/15000], Step [1/1], Loss: 0.2400, lr: 0.000020\n","Epoch [12231/15000], Step [1/1], Loss: 0.2402, lr: 0.000020\n","Epoch [12241/15000], Step [1/1], Loss: 0.2414, lr: 0.000020\n","Epoch [12251/15000], Step [1/1], Loss: 0.2395, lr: 0.000020\n","Epoch [12261/15000], Step [1/1], Loss: 0.2393, lr: 0.000020\n","Epoch [12271/15000], Step [1/1], Loss: 0.2420, lr: 0.000020\n","Epoch [12281/15000], Step [1/1], Loss: 0.2391, lr: 0.000020\n","Epoch [12291/15000], Step [1/1], Loss: 0.2409, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 79.6875%, 51 was correct\n","Epoch [12301/15000], Step [1/1], Loss: 0.2405, lr: 0.000020\n","Epoch [12311/15000], Step [1/1], Loss: 0.2416, lr: 0.000020\n","Epoch [12321/15000], Step [1/1], Loss: 0.2391, lr: 0.000020\n","Epoch [12331/15000], Step [1/1], Loss: 0.2384, lr: 0.000020\n","Epoch [12341/15000], Step [1/1], Loss: 0.2395, lr: 0.000020\n","Epoch [12351/15000], Step [1/1], Loss: 0.2392, lr: 0.000020\n","Epoch [12361/15000], Step [1/1], Loss: 0.2384, lr: 0.000020\n","Epoch [12371/15000], Step [1/1], Loss: 0.2409, lr: 0.000020\n","Epoch [12381/15000], Step [1/1], Loss: 0.2397, lr: 0.000020\n","Epoch [12391/15000], Step [1/1], Loss: 0.2409, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 78.125%, 50 was correct\n","Epoch [12401/15000], Step [1/1], Loss: 0.2385, lr: 0.000020\n","Epoch [12411/15000], Step [1/1], Loss: 0.2389, lr: 0.000020\n","Epoch [12421/15000], Step [1/1], Loss: 0.2381, lr: 0.000020\n","Epoch [12431/15000], Step [1/1], Loss: 0.2382, lr: 0.000020\n","Epoch [12441/15000], Step [1/1], Loss: 0.2389, lr: 0.000020\n","Epoch [12451/15000], Step [1/1], Loss: 0.2380, lr: 0.000020\n","Epoch [12461/15000], Step [1/1], Loss: 0.2365, lr: 0.000020\n","Epoch [12471/15000], Step [1/1], Loss: 0.2396, lr: 0.000020\n","Epoch [12481/15000], Step [1/1], Loss: 0.2373, lr: 0.000020\n","Epoch [12491/15000], Step [1/1], Loss: 0.2381, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 79.6875%, 51 was correct\n","Epoch [12501/15000], Step [1/1], Loss: 0.2374, lr: 0.000020\n","Epoch [12511/15000], Step [1/1], Loss: 0.2370, lr: 0.000020\n","Epoch [12521/15000], Step [1/1], Loss: 0.2383, lr: 0.000020\n","Epoch [12531/15000], Step [1/1], Loss: 0.2371, lr: 0.000020\n","Epoch [12541/15000], Step [1/1], Loss: 0.2367, lr: 0.000020\n","Epoch [12551/15000], Step [1/1], Loss: 0.2368, lr: 0.000020\n","Epoch [12561/15000], Step [1/1], Loss: 0.2361, lr: 0.000020\n","Epoch [12571/15000], Step [1/1], Loss: 0.2379, lr: 0.000020\n","Epoch [12581/15000], Step [1/1], Loss: 0.2365, lr: 0.000020\n","Epoch [12591/15000], Step [1/1], Loss: 0.2361, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","Epoch [12601/15000], Step [1/1], Loss: 0.2367, lr: 0.000020\n","Epoch [12611/15000], Step [1/1], Loss: 0.2352, lr: 0.000020\n","Epoch [12621/15000], Step [1/1], Loss: 0.2370, lr: 0.000020\n","Epoch [12631/15000], Step [1/1], Loss: 0.2354, lr: 0.000020\n","Epoch [12641/15000], Step [1/1], Loss: 0.2368, lr: 0.000020\n","Epoch [12651/15000], Step [1/1], Loss: 0.2341, lr: 0.000020\n","Epoch [12661/15000], Step [1/1], Loss: 0.2360, lr: 0.000020\n","Epoch [12671/15000], Step [1/1], Loss: 0.2352, lr: 0.000020\n","Epoch [12681/15000], Step [1/1], Loss: 0.2341, lr: 0.000020\n","Epoch [12691/15000], Step [1/1], Loss: 0.2357, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","Epoch [12701/15000], Step [1/1], Loss: 0.2350, lr: 0.000020\n","Epoch [12711/15000], Step [1/1], Loss: 0.2374, lr: 0.000020\n","Epoch [12721/15000], Step [1/1], Loss: 0.2334, lr: 0.000020\n","Epoch [12731/15000], Step [1/1], Loss: 0.2330, lr: 0.000020\n","Epoch [12741/15000], Step [1/1], Loss: 0.2344, lr: 0.000020\n","Epoch [12751/15000], Step [1/1], Loss: 0.2327, lr: 0.000020\n","Epoch [12761/15000], Step [1/1], Loss: 0.2348, lr: 0.000020\n","Epoch [12771/15000], Step [1/1], Loss: 0.2346, lr: 0.000020\n","Epoch [12781/15000], Step [1/1], Loss: 0.2338, lr: 0.000020\n","Epoch [12791/15000], Step [1/1], Loss: 0.2350, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 78.125%, 50 was correct\n","Epoch [12801/15000], Step [1/1], Loss: 0.2345, lr: 0.000020\n","Epoch [12811/15000], Step [1/1], Loss: 0.2346, lr: 0.000020\n","Epoch [12821/15000], Step [1/1], Loss: 0.2355, lr: 0.000020\n","Epoch [12831/15000], Step [1/1], Loss: 0.2329, lr: 0.000020\n","Epoch [12841/15000], Step [1/1], Loss: 0.2345, lr: 0.000020\n","Epoch [12851/15000], Step [1/1], Loss: 0.2332, lr: 0.000020\n","Epoch [12861/15000], Step [1/1], Loss: 0.2325, lr: 0.000020\n","Epoch [12871/15000], Step [1/1], Loss: 0.2326, lr: 0.000020\n","Epoch [12881/15000], Step [1/1], Loss: 0.2304, lr: 0.000020\n","Epoch [12891/15000], Step [1/1], Loss: 0.2330, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","Epoch [12901/15000], Step [1/1], Loss: 0.2328, lr: 0.000020\n","Epoch [12911/15000], Step [1/1], Loss: 0.2325, lr: 0.000020\n","Epoch [12921/15000], Step [1/1], Loss: 0.2323, lr: 0.000020\n","Epoch [12931/15000], Step [1/1], Loss: 0.2306, lr: 0.000020\n","Epoch [12941/15000], Step [1/1], Loss: 0.2308, lr: 0.000020\n","Epoch [12951/15000], Step [1/1], Loss: 0.2326, lr: 0.000020\n","Epoch [12961/15000], Step [1/1], Loss: 0.2321, lr: 0.000020\n","Epoch [12971/15000], Step [1/1], Loss: 0.2309, lr: 0.000020\n","Epoch [12981/15000], Step [1/1], Loss: 0.2317, lr: 0.000020\n","Epoch [12991/15000], Step [1/1], Loss: 0.2307, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","Epoch [13001/15000], Step [1/1], Loss: 0.2342, lr: 0.000020\n","Epoch [13011/15000], Step [1/1], Loss: 0.2277, lr: 0.000020\n","Epoch [13021/15000], Step [1/1], Loss: 0.2333, lr: 0.000020\n","Epoch [13031/15000], Step [1/1], Loss: 0.2308, lr: 0.000020\n","Epoch [13041/15000], Step [1/1], Loss: 0.2286, lr: 0.000020\n","Epoch [13051/15000], Step [1/1], Loss: 0.2313, lr: 0.000020\n","Epoch [13061/15000], Step [1/1], Loss: 0.2285, lr: 0.000020\n","Epoch [13071/15000], Step [1/1], Loss: 0.2295, lr: 0.000020\n","Epoch [13081/15000], Step [1/1], Loss: 0.2281, lr: 0.000020\n","Epoch [13091/15000], Step [1/1], Loss: 0.2301, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 78.125%, 50 was correct\n","Epoch [13101/15000], Step [1/1], Loss: 0.2294, lr: 0.000020\n","Epoch [13111/15000], Step [1/1], Loss: 0.2306, lr: 0.000020\n","Epoch [13121/15000], Step [1/1], Loss: 0.2287, lr: 0.000020\n","Epoch [13131/15000], Step [1/1], Loss: 0.2287, lr: 0.000020\n","Epoch [13141/15000], Step [1/1], Loss: 0.2313, lr: 0.000020\n","Epoch [13151/15000], Step [1/1], Loss: 0.2286, lr: 0.000020\n","Epoch [13161/15000], Step [1/1], Loss: 0.2287, lr: 0.000020\n","Epoch [13171/15000], Step [1/1], Loss: 0.2283, lr: 0.000020\n","Epoch [13181/15000], Step [1/1], Loss: 0.2297, lr: 0.000020\n","Epoch [13191/15000], Step [1/1], Loss: 0.2301, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","Epoch [13201/15000], Step [1/1], Loss: 0.2267, lr: 0.000020\n","Epoch [13211/15000], Step [1/1], Loss: 0.2311, lr: 0.000020\n","Epoch [13221/15000], Step [1/1], Loss: 0.2298, lr: 0.000020\n","Epoch [13231/15000], Step [1/1], Loss: 0.2290, lr: 0.000020\n","Epoch [13241/15000], Step [1/1], Loss: 0.2254, lr: 0.000020\n","Epoch [13251/15000], Step [1/1], Loss: 0.2279, lr: 0.000020\n","Epoch [13261/15000], Step [1/1], Loss: 0.2271, lr: 0.000020\n","Epoch [13271/15000], Step [1/1], Loss: 0.2281, lr: 0.000020\n","Epoch [13281/15000], Step [1/1], Loss: 0.2268, lr: 0.000020\n","Epoch [13291/15000], Step [1/1], Loss: 0.2277, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","Epoch [13301/15000], Step [1/1], Loss: 0.2279, lr: 0.000020\n","Epoch [13311/15000], Step [1/1], Loss: 0.2267, lr: 0.000020\n","Epoch [13321/15000], Step [1/1], Loss: 0.2262, lr: 0.000020\n","Epoch [13331/15000], Step [1/1], Loss: 0.2284, lr: 0.000020\n","Epoch [13341/15000], Step [1/1], Loss: 0.2261, lr: 0.000020\n","Epoch [13351/15000], Step [1/1], Loss: 0.2268, lr: 0.000020\n","Epoch [13361/15000], Step [1/1], Loss: 0.2256, lr: 0.000020\n","Epoch [13371/15000], Step [1/1], Loss: 0.2265, lr: 0.000020\n","Epoch [13381/15000], Step [1/1], Loss: 0.2258, lr: 0.000020\n","Epoch [13391/15000], Step [1/1], Loss: 0.2253, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","Epoch [13401/15000], Step [1/1], Loss: 0.2257, lr: 0.000020\n","Epoch [13411/15000], Step [1/1], Loss: 0.2257, lr: 0.000020\n","Epoch [13421/15000], Step [1/1], Loss: 0.2267, lr: 0.000020\n","Epoch [13431/15000], Step [1/1], Loss: 0.2249, lr: 0.000020\n","Epoch [13441/15000], Step [1/1], Loss: 0.2272, lr: 0.000020\n","Epoch [13451/15000], Step [1/1], Loss: 0.2259, lr: 0.000020\n","Epoch [13461/15000], Step [1/1], Loss: 0.2259, lr: 0.000020\n","Epoch [13471/15000], Step [1/1], Loss: 0.2250, lr: 0.000020\n","Epoch [13481/15000], Step [1/1], Loss: 0.2239, lr: 0.000020\n","Epoch [13491/15000], Step [1/1], Loss: 0.2261, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 75.0%, 48 was correct\n","Epoch [13501/15000], Step [1/1], Loss: 0.2290, lr: 0.000020\n","Epoch [13511/15000], Step [1/1], Loss: 0.2257, lr: 0.000020\n","Epoch [13521/15000], Step [1/1], Loss: 0.2243, lr: 0.000020\n","Epoch [13531/15000], Step [1/1], Loss: 0.2236, lr: 0.000020\n","Epoch [13541/15000], Step [1/1], Loss: 0.2233, lr: 0.000020\n","Epoch [13551/15000], Step [1/1], Loss: 0.2262, lr: 0.000020\n","Epoch [13561/15000], Step [1/1], Loss: 0.2239, lr: 0.000020\n","Epoch [13571/15000], Step [1/1], Loss: 0.2236, lr: 0.000020\n","Epoch [13581/15000], Step [1/1], Loss: 0.2245, lr: 0.000020\n","Epoch [13591/15000], Step [1/1], Loss: 0.2226, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","Epoch [13601/15000], Step [1/1], Loss: 0.2234, lr: 0.000020\n","Epoch [13611/15000], Step [1/1], Loss: 0.2222, lr: 0.000020\n","Epoch [13621/15000], Step [1/1], Loss: 0.2210, lr: 0.000020\n","Epoch [13631/15000], Step [1/1], Loss: 0.2226, lr: 0.000020\n","Epoch [13641/15000], Step [1/1], Loss: 0.2222, lr: 0.000020\n","Epoch [13651/15000], Step [1/1], Loss: 0.2228, lr: 0.000020\n","Epoch [13661/15000], Step [1/1], Loss: 0.2234, lr: 0.000020\n","Epoch [13671/15000], Step [1/1], Loss: 0.2213, lr: 0.000020\n","Epoch [13681/15000], Step [1/1], Loss: 0.2270, lr: 0.000020\n","Epoch [13691/15000], Step [1/1], Loss: 0.2223, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","Epoch [13701/15000], Step [1/1], Loss: 0.2226, lr: 0.000020\n","Epoch [13711/15000], Step [1/1], Loss: 0.2213, lr: 0.000020\n","Epoch [13721/15000], Step [1/1], Loss: 0.2224, lr: 0.000020\n","Epoch [13731/15000], Step [1/1], Loss: 0.2220, lr: 0.000020\n","Epoch [13741/15000], Step [1/1], Loss: 0.2217, lr: 0.000020\n","Epoch [13751/15000], Step [1/1], Loss: 0.2239, lr: 0.000020\n","Epoch [13761/15000], Step [1/1], Loss: 0.2226, lr: 0.000020\n","Epoch [13771/15000], Step [1/1], Loss: 0.2217, lr: 0.000020\n","Epoch [13781/15000], Step [1/1], Loss: 0.2234, lr: 0.000020\n","Epoch [13791/15000], Step [1/1], Loss: 0.2201, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","Epoch [13801/15000], Step [1/1], Loss: 0.2210, lr: 0.000020\n","Epoch [13811/15000], Step [1/1], Loss: 0.2205, lr: 0.000020\n","Epoch [13821/15000], Step [1/1], Loss: 0.2203, lr: 0.000020\n","Epoch [13831/15000], Step [1/1], Loss: 0.2191, lr: 0.000020\n","Epoch [13841/15000], Step [1/1], Loss: 0.2218, lr: 0.000020\n","Epoch [13851/15000], Step [1/1], Loss: 0.2246, lr: 0.000020\n","Epoch [13861/15000], Step [1/1], Loss: 0.2204, lr: 0.000020\n","Epoch [13871/15000], Step [1/1], Loss: 0.2218, lr: 0.000020\n","Epoch [13881/15000], Step [1/1], Loss: 0.2198, lr: 0.000020\n","Epoch [13891/15000], Step [1/1], Loss: 0.2192, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","Epoch [13901/15000], Step [1/1], Loss: 0.2212, lr: 0.000020\n","Epoch [13911/15000], Step [1/1], Loss: 0.2194, lr: 0.000020\n","Epoch [13921/15000], Step [1/1], Loss: 0.2212, lr: 0.000020\n","Epoch [13931/15000], Step [1/1], Loss: 0.2215, lr: 0.000020\n","Epoch [13941/15000], Step [1/1], Loss: 0.2196, lr: 0.000020\n","Epoch [13951/15000], Step [1/1], Loss: 0.2194, lr: 0.000020\n","Epoch [13961/15000], Step [1/1], Loss: 0.2209, lr: 0.000020\n","Epoch [13971/15000], Step [1/1], Loss: 0.2191, lr: 0.000020\n","Epoch [13981/15000], Step [1/1], Loss: 0.2186, lr: 0.000020\n","Epoch [13991/15000], Step [1/1], Loss: 0.2199, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","Epoch [14001/15000], Step [1/1], Loss: 0.2187, lr: 0.000020\n","Epoch [14011/15000], Step [1/1], Loss: 0.2197, lr: 0.000020\n","Epoch [14021/15000], Step [1/1], Loss: 0.2183, lr: 0.000020\n","Epoch [14031/15000], Step [1/1], Loss: 0.2173, lr: 0.000020\n","Epoch [14041/15000], Step [1/1], Loss: 0.2190, lr: 0.000020\n","Epoch [14051/15000], Step [1/1], Loss: 0.2191, lr: 0.000020\n","Epoch [14061/15000], Step [1/1], Loss: 0.2177, lr: 0.000020\n","Epoch [14071/15000], Step [1/1], Loss: 0.2178, lr: 0.000020\n","Epoch [14081/15000], Step [1/1], Loss: 0.2184, lr: 0.000020\n","Epoch [14091/15000], Step [1/1], Loss: 0.2177, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","Epoch [14101/15000], Step [1/1], Loss: 0.2189, lr: 0.000020\n","Epoch [14111/15000], Step [1/1], Loss: 0.2164, lr: 0.000020\n","Epoch [14121/15000], Step [1/1], Loss: 0.2173, lr: 0.000020\n","Epoch [14131/15000], Step [1/1], Loss: 0.2153, lr: 0.000020\n","Epoch [14141/15000], Step [1/1], Loss: 0.2196, lr: 0.000020\n","Epoch [14151/15000], Step [1/1], Loss: 0.2160, lr: 0.000020\n","Epoch [14161/15000], Step [1/1], Loss: 0.2168, lr: 0.000020\n","Epoch [14171/15000], Step [1/1], Loss: 0.2165, lr: 0.000020\n","Epoch [14181/15000], Step [1/1], Loss: 0.2179, lr: 0.000020\n","Epoch [14191/15000], Step [1/1], Loss: 0.2162, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","Epoch [14201/15000], Step [1/1], Loss: 0.2168, lr: 0.000020\n","Epoch [14211/15000], Step [1/1], Loss: 0.2157, lr: 0.000020\n","Epoch [14221/15000], Step [1/1], Loss: 0.2162, lr: 0.000020\n","Epoch [14231/15000], Step [1/1], Loss: 0.2170, lr: 0.000020\n","Epoch [14241/15000], Step [1/1], Loss: 0.2161, lr: 0.000020\n","Epoch [14251/15000], Step [1/1], Loss: 0.2173, lr: 0.000020\n","Epoch [14261/15000], Step [1/1], Loss: 0.2170, lr: 0.000020\n","Epoch [14271/15000], Step [1/1], Loss: 0.2183, lr: 0.000020\n","Epoch [14281/15000], Step [1/1], Loss: 0.2154, lr: 0.000020\n","Epoch [14291/15000], Step [1/1], Loss: 0.2158, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 75.0%, 48 was correct\n","Epoch [14301/15000], Step [1/1], Loss: 0.2150, lr: 0.000020\n","Epoch [14311/15000], Step [1/1], Loss: 0.2153, lr: 0.000020\n","Epoch [14321/15000], Step [1/1], Loss: 0.2147, lr: 0.000020\n","Epoch [14331/15000], Step [1/1], Loss: 0.2146, lr: 0.000020\n","Epoch [14341/15000], Step [1/1], Loss: 0.2150, lr: 0.000020\n","Epoch [14351/15000], Step [1/1], Loss: 0.2143, lr: 0.000020\n","Epoch [14361/15000], Step [1/1], Loss: 0.2151, lr: 0.000020\n","Epoch [14371/15000], Step [1/1], Loss: 0.2170, lr: 0.000020\n","Epoch [14381/15000], Step [1/1], Loss: 0.2153, lr: 0.000020\n","Epoch [14391/15000], Step [1/1], Loss: 0.2141, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","Epoch [14401/15000], Step [1/1], Loss: 0.2139, lr: 0.000020\n","Epoch [14411/15000], Step [1/1], Loss: 0.2137, lr: 0.000020\n","Epoch [14421/15000], Step [1/1], Loss: 0.2181, lr: 0.000020\n","Epoch [14431/15000], Step [1/1], Loss: 0.2144, lr: 0.000020\n","Epoch [14441/15000], Step [1/1], Loss: 0.2137, lr: 0.000020\n","Epoch [14451/15000], Step [1/1], Loss: 0.2137, lr: 0.000020\n","Epoch [14461/15000], Step [1/1], Loss: 0.2130, lr: 0.000020\n","Epoch [14471/15000], Step [1/1], Loss: 0.2138, lr: 0.000020\n","Epoch [14481/15000], Step [1/1], Loss: 0.2128, lr: 0.000020\n","Epoch [14491/15000], Step [1/1], Loss: 0.2136, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 73.4375%, 47 was correct\n","Epoch [14501/15000], Step [1/1], Loss: 0.2124, lr: 0.000020\n","Epoch [14511/15000], Step [1/1], Loss: 0.2119, lr: 0.000020\n","Epoch [14521/15000], Step [1/1], Loss: 0.2127, lr: 0.000020\n","Epoch [14531/15000], Step [1/1], Loss: 0.2128, lr: 0.000020\n","Epoch [14541/15000], Step [1/1], Loss: 0.2115, lr: 0.000020\n","Epoch [14551/15000], Step [1/1], Loss: 0.2141, lr: 0.000020\n","Epoch [14561/15000], Step [1/1], Loss: 0.2177, lr: 0.000020\n","Epoch [14571/15000], Step [1/1], Loss: 0.2148, lr: 0.000020\n","Epoch [14581/15000], Step [1/1], Loss: 0.2122, lr: 0.000020\n","Epoch [14591/15000], Step [1/1], Loss: 0.2115, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","Epoch [14601/15000], Step [1/1], Loss: 0.2122, lr: 0.000020\n","Epoch [14611/15000], Step [1/1], Loss: 0.2113, lr: 0.000020\n","Epoch [14621/15000], Step [1/1], Loss: 0.2123, lr: 0.000020\n","Epoch [14631/15000], Step [1/1], Loss: 0.2116, lr: 0.000020\n","Epoch [14641/15000], Step [1/1], Loss: 0.2118, lr: 0.000020\n","Epoch [14651/15000], Step [1/1], Loss: 0.2114, lr: 0.000020\n","Epoch [14661/15000], Step [1/1], Loss: 0.2110, lr: 0.000020\n","Epoch [14671/15000], Step [1/1], Loss: 0.2104, lr: 0.000020\n","Epoch [14681/15000], Step [1/1], Loss: 0.2103, lr: 0.000020\n","Epoch [14691/15000], Step [1/1], Loss: 0.2105, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","Epoch [14701/15000], Step [1/1], Loss: 0.2103, lr: 0.000020\n","Epoch [14711/15000], Step [1/1], Loss: 0.2102, lr: 0.000020\n","Epoch [14721/15000], Step [1/1], Loss: 0.2113, lr: 0.000020\n","Epoch [14731/15000], Step [1/1], Loss: 0.2102, lr: 0.000020\n","Epoch [14741/15000], Step [1/1], Loss: 0.2113, lr: 0.000020\n","Epoch [14751/15000], Step [1/1], Loss: 0.2071, lr: 0.000020\n","Epoch [14761/15000], Step [1/1], Loss: 0.2079, lr: 0.000020\n","Epoch [14771/15000], Step [1/1], Loss: 0.2098, lr: 0.000020\n","Epoch [14781/15000], Step [1/1], Loss: 0.2093, lr: 0.000020\n","Epoch [14791/15000], Step [1/1], Loss: 0.2081, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 75.0%, 48 was correct\n","Epoch [14801/15000], Step [1/1], Loss: 0.2081, lr: 0.000020\n","Epoch [14811/15000], Step [1/1], Loss: 0.2107, lr: 0.000020\n","Epoch [14821/15000], Step [1/1], Loss: 0.2093, lr: 0.000020\n","Epoch [14831/15000], Step [1/1], Loss: 0.2085, lr: 0.000020\n","Epoch [14841/15000], Step [1/1], Loss: 0.2090, lr: 0.000020\n","Epoch [14851/15000], Step [1/1], Loss: 0.2083, lr: 0.000020\n","Epoch [14861/15000], Step [1/1], Loss: 0.2079, lr: 0.000020\n","Epoch [14871/15000], Step [1/1], Loss: 0.2084, lr: 0.000020\n","Epoch [14881/15000], Step [1/1], Loss: 0.2110, lr: 0.000020\n","Epoch [14891/15000], Step [1/1], Loss: 0.2083, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 75.0%, 48 was correct\n","Epoch [14901/15000], Step [1/1], Loss: 0.2092, lr: 0.000020\n","Epoch [14911/15000], Step [1/1], Loss: 0.2084, lr: 0.000020\n","Epoch [14921/15000], Step [1/1], Loss: 0.2069, lr: 0.000020\n","Epoch [14931/15000], Step [1/1], Loss: 0.2064, lr: 0.000020\n","Epoch [14941/15000], Step [1/1], Loss: 0.2082, lr: 0.000020\n","Epoch [14951/15000], Step [1/1], Loss: 0.2079, lr: 0.000020\n","Epoch [14961/15000], Step [1/1], Loss: 0.2088, lr: 0.000020\n","Epoch [14971/15000], Step [1/1], Loss: 0.2072, lr: 0.000020\n","Epoch [14981/15000], Step [1/1], Loss: 0.2086, lr: 0.000020\n","Epoch [14991/15000], Step [1/1], Loss: 0.2066, lr: 0.000020\n","Test Accuracy of the model on 64 samples is: 76.5625%, 49 was correct\n","0\n"]}],"source":["#main\n","\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","#Data transforms (normalization and data augmentation)\n","\n","train_dataset = load_data(data_dir+'/train')\n","test_dataset = load_data(data_dir+'/validation')\n","\n","# Data loader\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size, \n","                                          shuffle=False)\n","\n","sum=0\n","\n","for i in range(1):\n","  #create the model\n","  RAW_IRNN=create_raw_model_IRNN(input_size, hidden_size, num_layers)\n","  model_CNN = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n","  model_RNN = Net(input_size, hidden_size, num_layers).to(device)\n","  model_IRNN = personal_Net(input_size, hidden_size, num_layers).to(device)\n","  # Loss and optimizer\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer_CNN = torch.optim.Adam(model_CNN.parameters(), lr=learning_rate)\n","  optimizer_RNN = torch.optim.Adam(model_RNN.parameters(), lr=learning_rate)\n","  optimizer_IRNN = torch.optim.Adam(model_IRNN.parameters(), lr=learning_rate)\n","\n","  # new_train(model,optimizer)\n","\n","  # Train the model\n","\n","  train(test_loader,train_loader,num_epochs,sequence_length,input_size,model_IRNN,optimizer_IRNN,max_lr,grad_clip)\n","  # score_A,score_B,score_C=train_test_multi(test_loader,train_loader,num_epochs,sequence_length,input_size,\n","  #                    model_CNN,optimizer_CNN,\"CNN\",\n","  #                    max_lr=max_lr,grad_clip=grad_clip,\n","  #                    model_B=model_RNN,optimizer_B=optimizer_RNN,model_name_B=\"RNN\",\n","  #                    model_C=model_IRNN,optimizer_C=optimizer_IRNN,model_name_C=\"IRNN\")\n","  # score_A,score_B,score_C=train_test_multi(test_loader,train_loader,num_epochs,sequence_length,input_size,\n","  #                    model_CNN,optimizer_CNN,\"CNN\",\n","  #                    max_lr=max_lr,grad_clip=grad_clip,\n","  #                    model_B=model_RNN,optimizer_B=optimizer_RNN,model_name_B=\"RNN\",\n","  #                    model_C=model_IRNN,optimizer_C=optimizer_IRNN,model_name_C=\"IRNN\")\n","  testing(model_IRNN,test_loader)\n","  # Test the model\n","  # sum+=testing(model,test_loader)\n","  # create_plot(score_A,\"red\",\"CNN\")\n","  # create_plot(score_B,\"blue\",\"RNN\")\n","  # create_plot(score_C,\"purple\",\"IRNN\")\n","  # plt.legend()\n","  # plt.show()\n","print(sum)"]},{"cell_type":"markdown","metadata":{"id":"opZTVJjPVMoa"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"vtB8zJuKEz4O"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"5YA-q6j0Ezp5"},"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"enU_QictM5iu"},"outputs":[],"source":["device = torch.device('cuda')\n","print(sum)\n","print(\"test before save\")\n","# testing(model_IRNN,test_loader)\n","device = torch.device('cpu')\n","# rawirnn=model_CNN.indrnn.state_dict()\n","PATH='./model_scissors'\n","# torch.save(model_IRNN.state_dict(), PATH)\n","# print(\"test after save\")\n","\n","model_test =  Net(input_size, hidden_size, num_layers,RAW_IRNN,True).to(device)\n","model_test.load_state_dict(torch.load(PATH))\n","# model_test.indrnn.load_state_dict(rawirnn)\n","model_test.eval()\n","testing(model_test,test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f4ma17QY4LxF"},"outputs":[],"source":["device = torch.device('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"477du8H7sq1I"},"outputs":[],"source":["testing(model_test,test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IMXw6UIdsqyJ"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOFdWPjsq7F4ibqmRfMIEY7","background_execution":"on","collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1u5ZR4yuxyDp7STW9227_qXyKD76t1pIZ","name":"RNNV5.ipynb","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}