"""Code modified from the example program to show how to read a multi-channel time series from LSL at https://github.com/OpenBCI/OpenBCI_GUI/blob/master/Networking-Test-Kit/LSL/lslStreamTest.py."""


from pylsl import StreamInlet, resolve_stream
import pyautogui
import time
import threading

import numpy as np


from sklearn.model_selection import train_test_split

from sklearn import svm



# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_VpMIZxLYkV0hrxufGJgtJLwSmUi5Xuf
"""


def loadDataList(dataList,
                 sizeOfGroup):  # get a list of data to learn(data[0]=when y = 0,data[1]=when y = 1),with the size of the group wanted,return X_train, X_valid, y_train, y_valid


    data, labels = load_data(dataList[0][0], dataList[1][0], sizeOfGroup,
                             bestCut("best cut to data train at index 0:", dataList[0][0], dataList[1][0], sizeOfGroup))

    X_train, X_valid, y_train, y_valid = train_test_split(data, labels, test_size=0.1, random_state=20, shuffle=True)

    for i in range(len(dataList[0]) - 1):
        X_train, X_valid, y_train, y_valid = addData(X_train, X_valid, y_train, y_valid, dataList[0][i + 1],
                                                     dataList[1][i + 1], sizeOfGroup,
                                                     bestCut("best cut to data train at index " + str(i + 1) + ":",
                                                             dataList[0][i + 1], dataList[1][i + 1], sizeOfGroup))

    return X_train, X_valid, y_train, y_valid


def bestCut(toPrint, open, close,
            sizeOfGroup):  # check how big we sould cut the edges , so the data can explain itself the best(edges=high chance of faults and noise)

    return 24
    start = 4
    end = 30
    bestAcc = 0
    bestI = 0
    for i in range(end):
        I = i + start
        data, labels = load_data(open, close, sizeOfGroup, I)
        acc = scoreWithSVM(data, labels)
        if bestAcc <= acc:
            bestAcc = acc
            bestI = I
    print(toPrint, bestI)
    return bestI


def scoreWithSVM(data, labels):  # simply get data ,labels , and return a score with svm algrorithms

    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.1, random_state=50, shuffle=True)
    clf = svm.SVC()
    clf.fit(X_train, y_train)
    predict = clf.predict(X_test)
    score = (compare(predict, y_test))
    return score


def addData(X_train, X_test, y_train, y_test, open, close, sizeOfGroup,
            cut):  # add data to the train andf test with the name of the files ,also get the group size of classes(must be equal to x classes),and the best cut
    data, labels = load_data(open, close, sizeOfGroup, cut)

    X_train2, X_test2, y_train2, y_test2 = train_test_split(data, labels, test_size=0.1, random_state=20, shuffle=True)

    X_train = np.vstack((X_train, X_train2))
    y_train = np.append(y_train, y_train2)

    X_test = np.vstack((X_test, X_test2))
    y_test = np.append(y_test, y_test2)

    return X_train, X_test, y_train, y_test


def predictWithSum(predicted,
                   k):  # check the last k results in the predict in each step and go by what most say , if 1 or 0 and return it ,
    # example with k=5 : 0000 0001 0011 0101 predict, will return 0000 0000 0001 1111 ,make it more sequential
    re = np.array([])
    for i in range(k):
        re = np.append(re, predicted[i])

    sumOf1 = np.sum(re[0:k] == 1)
    sum = 2 * sumOf1 - k  # sumOf1-(len(sumOf1)-sumOf1) how many 1 minues how many not 1
    for i in range(len(predicted) - k):
        j = i + k
        sum, decision = sumLastKSize(predicted[j], predicted[j - k], sum)
        re = np.append(re, decision)

    return re


def sumLastKSize(add, remove,
                 sum):  # calculte the next sum size k of the next sample(by removeing the first and adding a new one in order)
    # example :[00110]0=> sum=-1, sum-(-1)+-1->sum=-1 => 0[01100]
    decision = 0
    if remove == 0:
        remove = -1
    if add == 0:
        add = -1
    sum = sum + add - remove
    if sum < 0:
        decision = 0
    else:
        decision = 1
    return sum, decision


def groupData(data,
              size):  # loop on data, and group the samples as one sample in size of the size we got in the arguments
    # example: [2,3][4,2][1,2][3,5]=>size=2=>[2,3,4,2][1,2,3,5]
    returnData = np.array([[]])
    for i in range(int(len(data) - size)):
        block = np.array(data[i:i + size].flatten())  # group i to i +size all the data and create new colums for each
        if i == 0:
            returnData = np.append(returnData, block)
        else:
            returnData = np.vstack((returnData, block))

    return returnData


def load_data(openName, closeName, sizeOfGroup,
              split):  # get data name with y =0,data name with y=1, how many lines to group for each sample and the size to cut the edges

    OPEN = np.loadtxt(open("D:\\git\\MACHINE\\Data\\" + openName, "rb"), delimiter=",", usecols=range(3, 5))
    CLOSE = np.loadtxt(open("D:\\git\\MACHINE\\Data\\" + closeName, "rb"), delimiter=",", usecols=range(3, 5))

    OPEN = OPEN[int(len(OPEN) / split):int(len(OPEN) - len(OPEN) / split)]
    CLOSE = CLOSE[int(len(CLOSE) / split):int(len(CLOSE) - len(OPEN) / split)]


    openGrouped = groupData(OPEN, sizeOfGroup)
    closedGrouped = groupData(CLOSE, sizeOfGroup)

    openLabels = np.array([0] * len(openGrouped))
    closeLabels = np.array([1] * len(closedGrouped))
    data = np.vstack((openGrouped, closedGrouped))
    labels = np.append(openLabels, closeLabels)
    return data, labels


def compare(a, b):  # return how many was right divide by all
    size = len(a)
    sum = np.sum(a == b)
    return sum / size













#~~~~~~~~~~~~~~~~~~~~~~~~~~`main`~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
from PIL import Image
import psutil
import os
import subprocess


def showyourhand(isopen,im1,im2):
    if isopen:
        im1.show()
    else:
        im2.show()


isopen=True
with Image.open("open.jpg") as im1:
    im1.show()
with Image.open("closed.jpg") as im2:
    im2.show()

sizeOfGroup = 20
sumGroupSize = 10  # for sum algorithm #how many to check before the current one when u check what y the most sad
global LastPrediction
LastPrediction=None

lastSumPredict=[0]*sumGroupSize
lock = threading.Lock()

dataList = [[  # data list , data[0]= when y equal to zero , data[1]=when y equal to one

    "open3009.txt"
]
    , [

        "close3009.txt"

    ]]
dataTest = ["TESTOPEN.txt", "TESTCLOSE.txt"]  # the data will be only for final testing

X_train, X_valid, y_train, y_valid = loadDataList(dataList, sizeOfGroup)  # load a data from a list
X_test, y_test = load_data(dataTest[0], dataTest[1], sizeOfGroup,
                           bestCut("best cut on final data test : ", dataTest[0], dataTest[1], sizeOfGroup))

clf = svm.SVC(C=100, kernel='rbf', degree=3, gamma=0.0000025, coef0=0.0, shrinking=True, probability=False, tol=0.001,
              cache_size=200, class_weight=None, verbose=False, max_iter=- 1, decision_function_shape='ovr',
              break_ties=False, random_state=None)
clf.fit(X_train, y_train)


predict = clf.predict(X_valid)
print("\n\ncurrent score on valid :", str(compare(predict, y_valid) * 100) + "%")




def addSample(size,data,sample):#get the size of data, data, the sample , and return the data with the new sample
    if size==0:
        data=np.array([sample]*1)

    else:
        data=np.vstack((data,sample))

    return data



def CopyfirstPartOfData(data,size):#copy from the start size amount of data and return it
    if size > len(data):
        exit("error when copying")
    return data[0:size]
def deletefirstPart(data,size):# delete from the starty size amount of data and return it with the deleted data
    if size > len(data):
        exit("error when deleting")
    if size==len(data):
        return None
    return data[size:len(data)]


def setLastPrediction(param):
    global LastPrediction
    LastPrediction=param


def predictTheSample(data):
    data=data[:,2:4]
    X_test=np.array([data.ravel()])
    #predict = predictWithSum(clf.predict(X_test), sumGroupSize)[sumGroupSize:]
    predict = clf.predict(X_test)
#    print("last was:",LastPrediction)
    if predict[0]==0:
 #       if LastPrediction!="open":
  #          showyourhand(True, im1, im2)
            print("open")
            setLastPrediction("open")

    else:
 #       if LastPrediction != "closed":

#            showyourhand(False, im1, im2)
            print("closed")
            setLastPrediction("closed")
class SummingThread(threading.Thread):
    def __init__(self, mon):
        threading.Thread.__init__(self)
        self.mon = mon

    def run(self):
        toPredict=False
        print("predicter started")
        while True:
            lock.acquire()
            if self.mon[0]>=sizeOfGroup:
                copy=CopyfirstPartOfData(self.mon[1],sizeOfGroup)
                self.mon[1]=deletefirstPart(self.mon[1],sizeOfGroup)
                self.mon[0]=self.mon[0]-sizeOfGroup
                toPredict=True
            lock.release()
            if toPredict:
                predictTheSample(copy)
                toPredict=False

# resolve an EMG stream on the lab network and notify the user
print("Looking for an EMG stream...")
streams = resolve_stream('type', 'EMG')
inlet = StreamInlet(streams[0])
print("EMG stream found!")

# initialize thresholds and variables for storing time
time_thres = 2000
prev_time = 0
flex_thres = 1.0

data = []
i = 0
a = [0] + [None] #a[0]=size a[1]=data
thread = SummingThread(a)
thread.start()
SaveDataFromNow = False
start=0
while True:
    sample, timestamp = inlet.pull_sample()  # get EMG data sample and its timestamp


    lock.acquire()
    a[1] = addSample(a[0],a[1],sample)
    a[0]=a[0]+1
    lock.release()

    curr_time = int(round(time.time() * 1000))  # get current time in milliseconds

    # if ((sample[0] >= flex_thres) & (
    #         curr_time - time_thres > prev_time)):  # if an EMG peak is detected and enough time has gone by since the last one, press space
    #     prev_time = curr_time  # update time
    #     pyautogui.press('space')



